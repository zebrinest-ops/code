# -*- coding: utf-8 -*-
"""
Created on Fri Mar  7 10:57:07 2025

@author: Administrator
"""

import numpy as np
import pandas as pd
import math
import os,gc
from glob import glob
import xarray as xr
from datetime import datetime
import warnings
from pathlib import Path
from scipy.interpolate import interp1d
from scipy.interpolate import RegularGridInterpolator
from scipy import stats
import statsmodels.api as sm
import metpy.calc
from metpy.units import units
from metpy.calc import relative_humidity_from_dewpoint
import metpy.calc as mpcalc
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker
import matplotlib.lines as mlines
from matplotlib.gridspec import GridSpec
from matplotlib.ticker import MultipleLocator, AutoMinorLocator
with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=FutureWarning)
    # æ­¤å¤„ä»£ç ä¸­çš„FutureWarningå°†è¢«å¿½ç•¥
# é“å¡”æµ·æ‹”
Altitude = 49
output_path = "E:\\Beijing2024\\æ•°æ®å¤„ç†ç»“æœ2nd\\"
try:
    os.makedirs(output_path, exist_ok=True)
except:
    print(f"æƒé™ä¸è¶³ï¼Œæ— æ³•åˆ›å»ºç›®å½•ï¼š{output_path}")
    exit(1)
def goff_gratch_formula_dataframe(df):#å†°é¢çš„å…¬å¼å¦å¤–éœ€è¦åˆ—å‡ºï¼Œè®¡ç®—å¤å¤©æ­¤å¤„çœç•¥
    def goff_gratch_formula(T):
        T_ref = 373.15  # Reference temperature in Kelvin (100Â°C)
        log10_es = (
            -7.90298 * (T_ref / T - 1) +
            5.02808 * math.log10(T_ref / T) -
            1.3816e-7 * (10**(11.344 * (1 - T / T_ref)) - 1) +
            8.1328e-3 * (10**(-3.49149 * (T_ref / T - 1)) - 1) +
            math.log10(1013.246)
        )
        es = 10**log10_es
        return es
    
    # Apply the Goff-Gratch formula to each element in the DataFrame
    es_df = df.map(goff_gratch_formula)
    return es_df
############å¤„ç†é“å¡”æ•°æ®###################
# Set the path to your target directory
path = r'E:\Beijing2024\é“å¡”\2024é“å¡”å¹³å‡åœº6æœˆ6è‡³6æœˆ98æœˆ5æ—¥è‡³8æœˆ10æ—¥10å¤©æ•°æ®(1)\0805-0810\\'

# Get a list of all files in the folder
files = [f for f in os.listdir(path) if f.endswith('.txt')]  # Assuming all files are .txt files

# Initialize an empty list to collect data frames
all_data = []

# Loop through each file in the folder
for file in files:
    file_path = os.path.join(path, file)
    
    # Read data from the file
    df = pd.read_table(file_path, skiprows=5, header=None, sep=r'\s+')
    print(file)
    # Iterate over the data and create timestamps
    for i in range(1, 4321):  # i ä» 1 åˆ° 4320
        # è·å–å½“å‰æ—¶é—´ç‚¹çš„å„ä¸ªéƒ¨åˆ†
        if (18*i - 2) >= len(df):
            break
        year = "20" + str(df.iloc[18*i-2, 1])  # è·å–å¹´ä»½ï¼ˆå‡è®¾å¹´ä»½åœ¨ç¬¬ 1 åˆ—ï¼‰
        day = df.iloc[18*i-2, 3]  # è·å–æ—¥æœŸï¼ˆå‡è®¾æ—¥æœŸåœ¨ç¬¬ 3 åˆ—ï¼‰
        month = df.iloc[18*i-2, 5]  # è·å–æœˆä»½ï¼ˆå‡è®¾æœˆä»½åœ¨ç¬¬ 5 åˆ—ï¼‰
        hour = df.iloc[18*i-1, 1]  # è·å–å°æ—¶ï¼ˆå‡è®¾å°æ—¶åœ¨ç¬¬ 1 åˆ—ï¼‰
        minute = df.iloc[18*i-1, 3]  # è·å–åˆ†é’Ÿï¼ˆå‡è®¾åˆ†é’Ÿåœ¨ç¬¬ 3 åˆ—ï¼‰
        second = df.iloc[18*i-1, 5]  # è·å–ç§’ï¼ˆå‡è®¾ç§’åœ¨ç¬¬ 5 åˆ—ï¼‰

        # åˆ›å»ºæ—¶é—´æˆ³
        timestamps = pd.to_datetime(f"{year}-{month}-{day} {hour}:{minute}:{second}")

        # å°†æ—¶é—´æˆ³æ·»åŠ åˆ° DataFrame ä¸­
        df.loc[18*i-17:18*i-3, 'timestamps'] = timestamps
    
    # Append the processed DataFrame to the list
    all_data.append(df)

# Concatenate all DataFrames from all files into one large DataFrame
final_df = pd.concat(all_data, ignore_index=True)

tieta_filtered = final_df[~final_df.iloc[:, 0].str.contains('=|-', na=False)]
tieta_filtered.columns = tieta_filtered.iloc[0]
tieta_filtered.columns.values[6] = 'timestamps'
tieta_filtered = tieta_filtered[1:].reset_index(drop=True)  # åˆ é™¤ç¬¬ä¸€è¡Œå¹¶é‡ç½®ç´¢å¼•
tieta_filtered.set_index('timestamps', inplace=True)
tieta_filtered.replace('999.0', np.nan, inplace=True)
#Vnwå’ŒVseæ˜¯ç”±åŒä¸€æ¡çº¿ä¸Šä¸¤ä¸ªä¼ æ„Ÿå™¨æµ‹åˆ°çš„ï¼Œå¯ä»¥ä»»å–å…¶ä¸­ä¸€ä¸ªæˆ–è€…ä½œå¹³å‡
tieta_filtered['ws_mean(m/s)'] = tieta_filtered.iloc[:, 1:3].apply(pd.to_numeric, errors='coerce').mean(axis=1)
tieta_filtered['T(c)'] = tieta_filtered['T(c)'].apply(lambda x: pd.to_numeric(x,  errors='coerce'))
tieta_filtered['T(c)'] = tieta_filtered['T(c)'].astype(float).round(3)
tieta_filtered['T(K)'] = tieta_filtered['T(c)']+273.15
tieta_filtered['RH(%)'] = tieta_filtered['RH(%)'].apply(lambda x: pd.to_numeric(x,  errors='coerce'))
tieta_filtered['RH(%)'] = tieta_filtered['RH(%)'].astype(float).round(1)
tieta_filtered['D(deg)'] = tieta_filtered['D(deg)'].apply(lambda x: pd.to_numeric(x,  errors='coerce'))
tieta_filtered['D(deg)'] = tieta_filtered['D(deg)'].astype(float).round(1)
tieta_filtered['H(m)'] = tieta_filtered['H(m)'].apply(lambda x: pd.to_numeric(x,  errors='coerce'))
tieta_filtered['H(m)'] = tieta_filtered['H(m)'].astype(float).round(0)

tieta_filtered['u'] = tieta_filtered['ws_mean(m/s)'] *np.sin(np.deg2rad(tieta_filtered['D(deg)']))
tieta_filtered['v'] = tieta_filtered['ws_mean(m/s)'] *np.cos(np.deg2rad(tieta_filtered['D(deg)']))

tieta_filtered = tieta_filtered.drop(columns=['Vnw(m/s)', 'Vse(m/s)', 'T(c)'])
tieta_filtered.columns = ['H(m)', 'wd_tieta', 'RH_tieta', 'ws_tieta', 'T(K)_tieta','u','v']

tieta_1min = (tieta_filtered.reset_index().groupby(['H(m)', pd.Grouper(key='timestamps', freq='1min')]).mean()).reset_index()
tieta_5min = (tieta_filtered.reset_index().groupby(['H(m)', pd.Grouper(key='timestamps', freq='5min')]).mean()).reset_index()
tieta_60min = (tieta_filtered.reset_index().groupby(['H(m)', pd.Grouper(key='timestamps', freq='60min')]).mean()).reset_index()



tieta_filtered = tieta_filtered.reset_index()
tieta_filtered['timestamps'] = tieta_filtered['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')
tieta_1min['timestamps'] = tieta_1min['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')
tieta_5min['timestamps'] = tieta_5min['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')
tieta_60min['timestamps'] = tieta_60min['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')

# è°ƒæ•´åˆ—é¡ºåº
new_columns = ['timestamps', 'H(m)'] + [col for col in tieta_filtered.columns if col not in ['timestamps', 'H(m)']]
tieta_filtered = tieta_filtered[new_columns]
tieta_1min = tieta_1min[new_columns]
tieta_5min = tieta_5min[new_columns]
tieta_60min = tieta_60min[new_columns]

# æŒ‰æ—¶é—´å’Œé«˜åº¦æ’åº
tieta_filtered = tieta_filtered.sort_values(by=['timestamps', 'H(m)'])
tieta_1min = tieta_1min.sort_values(by=['timestamps', 'H(m)'])
tieta_5min = tieta_5min.sort_values(by=['timestamps', 'H(m)'])
tieta_60min = tieta_60min.sort_values(by=['timestamps', 'H(m)'])

tieta_1min['height_plus_alt'] = tieta_1min['H(m)'] + Altitude
tieta_1min['Level (hPa)'] = pd.DataFrame(metpy.calc.height_to_pressure_std(tieta_1min['height_plus_alt'].to_list() * units('m')).m)
tieta_1min = tieta_1min.set_index(['timestamps', 'Level (hPa)'])

#tieta_filtered.to_csv(os.path.join(path, 'tieta_origin_merged.csv'), index=False)
# with pd.ExcelWriter(output_path + 'tieta0805-0810_1-5-60.xlsx',  engine='xlsxwriter', date_format='yyyy/mm/dd hh:mm:ss') as writer:
#     # å†™å…¥æ•°æ®åˆ°ä¸åŒsheet
#     tieta_filtered.to_excel(writer,  sheet_name='tieta0805-0810_1s', index=False)
#     tieta_1min.reset_index().to_excel(writer,  sheet_name='tieta0805-0810_1min', index=False)
#     tieta_5min.to_excel(writer,  sheet_name='tieta0805-0810_5min', index=False)
#     tieta_60min.to_excel(writer,  sheet_name='tieta0805-0810_60min', index=False)
    
#     # è®¾ç½®åˆ—å®½ï¼ˆä»…é€‚ç”¨äºxlsxwriterå¼•æ“ï¼‰
#     for sheet_name in writer.sheets: 
#         worksheet = writer.sheets[sheet_name] 
#         worksheet.set_column('A:A',  20)  # æ³¨æ„å‚æ•°æ ¼å¼ä¸º'A:A'è€Œé'A'


#######è¶…å£°é£æ•°æ®å¤„ç†#######
#æ³¨é‡Šæ‰çš„ä»£ç ä¸ºå¤„ç†åŸå§‹æ•°æ®çš„ä»£ç ï¼Œè¿è¡Œä¸€æ¬¡ä¿å­˜åˆå¹¶åæ•°æ®ï¼Œåç»­è¯»å–æ—¶ç›´æ¥è¯»å–åˆå¹¶ååŸå§‹æ–‡ä»¶
# main_dir = r'E:\Beijing2024\è¶…å£°é£\2024-08-05---2024-08-10'

# # è·å–æ‰€æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶è·¯å¾„åŠå¯¹åº”é«˜åº¦ï¼ˆåŒ…å«æ‰€æœ‰æ‰©å±•åï¼‰
# file_list = []
# for raw_folder in glob(os.path.join(main_dir, '*', 'raw')):
#     height = os.path.basename(os.path.dirname(raw_folder))
#     for data_file in glob(os.path.join(raw_folder, '*.*')):  # åŒ¹é…æ‰€æœ‰æ–‡ä»¶ç±»å‹
#         file_list.append((data_file, height))

# required_columns = [
#     'CO2 (mmol/m^3)', 'CO2 (mg/m^3)',
#     'H2O (mmol/m^3)', 'H2O (g/m^3)',
#     'Temperature (C)', 'Pressure (kPa)',
#     'CO2 (umol/mol)', 'H2O (mmol/mol)',
#     'Dew Point (C)', 'U (m/s)', 'V (m/s)',
#     'W (m/s)', 'T (C)'
# ]

# # å…³é”®æ—¶é—´åˆ—æ£€æŸ¥æ¸…å•
# time_columns = ['Date', 'Time']

# dfs = []

# for file_path, height in file_list:
#     try:
#         # è¯»å–æ•°æ®ï¼ˆè‡ªåŠ¨æ£€æµ‹åˆ†éš”ç¬¦ï¼‰
#         df = pd.read_csv(file_path, sep=None, engine='python', skiprows=7, header=0)
#         print(file_path)
#         # æ£€æŸ¥å¿…è¦æ—¶é—´åˆ—æ˜¯å¦å­˜åœ¨
#         missing_cols = [col for col in time_columns if col not in df.columns]
#         if missing_cols:
#             raise KeyError(f"ç¼ºå°‘å…³é”®åˆ— {missing_cols}ï¼Œæ— æ³•ç”Ÿæˆæ—¶é—´æˆ³")
#         df['Time'] = df['Time'].str.replace(r':(\d{3})$', r'.\1', regex=True)  
        
#         df['timestamps'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%Y-%m-%d %H:%M:%S.%f')

#         # æ·»åŠ é«˜åº¦åˆ—å¹¶é€‰æ‹©æ‰€éœ€åˆ—
#         df['Height'] = height
#         selected_cols = ['timestamps', 'Height'] + [col for col in required_columns if col in df.columns]
#         df_selected = df[selected_cols]
        
#         dfs.append(df_selected)
        
#     except Exception as e:
#         print(f"è·³è¿‡æ–‡ä»¶ {os.path.basename(file_path)}ï¼ŒåŸå› ï¼š{str(e)}")
#         continue

# # åˆå¹¶å¤„ç†åçš„æ•°æ®
# if dfs:
#     combined_df = pd.concat(dfs, ignore_index=True)
    
#     # å¤„ç†å‹åŠ›åˆ—
#     if 'Pressure (kPa)' in combined_df.columns:
#         combined_df['Pressure (hPa)'] = combined_df['Pressure (kPa)'] * 10
#         combined_df.drop('Pressure (kPa)', axis=1, inplace=True)
#     else:
#         print("è­¦å‘Šï¼šæœªæ‰¾åˆ° Pressure (kPa) åˆ—")
    
#     print("åˆå¹¶å®Œæˆï¼Œæœ‰æ•ˆè®°å½•æ•°:", len(combined_df))
#     print("æœ€ç»ˆåˆ—é¡ºåº:", combined_df.columns.tolist())
# else:
#     combined_df = pd.DataFrame()
#     print("æœªåˆå¹¶ä»»ä½•æœ‰æ•ˆæ•°æ®")

###############å¤„ç†è¶…å£°é£æ•°æ®##############################
combined_df = pd.read_parquet('E:\\Beijing2024\\è¶…å£°é£\\turb.parquet', engine='pyarrow')
#combined_df = pd.read_csv('E:\\Beijing2024\\è¶…å£°é£\\2024-08-05---2024-08-10\\combined_ultrasonic_wind.csv')
combined_df = combined_df.rename(columns={'Timestamp':  'timestamps'})       
combined_df['timestamps'] = pd.to_datetime(combined_df['timestamps'])
combined_df = combined_df.replace(-9999, np.nan)

# ç»“æœç¤ºä¾‹
print("\nç¤ºä¾‹æ•°æ®ï¼š")
print(combined_df.head(2) if not combined_df.empty else "ç©ºæ•°æ®é›†")
ultrasonic_turb_1min = (combined_df.groupby(['Height', pd.Grouper(key='timestamps', freq='1min')]).mean()).reset_index()
ultrasonic_turb_1min['hws'] = np.sqrt(np.square(ultrasonic_turb_1min['U (m/s)']) + np.square(ultrasonic_turb_1min['V (m/s)']))
ultrasonic_turb_1min['wd'] =  (90 - np.degrees(np.arctan2(ultrasonic_turb_1min['V (m/s)'], -ultrasonic_turb_1min['U (m/s)']))) % 360

ultrasonic_turb_1s = (combined_df.groupby(['Height', pd.Grouper(key='timestamps', freq='1s')]).mean()).reset_index()
ultrasonic_turb_1s['hws'] = np.sqrt(np.square(ultrasonic_turb_1s['U (m/s)']) + np.square(ultrasonic_turb_1s['V (m/s)']))
ultrasonic_turb_1s['wd'] =  (90 - np.degrees(np.arctan2(ultrasonic_turb_1s['V (m/s)'], -ultrasonic_turb_1s['U (m/s)']))) % 360


#Uï¼šé£ä»å—å¾€åŒ—ä¸º+å€¼    é£ä»åŒ—å¾€å—ä¸º-å€¼  Vï¼šé£ä»ä¸œå¾€è¥¿ä¸º+å€¼    é£ä»è¥¿å¾€ä¸œä¸º-å€¼

# å®šä¹‰å„é«˜åº¦å±‚çš„æ ¡æ­£ä¿¡æ¯ï¼ˆåŒ…æ‹¬U/Væ ¡æ­£å› å­å’Œé£å‘å¤¹è§’Î¸ï¼‰
correction_info = {
    '8m': {'factor': 1/np.cos(math.radians(6)), 'theta': 6},
    '16m': {'factor': 1/np.cos(math.radians(8)), 'theta': 8},
    '47m': {'factor': 1/np.cos(math.radians(4)), 'theta': 4},
    '80m': {'factor': 1/np.cos(math.radians(2)), 'theta': 2},
    '140m': {'factor': 1/np.cos(math.radians(2)), 'theta': 2},
    '200m': {'factor': 1/np.cos(math.radians(3)), 'theta': 3},
    '280m': {'factor': 1/np.cos(math.radians(1)), 'theta': 1}
}
def correct_wind_data(df, correction_info):
    """
    æ ¡æ­£é£é€Ÿå’Œé£å‘ï¼Œç»“æœä¿å­˜åˆ°æ–°åˆ—ï¼Œå¹¶éš”ç¦»åŸå§‹æ•°æ®
    
    å‚æ•°:
    df (pd.DataFrame): å¿…é¡»åŒ…å«åˆ— ['Height', 'U (m/s)', 'V (m/s)', 'wd']
    correction_info (dict): æ ¡æ­£å‚æ•°ï¼Œé”®ä¸ºé«˜åº¦å­—ç¬¦ä¸²ï¼ˆå¦‚ '8m'ï¼‰
    
    è¿”å›:
    pd.DataFrame: åŒ…å«æ ¡æ­£åˆ—çš„æ–°æ•°æ®æ¡†ï¼ŒåŸå§‹æ•°æ®æ¡†å®Œå…¨ä¸è¢«ä¿®æ”¹
    """
    # åˆ›å»ºæ•°æ®æ¡†çš„æ‹·è´ä»¥éš”ç¦»åŸå§‹æ•°æ®
    df = df.copy()
    
    # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
    required_columns = ['Height', 'U (m/s)', 'V (m/s)', 'wd']
    missing_cols = [col for col in required_columns if col not in df.columns]
    if missing_cols:
        raise ValueError(f"è¾“å…¥æ•°æ®æ¡†ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
    
    # ç¡®ä¿heightåˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹
    df['Height'] = df['Height'].astype(str).str.strip()  # åŒæ—¶å»é™¤é¦–å°¾ç©ºæ ¼
    
    # åŠ¨æ€æ˜ å°„å‚æ•°
    df['factor'] = df['Height'].map(lambda x: correction_info.get(x, {}).get('factor', 1.0))
    df['theta'] = df['Height'].map(lambda x: correction_info.get(x, {}).get('theta', 0.0))
    
    # æ ¡æ­£å¹¶ä¿å­˜åˆ°æ–°åˆ—
    df['U_corrected (m/s)'] = df['U (m/s)'] * df['factor']
    df['V_corrected (m/s)'] = df['V (m/s)'] * df['factor']
    df['wd_corrected'] = (df['wd'] + df['theta']) % 360
    
    # åˆ é™¤ä¸´æ—¶åˆ—
    df.drop(['factor', 'theta'], axis=1, inplace=True)
    
    return df

turb_calibrated_1s = correct_wind_data(ultrasonic_turb_1s,correction_info)
turb_calibrated_1s['timestamps'] = pd.to_datetime(turb_calibrated_1s['timestamps']) 
turb_calibrated_1s['timestamps'] = turb_calibrated_1s['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')
turb_calibrated_1s['timestamps'] = pd.to_datetime(turb_calibrated_1s['timestamps'], format='%Y/%m/%d %H:%M:%S')

turb_calibrated_1min = correct_wind_data(ultrasonic_turb_1min,correction_info)
turb_calibrated_1min['timestamps'] = pd.to_datetime(turb_calibrated_1min['timestamps']) 
turb_calibrated_1min['timestamps'] = turb_calibrated_1min['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')
turb_calibrated_1min = (turb_calibrated_1s.groupby(['Height', pd.Grouper(key='timestamps', freq='1min')]).mean()).reset_index()
turb_calibrated_1min['hws_corrected'] = np.sqrt(np.square(turb_calibrated_1min['U_corrected (m/s)']) + np.square(turb_calibrated_1min['V_corrected (m/s)']))
turb_calibrated_1min['wd_corrected'] =  (90 - np.degrees(np.arctan2(turb_calibrated_1min['V_corrected (m/s)'], -turb_calibrated_1min['U_corrected (m/s)']))) % 360
turb_calibrated_1min['Height'] = list(map(lambda x: float(x.strip('m')), turb_calibrated_1min['Height']))
turb_calibrated_1min['Height_plus_alt'] = turb_calibrated_1min['Height'] + Altitude
turb_calibrated_1min['Level (hPa)'] = pd.DataFrame(metpy.calc.height_to_pressure_std(turb_calibrated_1min['Height_plus_alt'].to_list() * units('m')).m)
turb_calibrated_1min['T (K)'] = turb_calibrated_1min['Temperature (C)'] +273.15
turb_calibrated_1min['rh'] = 100*goff_gratch_formula_dataframe(turb_calibrated_1min['Dew Point (C)']+273.15)/goff_gratch_formula_dataframe(turb_calibrated_1min['Temperature (C)']+273.15)
turb_calibrated_1min['q*10^-2'] = 100*0.622*goff_gratch_formula_dataframe(turb_calibrated_1min['Dew Point (C)']+273.15)/(turb_calibrated_1min['Pressure (hPa)']
                                                                                                                        -0.378*goff_gratch_formula_dataframe(turb_calibrated_1min['Dew Point (C)']+273.15))
turb_calibrated_1min = turb_calibrated_1min.sort_values(by=['timestamps', 'Height'], ascending=[True, True])
turb_calibrated_1min['rh'] = relative_humidity_from_dewpoint(turb_calibrated_1min['Temperature (C)'].values * units.degC, turb_calibrated_1min['Dew Point (C)'].values * units.degC).to('percent').magnitude


turb_calibrated_5min = (turb_calibrated_1s.groupby(['Height', pd.Grouper(key='timestamps', freq='5min')]).mean()).reset_index()
turb_calibrated_5min['hws_corrected'] = np.sqrt(np.square(turb_calibrated_5min['U_corrected (m/s)']) + np.square(turb_calibrated_5min['V_corrected (m/s)']))
turb_calibrated_5min['wd_corrected'] =  (90 - np.degrees(np.arctan2(turb_calibrated_5min['V_corrected (m/s)'], -turb_calibrated_5min['U_corrected (m/s)']))) % 360
turb_calibrated_5min['Height'] = list(map(lambda x: float(x.strip('m')), turb_calibrated_5min['Height']))
turb_calibrated_5min['Height_plus_alt'] = turb_calibrated_5min['Height'] + Altitude
turb_calibrated_5min['Level (hPa)'] = pd.DataFrame(metpy.calc.height_to_pressure_std(turb_calibrated_5min['Height_plus_alt'].to_list() * units('m')).m)
turb_calibrated_5min['rh'] = 100*goff_gratch_formula_dataframe(turb_calibrated_5min['Dew Point (C)']+273.15)/goff_gratch_formula_dataframe(turb_calibrated_5min['Temperature (C)']+273.15)
turb_calibrated_5min['q*10^-2'] = 100*0.622*goff_gratch_formula_dataframe(turb_calibrated_5min['Dew Point (C)']+273.15)/(turb_calibrated_5min['Pressure (hPa)'] 
                                                                                                                         - 0.378*goff_gratch_formula_dataframe(turb_calibrated_5min['Dew Point (C)']+273.15))
turb_calibrated_5min = turb_calibrated_5min.sort_values(by=['timestamps', 'Height'], ascending=[True, True])
turb_calibrated_5min['T (K)'] = turb_calibrated_5min['Temperature (C)'] +273.15
turb_calibrated_5min['rh'] = relative_humidity_from_dewpoint(turb_calibrated_5min['Temperature (C)'].values * units.degC, turb_calibrated_5min['Dew Point (C)'].values * units.degC).to('percent').magnitude


turb_calibrated_60min = (turb_calibrated_1s.groupby(['Height', pd.Grouper(key='timestamps', freq='60min')]).mean()).reset_index()
#turb_calibrated_60min = turb_calibrated_60min.set_index(['timestamps','Height'])
#turb_calibrated_60min = turb_calibrated_60min[['T (C)','rh','U (m/s)', 'V (m/s)','W (m/s)','q*10^-2']]
#turb_calibrated_60min['W (m/s)'] = 100 * turb_calibrated_60min['W (m/s)']
#turb_calibrated_60min = turb_calibrated_60min.rename(columns={'W (m/s)':  'W (10â»Â² {m/s})'})
turb_calibrated_60min['Height'] = list(map(lambda x: float(x.strip('m')), turb_calibrated_60min['Height']))
#turb_calibrated_60min = turb_calibrated_60min.reset_index()
turb_calibrated_60min['hws_corrected'] = np.sqrt(np.square(turb_calibrated_60min['U_corrected (m/s)']) + np.square(turb_calibrated_60min['V_corrected (m/s)']))
turb_calibrated_60min['wd_corrected'] =  (90 - np.degrees(np.arctan2(turb_calibrated_60min['V_corrected (m/s)'], -turb_calibrated_60min['U_corrected (m/s)']))) % 360
turb_calibrated_60min['T (K)'] = turb_calibrated_60min['Temperature (C)'] +273.15
turb_calibrated_60min['rh'] = relative_humidity_from_dewpoint(turb_calibrated_60min['Temperature (C)'].values * units.degC, turb_calibrated_60min['Dew Point (C)'].values * units.degC).to('percent').magnitude

def process_turb_data(df_input, full_time):
    results = []
    for height in df_input['Height'].unique():
        # æå–å½“å‰é«˜åº¦å±‚æ•°æ®
        df_height = df_input[df_input['Height'] == height].copy()
        
        # å¤„ç†æ—¶é—´ç´¢å¼•å¹¶é‡æ–°å¯¹é½
        df_height = (df_height
                     .set_index(pd.to_datetime(df_height['timestamps']))  # è½¬æ¢å¹¶è®¾ç´¢å¼•
                     .reindex(full_time))                                # é‡æ–°ç´¢å¼•
        
        # å¡«å……é«˜åº¦å¹¶é‡ç½®ç´¢å¼•
        df_height = (df_height
                     .assign(Height=height)                             # å¡«å……é«˜åº¦
                     .reset_index()
                     .rename(columns={'index': 'timestampss'}))          # é‡å‘½åæ—¶é—´åˆ—
        
        results.append(df_height)
    
    return pd.concat(results, ignore_index=True)

# ç”Ÿæˆå…¬å…±æ—¶é—´èŒƒå›´
full_time = pd.date_range(start='2024-06-05 00:00:00', end='2024-08-10 23:59:59', freq='1min')
turb_calibrated_1min = process_turb_data(turb_calibrated_1min, full_time)
# full_time = pd.date_range(start='2024-06-05 00:00:00', end='2024-08-10 23:59:59', freq='5min')
# turb_calibrated_5min = process_turb_data(turb_calibrated_5min, full_time)
full_time = pd.date_range(start='2024-06-05 00:00:00', end='2024-08-10 23:59:59', freq='60min')
turb_calibrated_60min = process_turb_data(turb_calibrated_60min, full_time)

turb_calibrated_1min = turb_calibrated_1min.drop(turb_calibrated_1min.columns[2], axis=1)
turb_calibrated_1min = turb_calibrated_1min.rename(columns={'timestampss': 'timestamps'})
# turb_calibrated_5min = turb_calibrated_5min.drop(turb_calibrated_5min.columns[2], axis=1)
# turb_calibrated_5min = turb_calibrated_5min.rename(columns={'timestampss': 'timestamps'})
turb_calibrated_60min = turb_calibrated_60min.drop(turb_calibrated_60min.columns[2], axis=1)
turb_calibrated_60min = turb_calibrated_60min.rename(columns={'timestampss': 'timestamps'})

turb_calibrated_1min['timestamps'] = turb_calibrated_1min['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')
#turb_calibrated_5min['timestamps'] = turb_calibrated_5min['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')
turb_calibrated_60min['timestamps'] = turb_calibrated_60min['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')

turb_calibrated_1min = turb_calibrated_1min.sort_values(
    by=['Height','timestamps'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True,True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
).dropna()
# turb_calibrated_5min = turb_calibrated_5min.sort_values(
#     by=['Height','timestamps'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
#     ascending=[True,True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
# )
turb_calibrated_60min = turb_calibrated_60min.sort_values(
    by=['Height','timestamps'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True,True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
).dropna()

# turb_calibrated_1s.to_csv(output_path + 'turb_1s_corrected.csv',index=False)

# with pd.ExcelWriter(output_path + 'ultrasonic_1_5_60.xlsx', date_format='yyyy/mm/dd hh:mm:ss') as writer:

#     turb_calibrated_1min.to_excel(writer, sheet_name='turb_1min_corrected', index=False)
        
#     turb_calibrated_5min.to_excel(writer, sheet_name='turb_5min_corrected', index=False)
    
#     turb_calibrated_60min.to_excel(writer, sheet_name='turb_60min_corrected', index=False)
    
#     workbook = writer.book  
#     for sheet_name in writer.sheets: 
#         worksheet = writer.sheets[sheet_name] 
#         worksheet.set_column('A:Z',  17.5)  # æ³¨æ„å‚æ•°æ ¼å¼ä¸º'A:A'è€Œé'A'



#####å¤„ç†å¾®æ³¢è¾å°„è®¡æ•°æ®#####
folder_path = 'E:\\Beijing2024\\MWR\\ahrh\\04-07\\'  # æŒ‡å®šæ–‡ä»¶å¤¹è·¯å¾„
ah = pd.read_excel(folder_path+'ah&rh_merged.xlsx',sheet_name="ah_data")
ah = ah.rename(columns={'timestamp':  'timestamps'})       
ah['timestamps'] = pd.to_datetime(ah['timestamps'])
ah.set_index('timestamps', inplace=True)
rh = pd.read_excel(folder_path+'ah&rh_merged.xlsx',sheet_name="rh_data")
rh = rh.rename(columns={'timestamp':  'timestamps'})
rh['timestamps'] = pd.to_datetime(rh['timestamps'])
rh.set_index('timestamps', inplace=True)

folder_path = 'E:\\Beijing2024\\MWR\\temp\\0702-0810\\'
temp = pd.read_excel(folder_path+'temp merged.xlsx',sheet_name="0702-0810")
temp = temp.rename(columns={'timestamp':  'timestamps'}) 
temp['timestamps'] = pd.to_datetime(temp['timestamps'], format='%Y/%m/%d %H:%M:%S')
temp.set_index('timestamps', inplace=True)

#####å¤„ç†å¾®æ³¢è¾å°„è®¡æ•°æ®#####
folder_path2 = 'E:\\Beijing2024\\MWR\\ahrh\\04-06\\'  # æŒ‡å®šæ–‡ä»¶å¤¹è·¯å¾„
ah2 = pd.read_excel(folder_path2+'ah&rh_merged.xlsx',sheet_name="ah_data")
ah2 = ah2.rename(columns={'timestamp':  'timestamps'})       
ah2['timestamps'] = pd.to_datetime(ah2['timestamps'])
ah2.set_index('timestamps', inplace=True)
rh2 = pd.read_excel(folder_path2+'ah&rh_merged.xlsx',sheet_name="rh_data")
rh2 = rh2.rename(columns={'timestamp':  'timestamps'})
rh2['timestamps'] = pd.to_datetime(rh2['timestamps'])
rh2.set_index('timestamps', inplace=True)

folder_path2 = 'E:\\Beijing2024\\MWR\\temp\\0605-0624åŒ—äº¬\\'
temp2 = pd.read_excel(folder_path2+'temp merged.xlsx',sheet_name="0605-0624")
temp2 = temp2.rename(columns={'timestamp':  'timestamps'}) 
temp2['timestamps'] = pd.to_datetime(temp2['timestamps'], format='%Y/%m/%d %H:%M:%S')
temp2.set_index('timestamps', inplace=True)

temp = pd.concat([temp,temp2], axis=0)
rh = pd.concat([rh,rh2], axis=0)


###############################################################
folder_path = 'E:\\Beijing2024\\MWR\\met\\'  # æŒ‡å®šè·¯å¾„
all_data = []  # åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨ä»¥å­˜å‚¨æ•°æ®å¸§

# éå†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
for filename in os.listdir(folder_path):
    file_path = os.path.join(folder_path, filename)  # è·å–æ–‡ä»¶å®Œæ•´è·¯å¾„
    # ä½¿ç”¨pandasè¯»å–æ–‡ä»¶ï¼Œè·³è¿‡å‰8è¡Œ
    data = pd.read_table(file_path, skiprows=19,delimiter=',', header=None, encoding='ANSI')
    all_data.append(data)  # å°†æ•°æ®å¸§æ·»åŠ åˆ°åˆ—è¡¨ä¸­
merged_data = pd.concat(all_data, ignore_index=True)

met=merged_data.iloc[:,:10]

met.columns = ['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second','rain_flag','pressure','temperature','RH']
met['Year'] = met['Year'].apply(lambda x: 2000 + x)

# å°†ä¸¤ä½æ•°å¹´ä»½è½¬æ¢ä¸ºå››ä½æ•°å¹´ä»½
# åˆ›å»ºä¸€ä¸ªæ–°çš„åˆ—æ¥å­˜å‚¨æ—¶é—´æˆ³
met['timestamp'] = pd.to_datetime(met[['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']])
met['timestamp'] = met['timestamp'] + pd.Timedelta(hours=8)

df1_met = pd.DataFrame(met)
df1_met['timestamp'] = pd.to_datetime(df1_met['timestamp'])
df1_met.set_index('timestamp', inplace=True)
met_1min=df1_met.resample('1min').mean().interpolate()
met_1min = met_1min[['pressure', 'temperature', 'RH']]
###################################################################

start_time = '2024-06-05 10:35:00'#temp.index.min()
end_time = '2024-08-10 11:58:59'#temp.index.max()

temp_1min = temp[(temp.index >= start_time)&(temp.index <= end_time)]
temp_1min_index = pd.date_range(start=start_time,end=end_time,freq='1min')  # '1T' è¡¨ç¤º1åˆ†é’Ÿ
combined_index = temp_1min.index.union(temp_1min_index).drop_duplicates().sort_values()
temp_1min_reindexed = temp_1min.reindex(combined_index) 
temp_1min_reindexed_interpolated = temp_1min_reindexed.interpolate(method='time') 
temp_1min_reindexed_interpolated.update(temp_1min) 
temp_1min_reindexed_interpolated_final = temp_1min_reindexed_interpolated.reset_index().rename(columns={'index':  'timestamps'})
temp_1min_reindexed_interpolated_final = temp_1min_reindexed_interpolated_final[temp_1min_reindexed_interpolated_final['timestamps'].dt.second  == 0].reset_index(drop=True)

rh_1min = rh[(rh.index >= start_time)&(rh.index <= end_time)]
rh_1min_index = pd.date_range(start=start_time,end=end_time,freq='1min')  # '1T' è¡¨ç¤º1åˆ†é’Ÿ
combined_index = rh_1min.index.union(rh_1min_index).drop_duplicates().sort_values()
rh_1min_reindexed = rh_1min.reindex(combined_index) 
rh_1min_reindexed_interpolated = rh_1min_reindexed.interpolate(method='time') 
rh_1min_reindexed_interpolated.update(rh_1min) 
rh_1min_reindexed_interpolated_final = rh_1min_reindexed_interpolated.reset_index().rename(columns={'index':  'timestamps'})
rh_1min_reindexed_interpolated_final = rh_1min_reindexed_interpolated_final[rh_1min_reindexed_interpolated_final['timestamps'].dt.second  == 0].reset_index(drop=True)

ah_1min = ah[(ah.index >= start_time)&(ah.index <= end_time)]
ah_1min_index = pd.date_range(start=start_time,end=end_time,freq='1min')  # '1T' è¡¨ç¤º1åˆ†é’Ÿ
combined_index = ah_1min.index.union(ah_1min_index).drop_duplicates().sort_values()
ah_1min_reindexed = ah_1min.reindex(combined_index) 
ah_1min_reindexed_interpolated = ah_1min_reindexed.interpolate(method='time') 
ah_1min_reindexed_interpolated.update(ah_1min) 
ah_1min_reindexed_interpolated_final = ah_1min_reindexed_interpolated.reset_index().rename(columns={'index':  'timestamps'})
ah_1min_reindexed_interpolated_final = ah_1min_reindexed_interpolated_final[ah_1min_reindexed_interpolated_final['timestamps'].dt.second  == 0].reset_index(drop=True)

met = met.set_index("timestamp")
met_1min = met[(met.index >= start_time)&(met.index <= end_time)]
met_1min_index = pd.date_range(start=start_time,end=end_time,freq='1min')  # '1T' è¡¨ç¤º1åˆ†é’Ÿ

temp_1min_reindexed_interpolated_final.set_index('timestamps', inplace=True)
temp_60min = temp_1min_reindexed_interpolated_final.resample('h').mean() 

es_1min = goff_gratch_formula_dataframe(temp_1min_reindexed_interpolated_final)
es_60min = goff_gratch_formula_dataframe(temp_60min)

rh_1min_reindexed_interpolated_final['timestamps'] = pd.to_datetime(rh_1min_reindexed_interpolated_final['timestamps'], format='%Y-%m-%d %H:%M:%S')
rh_1min_reindexed_interpolated_final.set_index('timestamps', inplace=True)
rh_60min = rh_1min_reindexed_interpolated_final.resample('h').mean()
met_60min = met_1min.resample('h').mean()

L = 0.0065  # æ¸©åº¦æ¢¯åº¦ (K/m)
g = 9.8017104   # é‡åŠ›åŠ é€Ÿåº¦ (m/s^2)
M = 0.0289644  # ç©ºæ°”å¹³å‡æ‘©å°”è´¨é‡ (kg/mol)
R = 8.3144598  # æ°”ä½“å¸¸æ•° (J/(molÂ·K))
def calculate_pressure_series(P0_series, T0_series, heights):
    
    pressures = np.zeros((len(P0_series), len(heights)))
    
    for i in range(len(P0_series)):
        P0 = P0_series[i]
        T0 = T0_series[i]
        pressures[i, :] = P0 * (1 - (L * heights) / T0) ** (g * M / (R * L))        
    return pressures

height_temp=[col for col in temp_1min.columns if isinstance(col, int)]
heights = np.array(height_temp)  # é«˜åº¦æ•°ç»„ (m)

p_60min = pd.DataFrame(calculate_pressure_series(met_60min['pressure'].to_numpy(), met_60min['temperature'].values, heights), 
                       index=met_60min.index, columns=heights)

p_1min = pd.DataFrame(calculate_pressure_series(met_1min['pressure'].to_numpy(), met_1min['temperature'].values, heights), 
                       index=met_1min.index, columns=heights)

common_timestamps_1min = met_1min.index.intersection(temp_1min_reindexed_interpolated_final.index)
common_timestamps_60min = met_1min.index.intersection(temp_60min.index)

e_1min=np.multiply(es_1min.loc[common_timestamps_1min] , rh_1min_reindexed_interpolated_final.loc[common_timestamps_1min]/100)
e_60min=np.multiply(es_60min.loc[common_timestamps_60min] , rh_60min.loc[common_timestamps_60min[0:119]]/100)




q_1min=0.622*e_1min/(p_1min.loc[common_timestamps_1min]-0.378*e_1min.loc[common_timestamps_1min])
q_60min=0.622*e_60min/(p_60min-0.378*e_60min)

Î¸_1min=temp_1min_reindexed_interpolated_final.loc[common_timestamps_1min]*(1000/p_1min.loc[common_timestamps_1min]) ** 0.28571428571428564
Î¸_60min=temp_60min.loc[common_timestamps_60min[0:119]]*(1000/p_60min) ** 0.28571428571428564

Î¸v_1min=Î¸_1min*(1+0.608*q_1min)
Î¸v_60min=temp_60min.loc[common_timestamps_60min[0:119]]*(1+0.608*q_60min)*(1000/p_60min) ** 0.28571428571428564

t_mwr_long = temp_1min_reindexed_interpolated_final.reset_index().melt(id_vars='timestamps',  var_name='height', value_name='T(K)') 
rh_mwr_long = rh_1min_reindexed_interpolated_final.reset_index().melt(id_vars='timestamps',  var_name='height', value_name='RH(%)') 
#ah_mwr_long = ah_1min_reindexed_interpolated_final.reset_index().melt(id_vars='timestamps',  var_name='height', value_name='ah({g/m-3})') 
q_mwr_long = q_1min.reset_index().melt(id_vars='index',  var_name='height', value_name='q(kg/kg)') 
t_mwr_long = t_mwr_long.set_index(['timestamps', 'height'])
q_mwr_long = q_mwr_long.rename(columns={'index':  'timestamps'})
q_mwr_long = q_mwr_long.set_index(['timestamps', 'height'])
rh_mwr_long = rh_mwr_long.set_index(['timestamps', 'height'])


# åªä¿ç•™æ—¶é—´å’Œé«˜åº¦ä¸¤åˆ— 
df_mwr = pd.concat([t_mwr_long,  rh_mwr_long, q_mwr_long], axis=1)
df_mwr = df_mwr.sort_index(level=[0, 1], ascending=[True, True])
df_mwr = df_mwr.loc[pd.IndexSlice["2024-06-05":"2024-08-11", :], :]
df_mwr = df_mwr.reset_index()
df_mwr['height_plus_alt'] = df_mwr['height'] + Altitude + 2
#df_mwr = df_mwr.reset_index().dropna()
df_mwr.columns = ['timestamps','height','T(K)','RH(%)','q(kg/kg)','height_plus_alt']
df_mwr['Level (hPa)'] = pd.DataFrame(metpy.calc.height_to_pressure_std(df_mwr['height_plus_alt'].to_list() * units('m')).m)
df_mwr['timestamps'] = pd.to_datetime(df_mwr['timestamps'])
df_mwr['BJT'] = df_mwr['timestamps'] + pd.Timedelta(hours=8)
df_mwr['BJT'] =df_mwr['BJT'].dt.strftime('%Y/%m/%d %H:%M:%S')
df_mwr['BJT'] = pd.to_datetime(df_mwr['BJT'])
df_mwr_5min = (df_mwr.groupby(['Level (hPa)', pd.Grouper(key='BJT', freq='5min')]).mean()).reset_index()

df_mwr_60min = (df_mwr.groupby(['Level (hPa)', pd.Grouper(key='BJT', freq='60min')]).mean()).reset_index()
df_mwr = df_mwr.set_index(['BJT', 'Level (hPa)'])
df_mwr = df_mwr.sort_index(level=[0,1])  # å…ˆæŒ‰æ—¶é—´æ’åºï¼Œå†æŒ‰é«˜åº¦æ’åº
df_mwr_60min = df_mwr_60min.set_index(['BJT', 'Level (hPa)'])
df_mwr_60min = df_mwr_60min.sort_index(level=[0,1])  # å…ˆæŒ‰æ—¶é—´æ’åºï¼Œå†æŒ‰é«˜åº¦æ’åº

temp_1min_reindexed_interpolated_final = temp_1min_reindexed_interpolated_final.reset_index()
temp_1min_reindexed_interpolated_final['timestamps'] = temp_1min_reindexed_interpolated_final['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')
rh_1min_reindexed_interpolated_final = rh_1min_reindexed_interpolated_final.reset_index()
rh_1min_reindexed_interpolated_final['timestamps'] = rh_1min_reindexed_interpolated_final['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')
ah_1min_reindexed_interpolated_final['timestamps'] = ah_1min_reindexed_interpolated_final['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')
q_1min = q_1min.reset_index()
q_1min = q_1min.rename(columns={'index':  'timestamps'})
q_1min['timestamps'] = q_1min['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')
Î¸v_1min = Î¸v_1min.reset_index()
Î¸v_1min = Î¸v_1min.rename(columns={'index':  'timestamps'})
Î¸v_1min['timestamps'] = Î¸v_1min['timestamps'].dt.strftime('%Y/%m/%d %H:%M:%S')

#turb_calibrated_1s.to_csv(output_path + 'turb_1s_corrected.csv',index=False)

# with pd.ExcelWriter(output_path + 'MWR Raw data-1min.xlsx', engine='openpyxl', date_format='yyyy/mm/dd hh:mm:ss') as writer:

#     temp_1min_reindexed_interpolated_final.to_excel(writer, sheet_name='T_1min', index=False)
    
#     rh_1min_reindexed_interpolated_final.to_excel(writer, sheet_name='rh_1min', index=False)
    
#     ah_1min_reindexed_interpolated_final.to_excel(writer, sheet_name='ah_1min', index=False)
    
#     q_1min.to_excel(writer, sheet_name='q_1min', index=False)
    
#     Î¸v_1min.to_excel(writer, sheet_name='Î¸v_1min', index=False)

#     for sheet_name in writer.sheets:
#         worksheet = writer.sheets[sheet_name]
#             # è®¾ç½®Aåˆ°Fåˆ—
#         for col in ['A']:
#             worksheet.column_dimensions[col].width = 20




###MWRæ’å€¼åˆ°å†åˆ†æ###
target_heights = np.arange(275, 1001, 25)
var_series = df_mwr_60min[['T(K)','RH(%)','q(kg/kg)']]

def interpolate_group_multi(group, target_heights):
    # æå–å½“å‰æ—¶é—´ç»„çš„é«˜åº¦å€¼
    heights = group.index.get_level_values('Level (hPa)').values
    
    # åˆå§‹åŒ–ç»“æœå®¹å™¨
    interpolated_data = {}
    
    # éå†æ¯ä¸ªå˜é‡è¿›è¡Œæ’å€¼
    for col in group.columns:
        values = group[col].values
        
        # æ•°æ®å¯¹é½æ€§æ£€æŸ¥
        if len(heights) != len(values):
            print(f"å˜é‡ {col} æ•°æ®é•¿åº¦ä¸åŒ¹é…: heights={len(heights)}, values={len(values)}")
            interpolated_data[col] = np.full(len(target_heights), np.nan)
            continue
        
        # å¤„ç†å¤šç»´æ•°ç»„ï¼ˆå¦‚é™ç»´ï¼‰
        if values.ndim > 1:
            values = values.squeeze()
        
        # åˆ›å»ºæ’å€¼å‡½æ•°ï¼ˆçº¿æ€§æ’å€¼ï¼‰
        try:
            f = interp1d(heights, values, kind='linear', fill_value='extrapolate')
            interpolated_values = f(target_heights)
        except Exception as e:
            print(f"å˜é‡ {col} æ’å€¼å¤±è´¥: {str(e)}")
            interpolated_values = np.full(len(target_heights), np.nan)
        
        interpolated_data[col] = interpolated_values
    
    # è½¬æ¢ä¸ºDataFrameå¹¶è®¾ç½®ç›®æ ‡é«˜åº¦ä¸ºç´¢å¼•
    return pd.DataFrame(interpolated_data, index=target_heights)
# æŒ‰æ—¶é—´åˆ†ç»„å¹¶åº”ç”¨æ’å€¼
interpolated_df = var_series.groupby('BJT').apply(
    interpolate_group_multi, 
    target_heights=target_heights
)
# å±•å¼€å¤šå±‚ç´¢å¼•
interpolated_df = interpolated_df.unstack(level=1).stack(level=0,future_stack=True)

# é‡ç½®ç´¢å¼•å¹¶å‘½ååˆ—
interpolated_df = interpolated_df.reset_index()

# è½¬æ¢æ ¸å¿ƒæ­¥éª¤
long_df = (
    interpolated_df.melt(
        id_vars=['BJT', 'level_1'],
        var_name='pressure_level',
        value_name='value'
    )
    .query("level_1 in ['T(K)', 'RH(%)', 'q(kg/kg)']")  # è¿‡æ»¤æœ‰æ•ˆå‚æ•°
    .assign(pressure_level=lambda x: x.pressure_level.astype(int))  # è½¬æ¢å‹åŠ›å±‚çº§ä¸ºæ•´å‹
    .pivot_table(
        index=['BJT', 'pressure_level'],
        columns='level_1',
        values='value'
    )
    .reset_index()
    .rename_axis(None, axis=1)  # æ¸…ç†åˆ—å
    .sort_values('BJT')
)
sorted_df = long_df.sort_values(
    by=['BJT', 'pressure_level'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True, True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)

sorted_df = sorted_df.rename(columns={'pressure_level':  'Level (hPa)'})

# è®¾ç½®åŒé‡ç´¢å¼•
sorted_df = sorted_df.set_index(['BJT', 'Level (hPa)'])
mwr_interp_to_reanalysis = sorted_df



####MWRæ’å€¼åˆ°é“å¡”#####
target_heights = tieta_1min['H(m)'].unique()
filtered_df_mwr = df_mwr.query("height <= 341")

starttime = pd.to_datetime('2024-06-05')
endtime = filtered_df_mwr.reset_index()['timestamps'].unique().max()
mwr_tobe_interp = filtered_df_mwr.loc[pd.IndexSlice[starttime:endtime, :], :]
    
starttime = pd.to_datetime('2024/06/05')
endtime = pd.to_datetime(filtered_df_mwr.reset_index()['timestamps'].unique().max(),format='%Y/%m/%d %H:%M:%S')
new_index = pd.to_datetime(tieta_1min.index.levels[0])
tieta_1min.index = tieta_1min.index.set_levels(new_index, level=0)
tieta_tobe_interp = tieta_1min.loc[pd.IndexSlice[starttime:endtime, :], :]
tieta_tobe_interp = tieta_tobe_interp.reset_index()
var_series = mwr_tobe_interp[['T(K)', 'RH(%)']]

def interpolate_group_multi(group, target_heights, mwr_tobe_interp):
    current_time = group.name
    try:
        # ç›´æ¥é€šè¿‡ç´¢å¼•è·å–å¯¹åº”æ—¶é—´çš„é«˜åº¦æ•°æ®
        heights_df = mwr_tobe_interp.loc[[current_time]].sort_values('Level (hPa)')
    except KeyError:
        print(f"æ—¶é—´ {current_time}: åœ¨tieta_tobe_interpä¸­æœªæ‰¾åˆ°å¯¹åº”é«˜åº¦æ•°æ®")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns)
    
    if len(heights_df) == 0:
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®ä¸ºç©º")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns)
    
    heights = heights_df['height'].values
    if len(heights) != len(group):
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®é•¿åº¦({len(heights)})ä¸å˜é‡æ•°æ®({len(group)})ä¸åŒ¹é…")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns)
    
    # æ’å€¼é€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰
    interpolated_data = {}
    for col in group.columns:
        values = group[col].values
        if np.isnan(values).all():
            interpolated_data[col] = np.full(len(target_heights), np.nan)
            continue
        try:
            f = interp1d(heights, values, kind='linear', bounds_error=False, fill_value='extrapolate')
            interpolated_values = f(target_heights)
        except Exception as e:
            print(f"å˜é‡ {col} åœ¨æ—¶é—´ {current_time} æ’å€¼å¤±è´¥: {str(e)}")
            interpolated_values = np.full(len(target_heights), np.nan)
        interpolated_data[col] = interpolated_values
    
    return pd.DataFrame(interpolated_data, index=target_heights).infer_objects(copy=False)
# æŒ‰æ—¶é—´åˆ†ç»„å¹¶åº”ç”¨æ’å€¼
interpolated_df = var_series.groupby('BJT').apply(
    interpolate_group_multi, 
    target_heights=target_heights,
    mwr_tobe_interp=mwr_tobe_interp
)
# å±•å¼€å¤šå±‚ç´¢å¼•
interpolated_df = interpolated_df.reset_index().rename(columns={'level_1':  'height_tieta'})

sorted_df = interpolated_df.sort_values(
    by=['BJT', 'height_tieta'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True, True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)
# è®¾ç½®åŒé‡ç´¢å¼•
sorted_df = sorted_df.set_index(['BJT', 'height_tieta'])
mwr_interp_to_tieta = sorted_df



####MWRæ’å€¼åˆ°è¶…å£°#####
target_heights = turb_calibrated_1min.reset_index()['Height'].unique()
#turb_calibrated_1min = turb_calibrated_1min.set_index(['timestamps','Height'])
filtered_df_mwr = df_mwr.query("height <= 280")

starttime = pd.to_datetime('2024-08-04')
endtime = filtered_df_mwr.reset_index()['timestamps'].unique().max()
mwr_tobe_interp = filtered_df_mwr.loc[pd.IndexSlice[starttime:endtime, :], :]

starttime = pd.to_datetime('2024/08/04')
endtime = pd.to_datetime(filtered_df_mwr.reset_index()['timestamps'].unique().max(),format='%Y/%m/%d %H:%M:%S')

# new_index = pd.to_datetime(turb_calibrated_1min.index.levels[0])
# turb_calibrated_1min.index = turb_calibrated_1min.index.set_levels(new_index, level=0)
# ultra_tobe_interp = turb_calibrated_1min.loc[pd.IndexSlice[starttime:endtime, :], :]
#tieta_tobe_interp = tieta_tobe_interp.reset_index()
var_series = mwr_tobe_interp[['T(K)', 'RH(%)','q(kg/kg)']]

def interpolate_group_multi(group, target_heights, mwr_tobe_interp):
    current_time = group.name
    try:
        # ç›´æ¥é€šè¿‡ç´¢å¼•è·å–å¯¹åº”æ—¶é—´çš„é«˜åº¦æ•°æ®
        heights_df = mwr_tobe_interp.loc[[current_time]].sort_values('Level (hPa)')
    except KeyError:
        print(f"æ—¶é—´ {current_time}: åœ¨tieta_tobe_interpä¸­æœªæ‰¾åˆ°å¯¹åº”é«˜åº¦æ•°æ®")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns)
    
    if len(heights_df) == 0:
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®ä¸ºç©º")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns)
    
    heights = heights_df['height'].values
    if len(heights) != len(group):
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®é•¿åº¦({len(heights)})ä¸å˜é‡æ•°æ®({len(group)})ä¸åŒ¹é…")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns)
    
    # æ’å€¼é€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰
    interpolated_data = {}
    for col in group.columns:
        values = group[col].values
        if np.isnan(values).all():
            interpolated_data[col] = np.full(len(target_heights), np.nan)
            continue
        try:
            f = interp1d(heights, values, kind='linear', bounds_error=False, fill_value='extrapolate')
            interpolated_values = f(target_heights)
        except Exception as e:
            print(f"å˜é‡ {col} åœ¨æ—¶é—´ {current_time} æ’å€¼å¤±è´¥: {str(e)}")
            interpolated_values = np.full(len(target_heights), np.nan)
        interpolated_data[col] = interpolated_values
    
    return pd.DataFrame(interpolated_data, index=target_heights).infer_objects(copy=False)
# æŒ‰æ—¶é—´åˆ†ç»„å¹¶åº”ç”¨æ’å€¼
interpolated_df = var_series.groupby('BJT').apply(
    interpolate_group_multi, 
    target_heights=target_heights,
    mwr_tobe_interp=mwr_tobe_interp
)
# å±•å¼€å¤šå±‚ç´¢å¼•

interpolated_df = interpolated_df.reset_index().rename(columns={'level_1':  'height_ultra'})

sorted_df = interpolated_df.sort_values(
    by=['BJT', 'height_ultra'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True, True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)
# è®¾ç½®åŒé‡ç´¢å¼•
sorted_df = sorted_df.set_index(['BJT', 'height_ultra'])
mwr_interp_to_ultra = sorted_df


mwr_interp_to_ultra = mwr_interp_to_ultra.reset_index()
mwr_interp_to_ultra['BJT'] = pd.to_datetime(mwr_interp_to_ultra['BJT'])

mwr_interp_to_ultra['BJT'] = mwr_interp_to_ultra['BJT'].dt.strftime('%Y/%m/%d %H:%M:%S')
mwr_interp_to_ultra = mwr_interp_to_ultra.sort_values(
    by=['height_ultra','BJT'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[False,True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)

mwr_interp_to_tieta = mwr_interp_to_tieta.reset_index()
mwr_interp_to_tieta['BJT'] = pd.to_datetime(mwr_interp_to_tieta['BJT'])

mwr_interp_to_tieta['BJT'] = mwr_interp_to_tieta['BJT'].dt.strftime('%Y/%m/%d %H:%M:%S')
mwr_interp_to_tieta = mwr_interp_to_tieta.sort_values(
    by=['height_tieta','BJT'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[False,True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)

mwr_interp_to_reanalysis = mwr_interp_to_reanalysis.reset_index()
mwr_interp_to_reanalysis['BJT'] = pd.to_datetime(mwr_interp_to_reanalysis['BJT'])
mwr_interp_to_reanalysis['BJT'] = mwr_interp_to_reanalysis['BJT'].dt.strftime('%Y/%m/%d %H:%M:%S')
mwr_interp_to_reanalysis = mwr_interp_to_reanalysis.sort_values(
    by=['Level (hPa)','BJT'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[False,True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)


# with pd.ExcelWriter(output_path + 'MWR Interpolation Results.xlsx', engine='openpyxl', date_format='yyyy/mm/dd hh:mm:ss') as writer:

#     mwr_interp_to_reanalysis.to_excel(writer, sheet_name='MWRæ’å€¼å†åˆ†æ', index=False)
    
#     mwr_interp_to_tieta.to_excel(writer, sheet_name='MWRæ’å€¼é“å¡”', index=False)
    
#     mwr_interp_to_ultra.to_excel(writer, sheet_name='MWRæ’å€¼è¶…å£°', index=False)

# # è°ƒæ•´åˆ—å®½ï¼ˆopenpyxlè¯­æ³•ï¼‰
#     for sheet_name in writer.sheets:
#         worksheet = writer.sheets[sheet_name]
#         worksheet.column_dimensions['A'].width = 20  # è®¾ç½®Aåˆ—å®½åº¦ä¸º20
#         worksheet.column_dimensions['B'].width = 20
#         worksheet.column_dimensions['F'].width = 20


###################################################å¤„ç†CMA-RAæ•°æ®é›†######################################
# ===================== é…ç½®åŒº =====================
PARENT_DIR = r"E:\Beijing2024\CMA-RA\Reanalysis"
OUTPUT_DIR = r"E:\Beijing2024\CMA-RA"
TARGET_LON = 116.3705
TARGET_LAT = 39.9745
EXCEL_NAME = f"CRA_Interp_tieta_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx"

# ==================== æ ¸å¿ƒå¤„ç†é€»è¾‘ ====================
data = {
    'å¸¸è§„å˜é‡': {},
    'ç‰¹æ®Šå˜é‡': {}
}

variable_dirs = [d for d in os.listdir(PARENT_DIR) 
                if os.path.isdir(os.path.join(PARENT_DIR, d))]

for variable_dir in variable_dirs:
    input_dir = os.path.join(PARENT_DIR, variable_dir)
    
    # ç²¾ç¡®ç­›é€‰.grib2æ–‡ä»¶ï¼ˆæ’é™¤.grib2.xxxæ–‡ä»¶ï¼‰
    files = sorted([
        f for f in glob(os.path.join(input_dir, "*"))
        if os.path.isfile(f) and os.path.splitext(f)[1].lower() == ".grib2"
    ])
    
    if not files:
        print(f"âš ï¸ æ— æœ‰æ•ˆGRIB2æ–‡ä»¶è·³è¿‡ç›®å½•: {variable_dir}")
        continue

    try:
        # ç¦ç”¨ç´¢å¼•æ–‡ä»¶å¹¶å¿½ç•¥è­¦å‘Š
        os.environ["CFGRIB_DISABLE_INDEX"] = "True"
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            
            # è·å–ç½‘æ ¼ä¿¡æ¯
            with xr.open_dataset(files[0], engine='cfgrib',decode_timedelta=True,
                               backend_kwargs={'filter_by_keys': {'typeOfLevel': 'isobaricInhPa'},
                                               'indexpath': False}
                               ) as ds:
                var_name = list(ds.data_vars)[0]
                print(f"âœ”ï¸ æ­£åœ¨å¤„ç†å˜é‡: {variable_dir} | è¯†åˆ«åˆ°å˜é‡å: {var_name}")
                
                unit = ds[var_name].attrs.get('units', '')
                
                # å¤„ç†åæ ‡
                lons = np.unique(ds.longitude.values)
                lats = np.unique(ds.latitude.values)
                lons.sort()
                lats.sort()

                # è¾¹ç•Œæ£€æŸ¥
                if not (lons[0] <= TARGET_LON <= lons[-1] and lats[0] <= TARGET_LAT <= lats[-1]):
                    print(f"ğŸš« åæ ‡è¶Šç•Œè·³è¿‡: {variable_dir}")
                    continue

                # è®¡ç®—ç½‘æ ¼ç´¢å¼•
                i_lon = max(0, np.searchsorted(lons, TARGET_LON, side='right')-1)
                i_lat = np.searchsorted(lats, TARGET_LAT, side='left')

    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {variable_dir} | {str(e)}")
        continue

    # ç¡®å®šç¼©æ”¾å› å­
    SCALE_FACTOR = 1e2 if variable_dir in [
        'Cloud Ice', 'Specific Humidity', 
        'Absolute Vorticity', 'Cloud Mixing Ratio'
    ] else 1
    print(f"ğŸ”„ åº”ç”¨ç¼©æ”¾å› å­: {SCALE_FACTOR} äºå˜é‡: {var_name}")

    # å•ä½å¤„ç†
    if var_name == 'r':  # ç›¸å¯¹æ¹¿åº¦ç‰¹æ®Šå¤„ç†
        scaled_unit = "%"
        col_name = f"rh ({scaled_unit})"
        #SCALE_FACTOR = 100  # å‡è®¾åŸå§‹æ•°æ®æ˜¯å°æ•°å½¢å¼ï¼ˆ0-1ï¼‰
    elif var_name == 't':
        scaled_unit = "K"
        col_name = f"Temp ({scaled_unit})"
    else:
        scaled_unit = f"10â»2 {unit}" if SCALE_FACTOR == 1e2 else unit
        col_name = f"{var_name} ({scaled_unit})" if unit else var_name


    # å¤„ç†æ‰€æœ‰æ–‡ä»¶
    for file in files:
        try:
            filename = os.path.basename(file)
            time_str = filename[27:37]  # æ ¹æ®å®é™…æ–‡ä»¶åè°ƒæ•´
            dt = datetime.strptime(time_str, "%Y%m%d%H")
            
            with xr.open_dataset(file, engine='cfgrib',decode_timedelta=True,
                               backend_kwargs={'filter_by_keys': {'typeOfLevel': 'isobaricInhPa'}}) as ds:
                for level in ds.isobaricInhPa.values:
                    grid_data = ds[var_name].sel(isobaricInhPa=level).values
                    
                    # åº”ç”¨ç¼©æ”¾å› å­
                    if SCALE_FACTOR != 1:
                        grid_data = grid_data * SCALE_FACTOR

                    # æ‰§è¡Œæ’å€¼
                    interpolator = RegularGridInterpolator(
                        (lats, lons), grid_data, bounds_error=False)
                    value = interpolator([[TARGET_LAT, TARGET_LON]])[0]
                    #value = np.nan_to_num(value,  nan=0)
                    
                    # ç¡®å®šå·¥ä½œè¡¨åˆ†ç»„
                    sheet_group = 'ç‰¹æ®Šå˜é‡' if variable_dir in [
                        #'Vertical velocity',   # å¯¹åº”wå˜é‡
                        'Cloud Ice',           # å¯¹åº”ciceå˜é‡ 
                        'Cloud Mixing Ratio'   # å¯¹åº”clwmrå˜é‡
                        ] else 'å¸¸è§„å˜é‡'

                    timestamp = dt.strftime("%Y-%m-%d %H:00")
                    level_key = (timestamp, int(level))
                    
                    # æ›´æ–°æ•°æ®ç»“æ„
                    if level_key not in data[sheet_group]:
                        data[sheet_group][level_key] = {
                            'timestamps': timestamp,
                            'Level (hPa)': int(level)
                        }
                    data[sheet_group][level_key][col_name] = value

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {filename} | {str(e)}")
            continue

    # æ‰“å°ç½‘æ ¼ä¿¡æ¯
    print(f"\nğŸ” å®Œæˆç›®å½•: {variable_dir}")
    print(f"ç½‘æ ¼åæ ‡ç´¢å¼•: ç»åº¦[{i_lon}:{i_lon+1}] çº¬åº¦[{i_lat-1}:{i_lat}]")
    print("å®é™…åæ ‡ç‚¹:")
    print(f"  NW: {lats[i_lat]:.4f}Â°N, {lons[i_lon]:.4f}Â°E")
    print(f"  NE: {lats[i_lat]:.4f}Â°N, {lons[i_lon+1]:.4f}Â°E")
    print(f"  SW: {lats[i_lat-1]:.4f}Â°N, {lons[i_lon]:.4f}Â°E")
    print(f"  SE: {lats[i_lat-1]:.4f}Â°N, {lons[i_lon+1]:.4f}Â°E\n")

# # ç”ŸæˆExcelæ–‡ä»¶
# with pd.ExcelWriter(os.path.join(output_path, EXCEL_NAME), engine='openpyxl', date_format='yyyy/mm/dd hh:mm:ss') as writer:
#     for sheet_name in ['å¸¸è§„å˜é‡', 'ç‰¹æ®Šå˜é‡']:
#         if not data[sheet_name]:
#             continue
            
#         df = pd.DataFrame(list(data[sheet_name].values())).fillna(0)
#         df = df.sort_values(by=['timestamps', 'Level (hPa)'], 
#                           ascending=[True, False])
        
#         if sheet_name == 'å¸¸è§„å˜é‡':  
            
#             #df['height(m)'] = pd.DataFrame(metpy.calc.geopotential_to_height(units.Quantity(df['gh (gpm)'].to_list(), 'm^2/s^2')).m)
#             df['vws(10â»Â² {m/s})'] = 100*pd.DataFrame((metpy.calc.vertical_velocity(df['w (Pa s**-1)'].to_list() * units('Pa/s'), 
#                                                                         df['Level (hPa)'].to_list() * units.hPa, 
#                                                                         df['Temp (K)'].to_list() * units.K,
#                                                                         (df['q (10â»2 kg kg**-1)']*10**-2).to_list() * units('kg/kg'))).m)
#             df['hws(m/s)'] = np.sqrt(np.square(df['u (m s**-1)']) + np.square(df['v (m s**-1)']))
#             df['hwd(deg)'] = np.mod(180+ np.degrees(np.arctan2(-df['u (m s**-1)'],-df['u (m s**-1)'])),360)

#             omega = df[['timestamps','Level (hPa)','w (Pa s**-1)']]
#             omega = omega.set_index(['timestamps','Level (hPa)'])
#             df = df.drop(columns=['w (Pa s**-1)'])
#             df['timestamps'] = pd.to_datetime(df['timestamps'])
#             df['BJT'] = df['timestamps'] + pd.Timedelta(hours=8)
#             df['BJT'] = df['BJT'].dt.strftime('%Y/%m/%d %H:%M:%S')
            
#             cols = ['timestamps','BJT', 'Level (hPa)'] + sorted(
#                 [c for c in df.columns if c not in ['timestamps','BJT', 'Level (hPa)']],
#                 key=lambda x: x.lower()
#             )
#             df = df[cols]
#             sheet1 = df
#         else:
            
#             df = df.set_index(['timestamps','Level (hPa)'])            
#             df = pd.concat([df,  omega], axis=1)
#             df = df.reset_index()
#             df['w (Pa s**-1)'] = df['w (Pa s**-1)'] *100
#             df.rename(columns={'w (Pa s**-1)': 'omega(10â»Â² {Pa/s})'}, inplace=True)   
#             df['timestamps'] = pd.to_datetime(df['timestamps'])
#             df['BJT'] = df['timestamps'] + pd.Timedelta(hours=8)
#             df['BJT'] = df['BJT'].dt.strftime('%Y/%m/%d %H:%M:%S')
#             cols = ['timestamps','BJT', 'Level (hPa)'] + sorted(
#                 [c for c in df.columns if c not in ['timestamps','BJT', 'Level (hPa)']],
#                 key=lambda x: x.lower()
#             )
#             df = df[cols]
            
#             sheet2 = df
#         # æ™ºèƒ½åˆ—æ’åº
#         cols = ['timestamps', 'Level (hPa)'] + sorted(
#             [c for c in df.columns if c not in ['timestamps', 'Level (hPa)']],
#             key=lambda x: x.replace('rh  (%)', 'A').lower()
#         )
#         df = df[cols]
        
#         df.to_excel(writer, sheet_name=sheet_name, index=False)
#         ws = writer.sheets[sheet_name]
#         ws.freeze_panes = 'A2'  # æ ¸å¿ƒä»£ç 
#         # è®¾ç½®æ ·å¼
#         #header_font = Font(color="FFFFFF", bold=True)
#         #header_fill = PatternFill("solid", fgColor="4F81BD")
        
#         # # è‡ªé€‚åº”åˆ—å®½
#         # # ==== ä¿®æ”¹åçš„åˆ—å®½è®¾ç½® ====
#         # for col_idx, col_name in enumerate(df.columns, 1):
#         #     col_letter = get_column_letter(col_idx)
            
#         #     if col_name == 'Level (hPa)':
#         #         ws.column_dimensions[col_letter].width = 10  # å›ºå®šå®½åº¦
#         #     else:
#         #         # è®¡ç®—è¯¥åˆ—æœ€å¤§å†…å®¹é•¿åº¦ï¼ˆè·³è¿‡æ ‡é¢˜ï¼‰
#         #         max_length = max(
#         #             len(str(cell)) for cell in df[col_name].astype(str)
#         #         )
#         #         adjusted_width = (max_length + 2) * 1.2
#         #         ws.column_dimensions[col_letter].width = adjusted_width
            
#         # for cell in ws[1]:
#         #     cell.font = header_font
#         #     cell.fill = header_fill

# print(f"\nâœ… å¤„ç†å®Œæˆ! ç»“æœæ–‡ä»¶å·²ä¿å­˜è‡³:\n{os.path.join(OUTPUT_DIR, EXCEL_NAME)}")

##############CRAv1.5æ’å€¼åˆ°47å’Œ280ç±³å¯¹åº”1000/975hPa##############

# åˆå§‹åŒ–ç»“æœå˜é‡,ç”Ÿæˆä¸¤ä¸ªè¡¨å­˜å‚¨å¤„ç†ç»“æœ
cra_regular = None
cra_special = None
omega = None

for sheet_name in ['å¸¸è§„å˜é‡', 'ç‰¹æ®Šå˜é‡']:
    if not data.get(sheet_name):
        continue  # å¦‚æœæ•°æ®ä¸ºç©ºåˆ™è·³è¿‡
        
    # åˆ›å»ºDataFrameå¹¶å¡«å……ç¼ºå¤±å€¼
    df = pd.DataFrame(list(data[sheet_name].values())).fillna(0)
    # æŒ‰æ—¶é—´æˆ³å’Œå±‚çº§æ’åº
    df = df.sort_values(by=['timestamps', 'Level (hPa)'], ascending=[True, False])
    
    if sheet_name == 'å¸¸è§„å˜é‡':
        # --------------- ç‰©ç†é‡è®¡ç®— ---------------
        # # ä½åŠ¿é«˜åº¦è½¬å‡ ä½•é«˜åº¦
        # df['height(m)'] = pd.DataFrame(
        #     metpy.calc.geopotential_to_height(
        #         units.Quantity(df['gh (gpm)'].to_list(), 'm^2/s^2')
        #     ).m
        # )
        
        # å‚ç›´é€Ÿåº¦è½¬æ¢ (éœ€è¦æ¸©åº¦ã€æ°”å‹ã€æ¯”æ¹¿æ•°æ®)
        df['vws(10â»Â² {m/s})'] = 100 * pd.DataFrame(
            metpy.calc.vertical_velocity(
                df['w (Pa s**-1)'].to_list() * units('Pa/s'),
                df['Level (hPa)'].to_list() * units.hPa,
                df['Temp (K)'].to_list() * units.K,
                (df['q (10â»2 kg kg**-1)'] * 1e-2).to_list() * units('kg/kg')
            ).m
        )
        
        # æ°´å¹³é£é€Ÿå’Œé£å‘
        df['hws(m/s)'] = np.sqrt(df['u (m s**-1)']**2 + df['v (m s**-1)']**2)
        df['hwd(deg)'] = np.mod(180+ np.degrees(np.arctan2(-df['u (m s**-1)'],-df['u (m s**-1)'])),360)
        
        # ä¿å­˜omegaå˜é‡ä¾›ç‰¹æ®Šå˜é‡è¡¨ä½¿ç”¨
        omega = df[['timestamps', 'Level (hPa)', 'w (Pa s**-1)']]
        omega = omega.set_index(['timestamps', 'Level (hPa)'])
        df = df.drop(columns=['w (Pa s**-1)'])
        
        # æ™ºèƒ½åˆ—æ’åº
        cols = ['timestamps', 'Level (hPa)'] + sorted(
            [c for c in df.columns if c not in ['timestamps', 'Level (hPa)']],
            key=lambda x: x.replace('rh  (%)', 'A').lower()  # ä¿æŒrhåˆ—é å‰
        )
        cra_regular = df[cols]
        
    else:  # å¤„ç†ç‰¹æ®Šå˜é‡
        # åˆå¹¶omegaå˜é‡
        df = df.set_index(['timestamps', 'Level (hPa)'])
        df = pd.concat([df, omega], axis=1).reset_index()
        
        # å•ä½è½¬æ¢å’Œé‡å‘½å
        df['w (Pa s**-1)'] *= 100
        df.rename(columns={'w (Pa s**-1)': 'omega(10â»Â² {Pa/s})'}, inplace=True)
        
        # åˆ—æ’åºï¼ˆé€»è¾‘åŒå¸¸è§„å˜é‡ï¼‰
        cols = ['timestamps', 'Level (hPa)'] + sorted(
            [c for c in df.columns if c not in ['timestamps', 'Level (hPa)']],
            key=lambda x: x.replace('rh  (%)', 'A').lower()
        )
        cra_special = df[cols]

target_heights = np.array([65,80,103,120,140,160,180,200,240,280,320])
cra_regular_tobe_interp = cra_regular.copy()
cra_regular_tobe_interp = cra_regular_tobe_interp.rename(columns={'Level (hPa)':  'pressure_level'})
cra_regular_tobe_interp = cra_regular_tobe_interp.query("pressure_level >= 950")
cra_regular_tobe_interp = cra_regular_tobe_interp.set_index(['timestamps','pressure_level'])
cra_regular_tobe_interp = cra_regular_tobe_interp[['Temp (K)','q (10â»2 kg kg**-1)','rh (%)','u (m s**-1)','v (m s**-1)', 'vws(10â»Â² {m/s})']]
cra_regular_tobe_interp = cra_regular_tobe_interp.reset_index()
cra_regular_tobe_interp['pressure_level'] =pd.to_numeric(cra_regular_tobe_interp['pressure_level'], errors='coerce', downcast='float')
cra_regular_tobe_interp['height_plus_alt'] = 1000*pd.DataFrame(metpy.calc.pressure_to_height_std(cra_regular_tobe_interp['pressure_level'].to_list() * units('hPa')).m) - Altitude



starttime = pd.to_datetime('2024-06-05')
endtime = cra_regular_tobe_interp.reset_index()['timestamps'].unique().max()
var_series = cra_regular_tobe_interp.reset_index()
var_series = var_series.sort_values(
    by=['timestamps', 'height_plus_alt'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True, True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)
def interpolate_group_multi(group, target_heights, cra_tobe_interp):
    current_time = group.name
    try:
        # ç›´æ¥é€šè¿‡ç´¢å¼•è·å–å¯¹åº”æ—¶é—´çš„é«˜åº¦æ•°æ®
        heights_df = cra_tobe_interp[cra_tobe_interp['timestamps'] == current_time].sort_values('height_plus_alt') 
    except KeyError:
        print(f"æ—¶é—´ {current_time}: åœ¨era5_tobe_interpä¸­æœªæ‰¾åˆ°å¯¹åº”é«˜åº¦æ•°æ®")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns)
    
    if len(heights_df) == 0:
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®ä¸ºç©º")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns)
    
    heights = heights_df['height_plus_alt'].values
    if len(heights) != len(group):
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®é•¿åº¦({len(heights)})ä¸å˜é‡æ•°æ®({len(group)})ä¸åŒ¹é…")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns)
    
    # æ’å€¼é€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰
    interpolated_data = {}
    for col in group.columns:
        values = group[col].values
        if np.isnan(values).all():
            interpolated_data[col] = np.full(len(target_heights), np.nan)
            continue
        try:
            f = interp1d(heights, values, kind='linear', bounds_error=False, fill_value='extrapolate')
            interpolated_values = f(target_heights)
        except Exception as e:
            print(f"å˜é‡ {col} åœ¨æ—¶é—´ {current_time} æ’å€¼å¤±è´¥: {str(e)}")
            interpolated_values = np.full(len(target_heights), np.nan)
        interpolated_data[col] = interpolated_values
    
    return pd.DataFrame(interpolated_data, index=target_heights).infer_objects(copy=False)
# æŒ‰æ—¶é—´åˆ†ç»„å¹¶åº”ç”¨æ’å€¼
interpolated_df = var_series.groupby('timestamps').apply(
    interpolate_group_multi, 
    target_heights=target_heights,
    cra_tobe_interp=var_series,
    include_groups=False
)

interpolated_df = interpolated_df.reset_index().rename(columns={'level_1':  'cra_tobe_interp'})
interpolated_df['hws(m/s)'] = np.sqrt(np.square(interpolated_df['u (m s**-1)']) + np.square(interpolated_df['v (m s**-1)']))
interpolated_df['hwd(deg)'] = np.degrees(np.arctan2(-interpolated_df['u (m s**-1)'], -interpolated_df['v (m s**-1)'])) % 360

sorted_df = interpolated_df.sort_values(
    by=['timestamps', 'height_plus_alt'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True, True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)

# è®¾ç½®åŒé‡ç´¢å¼•
sorted_df = sorted_df.set_index(['timestamps', 'height_plus_alt'])
CRA_interp_to_65_80_280 = sorted_df[['Temp (K)','q (10â»2 kg kg**-1)','rh (%)','hws(m/s)','hwd(deg)', 'vws(10â»Â² {m/s})']]
CRA_interp_to_65_80_280 = CRA_interp_to_65_80_280.reset_index()
CRA_interp_to_65_80_280['timestamps'] =  pd.to_datetime(CRA_interp_to_65_80_280['timestamps'])
CRA_interp_to_65_80_280['BJT'] = CRA_interp_to_65_80_280['timestamps'] + pd.Timedelta(hours=8)
CRA_interp_to_65_80_280['BJT'] =  pd.to_datetime(CRA_interp_to_65_80_280['BJT'])
CRA_interp_to_65_80_280['BJT'] = CRA_interp_to_65_80_280['BJT'].dt.strftime('%Y/%m/%d %H:%M:%S')


target_heights = temp_1min_reindexed_interpolated_final.set_index("timestamps").columns
cra_regular_tobe_interp = cra_regular.copy()
cra_regular_tobe_interp = cra_regular_tobe_interp.rename(columns={'Level (hPa)':  'pressure_level'})
cra_regular_tobe_interp = cra_regular_tobe_interp.query("pressure_level >= 250")
cra_regular_tobe_interp = cra_regular_tobe_interp.set_index(['timestamps','pressure_level'])
cra_regular_tobe_interp = cra_regular_tobe_interp[['Temp (K)','q (10â»2 kg kg**-1)','rh (%)','u (m s**-1)','v (m s**-1)', 'vws(10â»Â² {m/s})']]
cra_regular_tobe_interp = cra_regular_tobe_interp.reset_index()
cra_regular_tobe_interp['pressure_level'] =pd.to_numeric(cra_regular_tobe_interp['pressure_level'], errors='coerce', downcast='float')
cra_regular_tobe_interp['height_plus_alt'] = 1000*pd.DataFrame(metpy.calc.pressure_to_height_std(cra_regular_tobe_interp['pressure_level'].to_list() * units('hPa')).m) - Altitude

starttime = pd.to_datetime('2024-08-05')
endtime = cra_regular_tobe_interp.reset_index()['timestamps'].unique().max()
var_series = cra_regular_tobe_interp
var_series = var_series.sort_values(
    by=['timestamps', 'height_plus_alt'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True, True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)
def interpolate_group_multi(group, target_heights, cra_tobe_interp):
    current_time = group.name
    try:
        # æ·»åŠ æ˜ç¡®çš„ç±»å‹è½¬æ¢
        heights_df = cra_tobe_interp[cra_tobe_interp['timestamps'] == current_time].sort_values('height_plus_alt')
        heights_df = heights_df.astype({'height_plus_alt': np.float64})  # ç¡®ä¿æ•°å€¼ç±»å‹
    except KeyError:
        print(f"æ—¶é—´ {current_time}: åœ¨era5_tobe_interpä¸­æœªæ‰¾åˆ°å¯¹åº”é«˜åº¦æ•°æ®")
        # æ˜ç¡®æŒ‡å®šæ•°æ®ç±»å‹ä¸ºfloat
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns).astype(np.float64)
    
    if len(heights_df) == 0:
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®ä¸ºç©º")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns).astype(np.float64)
    
    heights = heights_df['height_plus_alt'].values.astype(np.float64)  # å¼ºåˆ¶ç±»å‹è½¬æ¢
    if len(heights) != len(group):
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®é•¿åº¦({len(heights)})ä¸å˜é‡æ•°æ®({len(group)})ä¸åŒ¹é…")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns).astype(np.float64)
    
    interpolated_data = {}
    for col in group.columns:
        # ç¡®ä¿è¾“å…¥æ•°æ®ä¸ºæµ®ç‚¹ç±»å‹
        values = group[col].astype(np.float64).values
        if np.isnan(values).all():
            # åˆ›å»ºæ•°ç»„æ—¶æŒ‡å®šdtype
            interpolated_data[col] = np.full(len(target_heights), np.nan, dtype=np.float64)
            continue
        try:
            f = interp1d(heights, values, kind='linear', bounds_error=False, fill_value=np.nan)
            interpolated_values = f(target_heights.astype(np.float64))  # ç¡®ä¿ç›®æ ‡é«˜åº¦ä¸ºæ•°å€¼ç±»å‹
        except Exception as e:
            print(f"å˜é‡ {col} åœ¨æ—¶é—´ {current_time} æ’å€¼å¤±è´¥: {str(e)}")
            interpolated_values = np.full(len(target_heights), np.nan, dtype=np.float64)
        interpolated_data[col] = interpolated_values
    
    # åˆ›å»ºDataFrameæ—¶å¼ºåˆ¶ç±»å‹ä¸ºfloat
    return pd.DataFrame(interpolated_data, index=target_heights.astype(np.float64)).astype(np.float64)
# æŒ‰æ—¶é—´åˆ†ç»„å¹¶åº”ç”¨æ’å€¼
interpolated_df = var_series.groupby('timestamps').apply(
    interpolate_group_multi, 
    target_heights=target_heights,
    cra_tobe_interp=var_series,
    include_groups=False
)

interpolated_df = interpolated_df.reset_index().rename(columns={'level_1':  'cra_tobe_interp'})
interpolated_df['hws(m/s)'] = np.sqrt(np.square(interpolated_df['u (m s**-1)']) + np.square(interpolated_df['v (m s**-1)']))
interpolated_df['hwd(deg)'] = np.degrees(np.arctan2(-interpolated_df['u (m s**-1)'], -interpolated_df['v (m s**-1)'])) % 360

sorted_df = interpolated_df.sort_values(
    by=['timestamps', 'height_plus_alt'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True, True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)

# è®¾ç½®åŒé‡ç´¢å¼•
sorted_df = sorted_df.set_index(['timestamps', 'height_plus_alt'])
CRA_interp_to_MWR = sorted_df[['pressure_level', 'Temp (K)', 'q (10â»2 kg kg**-1)',
       'rh (%)', 'u (m s**-1)', 'v (m s**-1)', 'vws(10â»Â² {m/s})', 'hws(m/s)',
       'hwd(deg)']]
CRA_interp_to_MWR = CRA_interp_to_MWR.reset_index()
CRA_interp_to_MWR['timestamps'] =  pd.to_datetime(CRA_interp_to_MWR['timestamps'])
CRA_interp_to_MWR['BJT'] = CRA_interp_to_MWR['timestamps'] + pd.Timedelta(hours=8)
CRA_interp_to_MWR['BJT'] =  pd.to_datetime(CRA_interp_to_MWR['BJT'])
CRA_interp_to_MWR['BJT'] = CRA_interp_to_MWR['BJT'].dt.strftime('%Y/%m/%d %H:%M:%S')


target_heights = np.arange(50, 2776, 25)
cra_regular_tobe_interp = cra_regular.copy()
cra_regular_tobe_interp = cra_regular_tobe_interp.rename(columns={'Level (hPa)':  'pressure_level'})
cra_regular_tobe_interp = cra_regular_tobe_interp.query("pressure_level >= 250")
cra_regular_tobe_interp = cra_regular_tobe_interp.set_index(['timestamps','pressure_level'])
cra_regular_tobe_interp = cra_regular_tobe_interp[['Temp (K)','q (10â»2 kg kg**-1)','rh (%)','u (m s**-1)','v (m s**-1)', 'vws(10â»Â² {m/s})']]
cra_regular_tobe_interp = cra_regular_tobe_interp.reset_index()
cra_regular_tobe_interp['pressure_level'] =pd.to_numeric(cra_regular_tobe_interp['pressure_level'], errors='coerce', downcast='float')
cra_regular_tobe_interp['height_plus_alt'] = 1000*pd.DataFrame(metpy.calc.pressure_to_height_std(cra_regular_tobe_interp['pressure_level'].to_list() * units('hPa')).m) - Altitude

starttime = pd.to_datetime('2024-08-05')
endtime = cra_regular_tobe_interp.reset_index()['timestamps'].unique().max()
var_series = cra_regular_tobe_interp
var_series = var_series.sort_values(
    by=['timestamps', 'height_plus_alt'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True, True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)
def interpolate_group_multi(group, target_heights, cra_tobe_interp):
    current_time = group.name
    try:
        # æ·»åŠ æ˜ç¡®çš„ç±»å‹è½¬æ¢
        heights_df = cra_tobe_interp[cra_tobe_interp['timestamps'] == current_time].sort_values('height_plus_alt')
        heights_df = heights_df.astype({'height_plus_alt': np.float64})  # ç¡®ä¿æ•°å€¼ç±»å‹
    except KeyError:
        print(f"æ—¶é—´ {current_time}: åœ¨era5_tobe_interpä¸­æœªæ‰¾åˆ°å¯¹åº”é«˜åº¦æ•°æ®")
        # æ˜ç¡®æŒ‡å®šæ•°æ®ç±»å‹ä¸ºfloat
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns).astype(np.float64)
    
    if len(heights_df) == 0:
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®ä¸ºç©º")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns).astype(np.float64)
    
    heights = heights_df['height_plus_alt'].values.astype(np.float64)  # å¼ºåˆ¶ç±»å‹è½¬æ¢
    if len(heights) != len(group):
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®é•¿åº¦({len(heights)})ä¸å˜é‡æ•°æ®({len(group)})ä¸åŒ¹é…")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns).astype(np.float64)
    
    interpolated_data = {}
    for col in group.columns:
        # ç¡®ä¿è¾“å…¥æ•°æ®ä¸ºæµ®ç‚¹ç±»å‹
        values = group[col].astype(np.float64).values
        if np.isnan(values).all():
            # åˆ›å»ºæ•°ç»„æ—¶æŒ‡å®šdtype
            interpolated_data[col] = np.full(len(target_heights), np.nan, dtype=np.float64)
            continue
        try:
            f = interp1d(heights, values, kind='linear', bounds_error=False, fill_value=np.nan)
            interpolated_values = f(target_heights.astype(np.float64))  # ç¡®ä¿ç›®æ ‡é«˜åº¦ä¸ºæ•°å€¼ç±»å‹
        except Exception as e:
            print(f"å˜é‡ {col} åœ¨æ—¶é—´ {current_time} æ’å€¼å¤±è´¥: {str(e)}")
            interpolated_values = np.full(len(target_heights), np.nan, dtype=np.float64)
        interpolated_data[col] = interpolated_values
    
    # åˆ›å»ºDataFrameæ—¶å¼ºåˆ¶ç±»å‹ä¸ºfloat
    return pd.DataFrame(interpolated_data, index=target_heights.astype(np.float64)).astype(np.float64)
# æŒ‰æ—¶é—´åˆ†ç»„å¹¶åº”ç”¨æ’å€¼
interpolated_df = var_series.groupby('timestamps').apply(
    interpolate_group_multi, 
    target_heights=target_heights,
    cra_tobe_interp=var_series,
    include_groups=False
)

interpolated_df = interpolated_df.reset_index().rename(columns={'level_1':  'cra_tobe_interp'})
interpolated_df['hws(m/s)'] = np.sqrt(np.square(interpolated_df['u (m s**-1)']) + np.square(interpolated_df['v (m s**-1)']))
interpolated_df['hwd(deg)'] = np.degrees(np.arctan2(-interpolated_df['u (m s**-1)'], -interpolated_df['v (m s**-1)'])) % 360

sorted_df = interpolated_df.sort_values(
    by=['timestamps', 'height_plus_alt'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True, True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)

# è®¾ç½®åŒé‡ç´¢å¼•
sorted_df = sorted_df.set_index(['timestamps', 'height_plus_alt'])
CRA_interp_to_WL = sorted_df[['pressure_level', 'Temp (K)', 'q (10â»2 kg kg**-1)',
       'rh (%)', 'u (m s**-1)', 'v (m s**-1)', 'vws(10â»Â² {m/s})', 'hws(m/s)',
       'hwd(deg)']]
CRA_interp_to_WL = CRA_interp_to_WL.reset_index()
CRA_interp_to_WL['timestamps'] =  pd.to_datetime(CRA_interp_to_WL['timestamps'])
CRA_interp_to_WL['BJT'] = CRA_interp_to_WL['timestamps'] + pd.Timedelta(hours=8)
CRA_interp_to_WL['BJT'] =  pd.to_datetime(CRA_interp_to_WL['BJT'])
CRA_interp_to_WL['BJT'] = CRA_interp_to_WL['BJT'].dt.strftime('%Y/%m/%d %H:%M:%S')
# with pd.ExcelWriter(output_path + 'CRAæ’åˆ°é“å¡”ã€MWRå’ŒWL.xlsx', engine='openpyxl', date_format='yyyy/mm/dd hh:mm:ss') as writer:

#     CRA_interp_to_65_80_280.to_excel(writer, sheet_name='CRA_to_65_80_280', index=False)
#     # for sheet_name in writer.sheets:
#     #     worksheet = writer.sheets[sheet_name]
#     #         # è®¾ç½®Aåˆ°Fåˆ—
#     #     for col in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']:
#     #         worksheet.column_dimensions[col].width = 20
    
#     CRA_interp_to_WL.dropna().to_excel(writer, sheet_name='CRA_to_WL', index=False)
#     CRA_interp_to_MWR.dropna().to_excel(writer, sheet_name='CRA_to_MWR', index=False)
#     #CRA_interp_to_ultra.dropna().to_excel(writer, sheet_name='CRA_to_ultra', index=False)
#     for sheet_name in writer.sheets:
#         worksheet = writer.sheets[sheet_name]
#             # è®¾ç½®Aåˆ°Fåˆ—
#         for col in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']:
#             worksheet.column_dimensions[col].width = 20

Altitude = 49
# ###############################ERA5æå–å¹¶æ’å€¼æ–°ç‰ˆ#######################################
# # 1. åŠ è½½æ•°æ®å¹¶ç­›é€‰å˜é‡
# ds = xr.open_dataset(r'E:\Beijing2024\ERA5\0804-0811 hourly pressure level.nc')
# target_vars = ['q', 'u', 'v', 'w', 't', 'r']
# variables = [var for var in ds.data_vars if var in target_vars]

# # 2. ç›®æ ‡åæ ‡
# target_lon = 116.3705
# target_lat = 39.9745

# # 3. è·å–åŸå§‹ç½‘æ ¼ä¿¡æ¯
# raw_lats = ds.latitude.values  # ERA5çº¬åº¦é€šå¸¸ä¸ºé™åº
# raw_lons = ds.longitude.values

# # 4. è‡ªåŠ¨å®šä½åŒ…å›´ç½‘æ ¼ç‚¹ ------------------------------------------------------
# # å¯»æ‰¾æœ€è¿‘çš„4ä¸ªæ ¼ç‚¹ç´¢å¼•
# lat_idx = np.searchsorted(raw_lats[::-1], target_lat)  # å¤„ç†é™åºçº¬åº¦
# lon_idx = np.searchsorted(raw_lons, target_lon)

# # ç¡®å®šåŒ…å›´æ ¼ç‚¹çš„ç´¢å¼•
# if lat_idx == 0 or lat_idx == len(raw_lats):
#     raise ValueError("ç›®æ ‡çº¬åº¦è¶…å‡ºèŒƒå›´")
# if lon_idx == 0 or lon_idx == len(raw_lons):
#     raise ValueError("ç›®æ ‡ç»åº¦è¶…å‡ºèŒƒå›´")

# # è·å–å®é™…å‚ä¸æ’å€¼çš„å››ä¸ªæ ¼ç‚¹ç´¢å¼•ï¼ˆåŸå§‹æ•°æ®ç´¢å¼•ï¼‰
# surrounding_points = [
#     (lat_idx-1, lon_idx-1),  # è¥¿å—
#     (lat_idx-1, lon_idx),    # ä¸œå—
#     (lat_idx, lon_idx-1),    # è¥¿åŒ—
#     (lat_idx, lon_idx)       # ä¸œåŒ—
# ]

# # è½¬æ¢ä¸ºåŸå§‹çº¬åº¦ç´¢å¼•ï¼ˆå› çº¬åº¦é™åºæ’åˆ—çš„ç‰¹æ®Šå¤„ç†ï¼‰
# adjusted_points = [
#     (len(raw_lats)-1 - i, j) for i, j in surrounding_points
# ]

# # 5. è¾“å‡ºç½‘æ ¼ç‚¹ä¿¡æ¯ ----------------------------------------------------------
# print("æ’å€¼ä½¿ç”¨çš„ç½‘æ ¼ç‚¹ä¿¡æ¯ï¼š")
# print(f"ç›®æ ‡åæ ‡ï¼š{target_lat}Â°N, {target_lon}Â°E")
# print("åŒ…å›´ç‚¹åŸå§‹ç´¢å¼•ï¼ˆlat_index, lon_indexï¼‰åŠåæ ‡ï¼š")

# for i, (lat_i, lon_i) in enumerate(adjusted_points, 1):
#     lat_val = raw_lats[lat_i].item()
#     lon_val = raw_lons[lon_i].item()
#     print(f"ç‚¹{i}ï¼š({lat_i}, {lon_i}) -> {lat_val}Â°N, {lon_val}Â°E")

# # 6. æ•°æ®é¢„å¤„ç† --------------------------------------------------------------
# # åè½¬çº¬åº¦æ•°æ®ä»¥é€‚åº”RegularGridInterpolatorè¦æ±‚
# lats = raw_lats[::-1]  # ç°åœ¨å˜ä¸ºå‡åº
# lons = raw_lons

# # åˆ›å»ºæ—¶ç©ºç´¢å¼•
# times = ds.valid_time.values
# levels = ds.pressure_level.values
# index = pd.MultiIndex.from_product([times, levels], 
#                                   names=["valid_time", "pressure_level"])

# # åˆå§‹åŒ–ç»“æœDataFrame
# final_df = pd.DataFrame({
#     "valid_time": index.get_level_values("valid_time"),
#     "pressure_level": index.get_level_values("pressure_level")
# })

# # 7. æ‰¹é‡æ’å€¼æ ¸å¿ƒé€»è¾‘ --------------------------------------------------------
# for var in variables:
#     # è½¬ç½®ç»´åº¦å¹¶åè½¬çº¬åº¦é¡ºåº
#     data = ds[var].transpose("latitude", "longitude", "valid_time", "pressure_level").values[::-1]
    
#     # åˆ›å»ºæ’å€¼å™¨
#     interpolator = RegularGridInterpolator(
#         (lats, lons),
#         data,
#         method="linear",
#         bounds_error=False,
#         fill_value=np.nan
#     )
    
#     # æ‰§è¡Œæ’å€¼
#     result = interpolator([[target_lat, target_lon]]).squeeze(0)
#     final_df[var] = result.ravel()

# final_df['vws(10â»Â² {m/s})'] = pd.DataFrame((metpy.calc.vertical_velocity(final_df['w'].to_list() * units('Pa/s'), 
#                                                             final_df['pressure_level'].to_list() * units.hPa, 
#                                                             final_df['t'].to_list() * units.K,mixing_ratio = 0
#                                                             )).m)#(final_df['q']).to_list() * units('kg/kg')
# final_df['hws(m/s)'] = np.sqrt(np.square(final_df['u']) + np.square(final_df['v']))
# final_df['hwd(deg)'] = np.mod(180+ np.degrees(np.arctan2(final_df['u'],final_df['v'])),360)
# final_df['height'] = 1000*pd.DataFrame(metpy.calc.pressure_to_height_std(final_df['pressure_level'].to_list() * units('hPa')).m) - Altitude
# #å¯¹åº”æŒ‡å®šç‚¹çš„above ground level
# # 8. è¾“å‡ºéªŒè¯ ---------------------------------------------------------------
# print("\næ’å€¼ç»“æœç¤ºä¾‹ï¼š")
# print(final_df.head())
# print("\næ•°æ®ç»“æ„éªŒè¯ï¼š")
# print(f"æ€»è¡Œæ•°ï¼š{len(final_df)} (æ—¶é—´ç‚¹{len(times)} Ã— æ°”å‹å±‚{len(levels)})")
# print(f"ä¿ç•™å˜é‡ï¼š{variables}")
# ERA5_interp_BJ = final_df
# ERA5_interp_BJ['valid_time'] =  pd.to_datetime(ERA5_interp_BJ['valid_time'])
# ERA5_interp_BJ['BJT'] = ERA5_interp_BJ['valid_time'] + pd.Timedelta(hours=8)
# ERA5_interp_BJ['BJT'] =  pd.to_datetime(ERA5_interp_BJ['BJT'])
# ERA5_interp_BJ['BJT'] = ERA5_interp_BJ['BJT'].dt.strftime('%Y/%m/%d %H:%M:%S')

# cols = ['BJT', 'valid_time','pressure_level'] + sorted(
#     [c for c in ERA5_interp_BJ.columns if c not in ['BJT','valid_time', 'pressure_level']],
#     key=lambda x: x.lower()
# )
# ERA5_interp_BJ = ERA5_interp_BJ[cols]


import os
import xarray as xr
import numpy as np
import pandas as pd
from scipy.interpolate import RegularGridInterpolator
import metpy.calc as mpcalc
from metpy.units import units

# ================== åŸºæœ¬è®¾ç½® ==================
data_dir = r'E:\Beijing2024\ERA5'

# åªéå†å½“å‰ç›®å½•ä¸‹çš„ .nc æ–‡ä»¶ï¼Œä¸è¿›å…¥å­æ–‡ä»¶å¤¹
files = [
    f for f in os.listdir(data_dir)
    if os.path.isfile(os.path.join(data_dir, f)) and f.endswith('.nc')
]

target_lon = 116.3705
target_lat = 39.9745

target_vars = ['q', 'u', 'v', 'w', 't', 'r']  # æŒ‰ä½ åŸæ¥è®¾å®š
Altitude = 49.0  # ä¸¾ä¾‹ï¼šåœ°é¢é«˜åº¦ï¼ˆmï¼‰ï¼Œä½ æŒ‰çœŸå®é«˜åº¦æ”¹

all_dfs = []  # å­˜å‚¨æ¯ä¸ªæ–‡ä»¶çš„ç»“æœï¼Œæœ€åå† concat

for file in files:
    file_path = os.path.join(data_dir, file)
    print(f"æ­£åœ¨å¤„ç†æ–‡ä»¶ï¼š{file_path}")

    # 1. æ‰“å¼€æ•°æ®é›†
    ds = xr.open_dataset(file_path)
    variables = [var for var in ds.data_vars if var in target_vars]

    # 2. åŸå§‹ç»çº¬åº¦
    raw_lats = ds.latitude.values  # é€šå¸¸ä¸ºé™åº
    raw_lons = ds.longitude.values

    # 3. å®šä½åŒ…å›´ç›®æ ‡ç‚¹çš„ç½‘æ ¼ç´¢å¼•
    lat_idx = np.searchsorted(raw_lats[::-1], target_lat)
    lon_idx = np.searchsorted(raw_lons, target_lon)

    if lat_idx == 0 or lat_idx == len(raw_lats):
        raise ValueError("ç›®æ ‡çº¬åº¦è¶…å‡ºèŒƒå›´")
    if lon_idx == 0 or lon_idx == len(raw_lons):
        raise ValueError("ç›®æ ‡ç»åº¦è¶…å‡ºèŒƒå›´")

    surrounding_points = [
        (lat_idx-1, lon_idx-1),
        (lat_idx-1, lon_idx),
        (lat_idx,   lon_idx-1),
        (lat_idx,   lon_idx),
    ]
    adjusted_points = [
        (len(raw_lats)-1 - i, j) for i, j in surrounding_points
    ]

    # 4. ä¸ºæ’å€¼å‡†å¤‡â€œå‡åºçº¬åº¦â€
    lats = raw_lats[::-1]
    lons = raw_lons

    # 5. æ—¶é—´ä¸å±‚æ¬¡
    times = ds.valid_time.values
    levels = ds.pressure_level.values

    index = pd.MultiIndex.from_product(
        [times, levels],
        names=['valid_time', 'pressure_level']
    )

    # âš ï¸ å…³é”®ï¼šæ¯ä¸ªæ–‡ä»¶å…ˆå»ºä¸€ä¸ªéª¨æ¶ DataFrame
    file_df = pd.DataFrame({
        'valid_time': index.get_level_values('valid_time'),
        'pressure_level': index.get_level_values('pressure_level')
    })

    # 6. å˜é‡å¾ªç¯ï¼šåœ¨ file_df ä¸­ä¸€åˆ—ä¸€åˆ—å¡«æ•°æ®
    for var in variables:
        print(f"  æ’å€¼å˜é‡ï¼š{var}")

        # ç»´åº¦è°ƒæ•´ï¼šlat, lon, time, level å†åè½¬çº¬åº¦
        data = ds[var].transpose(
            'latitude', 'longitude', 'valid_time', 'pressure_level'
        ).values[::-1]

        # è®¾ç½®æ’å€¼å™¨
        interpolator = RegularGridInterpolator(
            (lats, lons),
            data,
            method='linear',
            bounds_error=False,
            fill_value=np.nan
        )

        # å¯¹å•ç‚¹æ’å€¼ï¼Œç»“æœå½¢çŠ¶ï¼š(time, level)
        result = interpolator([[target_lat, target_lon]]).squeeze(0)

        # å±•å¹³æˆä¸€ç»´ï¼Œä¸ index å¯¹é½
        file_df[var] = result.ravel()

    # 7. è¿™ä¸ªæ–‡ä»¶çš„ç»“æœæš‚å­˜
    all_dfs.append(file_df)

# 8. æ‰€æœ‰æ–‡ä»¶æ‹¼æ¥
final_df = pd.concat(all_dfs, ignore_index=True)

# 9. è®¡ç®—æ´¾ç”Ÿé‡ï¼ˆè¦æ±‚å·²æœ‰ u, v, w, t, pressure_levelï¼‰
if {'w', 't', 'pressure_level'}.issubset(final_df.columns):
    final_df['vws(10â»Â² {m/s})'] = (
        mpcalc.vertical_velocity(
            final_df['w'].to_numpy() * units('Pa/s'),
            final_df['pressure_level'].to_numpy() * units.hPa,
            final_df['t'].to_numpy() * units.K,
            mixing_ratio=0 * units('kg/kg')
        ).m
    )

if {'u', 'v'}.issubset(final_df.columns):
    final_df['hws(m/s)'] = np.sqrt(
        np.square(final_df['u']) + np.square(final_df['v'])
    )
    final_df['hwd(deg)'] = np.mod(180+ np.degrees(np.arctan2(final_df['u'],final_df['v'])),360)

# æ ‡å‡†å¤§æ°”é«˜åº¦ï¼ˆç›¸å¯¹æµ·å¹³é¢ï¼‰ï¼Œå†å‡å»ç«™ç‚¹æµ·æ‹”å¾—åˆ° AGL
final_df['height'] = (
    1000.0
    * mpcalc.pressure_to_height_std(
        final_df['pressure_level'].to_numpy() * units.hPa
    ).m
    - Altitude
)

# 10. æ—¶é—´å¤„ç†ä¸åˆ—æ’åº
final_df['valid_time'] = pd.to_datetime(final_df['valid_time'])
final_df['BJT'] = (final_df['valid_time'] + pd.Timedelta(hours=8)).dt.strftime(
    '%Y/%m/%d %H:%M:%S'
)

cols = ['BJT', 'valid_time', 'pressure_level'] + sorted(
    [c for c in final_df.columns if c not in ['BJT', 'valid_time', 'pressure_level']],
    key=lambda x: x.lower()
)
final_df = final_df[cols]

print("\næ’å€¼ç»“æœç¤ºä¾‹ï¼š")
print(final_df.head())
print(f"\næ€»è¡Œæ•°ï¼š{len(final_df)}")
print(f"åˆ—ï¼š{final_df.columns.tolist()}")

# with pd.ExcelWriter(output_path + 'ERA5_interp_BJ.xlsx', engine='openpyxl', date_format='yyyy/mm/dd hh:mm:ss') as writer:

#     ERA5_interp_BJ.to_excel(writer, sheet_name='ERA5_interp_BJ', index=False)

#     for sheet_name in writer.sheets:
#         worksheet = writer.sheets[sheet_name]
#             # è®¾ç½®Aåˆ°Fåˆ—
#         for col in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I','L']:
#             worksheet.column_dimensions[col].width = 20


##############ERA5æ’å€¼åˆ°65å’Œ280ç±³å¯¹åº”1000/975hPa##############
filtered_final_df = final_df.query("pressure_level >= 950")
filtered_final_df = filtered_final_df.rename(columns={'valid_time':  'timestamps'})
filtered_final_df = filtered_final_df.set_index(['timestamps','height'])

target_heights = np.array([65,80,103,120,140,160,180,200,240,280,320])#65m and 280m
starttime = pd.to_datetime('2024-06-05')
endtime = filtered_final_df.reset_index()['timestamps'].unique().max()
era5_tobe_interp = filtered_final_df[['t','r','u','v','q','vws(10â»Â² {m/s})']]
var_series = era5_tobe_interp.reset_index()

def interpolate_group_multi(group, target_heights, era5_tobe_interp):
    current_time = group.name
    try:
        # ç›´æ¥é€šè¿‡ç´¢å¼•è·å–å¯¹åº”æ—¶é—´çš„é«˜åº¦æ•°æ®
        heights_df = era5_tobe_interp[era5_tobe_interp['timestamps'] == current_time].sort_values('height') 
    except KeyError:
        print(f"æ—¶é—´ {current_time}: åœ¨era5_tobe_interpä¸­æœªæ‰¾åˆ°å¯¹åº”é«˜åº¦æ•°æ®")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns)
    
    if len(heights_df) == 0:
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®ä¸ºç©º")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns)
    
    heights = heights_df['height'].values
    if len(heights) != len(group):
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®é•¿åº¦({len(heights)})ä¸å˜é‡æ•°æ®({len(group)})ä¸åŒ¹é…")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns)
    
    # æ’å€¼é€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰
    interpolated_data = {}
    for col in group.columns:
        values = group[col].values
        if np.isnan(values).all():
            interpolated_data[col] = np.full(len(target_heights), np.nan)
            continue
        try:
            f = interp1d(heights, values, kind='linear', bounds_error=False, fill_value='extrapolate')
            interpolated_values = f(target_heights)
        except Exception as e:
            print(f"å˜é‡ {col} åœ¨æ—¶é—´ {current_time} æ’å€¼å¤±è´¥: {str(e)}")
            interpolated_values = np.full(len(target_heights), np.nan)
        interpolated_data[col] = interpolated_values
    
    return pd.DataFrame(interpolated_data, index=target_heights).infer_objects(copy=False)
# æŒ‰æ—¶é—´åˆ†ç»„å¹¶åº”ç”¨æ’å€¼
interpolated_df = var_series.groupby('timestamps').apply(
    interpolate_group_multi, 
    target_heights=target_heights,
    era5_tobe_interp=var_series,
    include_groups=False
)
# å±•å¼€å¤šå±‚ç´¢å¼•

interpolated_df = interpolated_df.reset_index().rename(columns={'level_1':  'era5_tobe_interp'})
#interpolated_df['height'] = interpolated_df['height']
interpolated_df['hws(m/s)'] = np.sqrt(np.square(interpolated_df['u']) + np.square(interpolated_df['v']))
interpolated_df['hwd(deg)'] = np.degrees(np.arctan2(-interpolated_df['u'], -interpolated_df['v'])) % 360

sorted_df = interpolated_df.sort_values(
    by=['timestamps', 'height'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True, True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)
# è®¾ç½®åŒé‡ç´¢å¼•
#sorted_df = sorted_df.set_index(['timestamps', 'height'])
ERA5_interp_to_65_80_280 = sorted_df#.reset_index()[['timestamps','tieta_tobe_interp','height','t', 'r','q','hws(m/s)', 'hwd(deg)','vws(10â»Â² {m/s})']]
ERA5_interp_to_65_80_280.loc[:, 'q'] = ERA5_interp_to_65_80_280['q'] * 100
ERA5_interp_to_65_80_280 = ERA5_interp_to_65_80_280.rename(columns={'q':  'q*10^-2'})
ERA5_interp_to_65_80_280['timestamps'] = pd.to_datetime(ERA5_interp_to_65_80_280['timestamps'])
ERA5_interp_to_65_80_280['BJT'] = ERA5_interp_to_65_80_280['timestamps'] + pd.Timedelta(hours=8)
ERA5_interp_to_65_80_280['BJT'] = ERA5_interp_to_65_80_280['BJT'].dt.strftime('%Y/%m/%d %H:%M:%S')
cols = ['BJT', 'timestamps','era5_tobe_interp','height'] + sorted(
    [c for c in ERA5_interp_to_65_80_280.columns if c not in ['BJT', 'timestamps','era5_tobe_interp','height']],
    key=lambda x: x.lower()
)
ERA5_interp_to_65_80_280 = ERA5_interp_to_65_80_280[cols]



##############ERA5æ’å€¼åˆ°MWR##############

filtered_final_df = final_df.query("pressure_level >= 250")
filtered_final_df = filtered_final_df.rename(columns={'valid_time':  'timestamps'})
filtered_final_df = filtered_final_df.set_index(['timestamps','height'])

target_heights = temp_1min_reindexed_interpolated_final.set_index("timestamps").columns
starttime = pd.to_datetime('2024-08-05')
endtime = filtered_final_df.reset_index()['timestamps'].unique().max()
era5_tobe_interp = filtered_final_df[['t','r','u','v','q','vws(10â»Â² {m/s})']]
var_series = era5_tobe_interp.reset_index()

def interpolate_group_multi(group, target_heights, era5_tobe_interp):
    current_time = group.name
    
    # å¼ºåˆ¶è½¬æ¢ç›®æ ‡é«˜åº¦ä¸ºæµ®ç‚¹å‹
    target_heights = np.asarray(target_heights, dtype=np.float64)
    
    try:
        # ç¡®ä¿heightåˆ—æ˜¯æ•°å€¼å‹
        heights_df = era5_tobe_interp[era5_tobe_interp['timestamps'] == current_time].copy()
        heights_df['height'] = pd.to_numeric(heights_df['height'], errors='coerce')  # å®‰å…¨è½¬æ¢
        heights_df = heights_df.sort_values('height').dropna(subset=['height'])
    except KeyError as e:
        print(f"æ—¶é—´ {current_time}: å…³é”®åˆ—ç¼ºå¤± - {str(e)}")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns).astype(np.float64)
    
    if len(heights_df) == 0:
        print(f"æ—¶é—´ {current_time}: æœ‰æ•ˆé«˜åº¦æ•°æ®ä¸ºç©º")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns).astype(np.float64)
    
    # ç¡®ä¿é«˜åº¦æ•°æ®æ˜¯æµ®ç‚¹æ•°ç»„
    heights = heights_df['height'].values.astype(np.float64)
    if len(heights) != len(group):
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®é•¿åº¦({len(heights)})ä¸å˜é‡æ•°æ®({len(group)})ä¸åŒ¹é…")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns).astype(np.float64)
    
    interpolated_data = {}
    for col in group.columns:
        # å®‰å…¨æ•°æ®ç±»å‹è½¬æ¢
        try:
            values = pd.to_numeric(group[col], errors='coerce').values.astype(np.float64)
        except Exception as e:
            print(f"åˆ— {col} åŒ…å«éæ•°å€¼æ•°æ®: {str(e)}")
            values = np.full(len(group), np.nan, dtype=np.float64)
        
        if np.isnan(values).all():
            interpolated_data[col] = np.full(len(target_heights), np.nan, dtype=np.float64)
            continue
            
        try:
            # éªŒè¯æ’å€¼è¾“å…¥
            valid_mask = ~np.isnan(heights) & ~np.isnan(values)
            f = interp1d(heights[valid_mask], 
                         values[valid_mask], 
                         kind='linear', 
                         bounds_error=False, 
                         fill_value=np.nan)
            interpolated_values = f(target_heights)
        except Exception as e:
            print(f"å˜é‡ {col} åœ¨æ—¶é—´ {current_time} æ’å€¼å¤±è´¥: {str(e)}")
            interpolated_values = np.full(len(target_heights), np.nan, dtype=np.float64)
        
        interpolated_data[col] = interpolated_values
    
    # å¼ºåˆ¶è¾“å‡ºç±»å‹ä¸ºfloat64
    return pd.DataFrame(interpolated_data, index=target_heights).astype(np.float64)
# æŒ‰æ—¶é—´åˆ†ç»„å¹¶åº”ç”¨æ’å€¼
interpolated_df = var_series.groupby('timestamps').apply(
    interpolate_group_multi, 
    target_heights=target_heights,
    era5_tobe_interp=var_series,
    include_groups=False
)
# å±•å¼€å¤šå±‚ç´¢å¼•

interpolated_df = interpolated_df.reset_index().rename(columns={'level_1':  'era5_tobe_interp'})
interpolated_df['height'] = interpolated_df['height'] - Altitude
interpolated_df['hws(m/s)'] = np.sqrt(np.square(interpolated_df['u']) + np.square(interpolated_df['v']))
interpolated_df['hwd(deg)'] = np.degrees(np.arctan2(-interpolated_df['u'], -interpolated_df['v'])) % 360

sorted_df = interpolated_df.sort_values(
    by=['timestamps', 'height'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True, True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)
# è®¾ç½®åŒé‡ç´¢å¼•
#sorted_df = sorted_df.set_index(['timestamps', 'height'])
ERA5_interp_to_MWR = sorted_df#.reset_index()[['timestamps','tieta_tobe_interp','height','t', 'r','q','hws(m/s)', 'hwd(deg)','vws(10â»Â² {m/s})']]
ERA5_interp_to_MWR.loc[:, 'q'] = ERA5_interp_to_MWR['q'] * 100
ERA5_interp_to_MWR = ERA5_interp_to_MWR.rename(columns={'q':  'q*10^-2'})
ERA5_interp_to_MWR['timestamps'] = pd.to_datetime(ERA5_interp_to_MWR['timestamps'])
ERA5_interp_to_MWR['BJT'] = ERA5_interp_to_MWR['timestamps'] + pd.Timedelta(hours=8)
ERA5_interp_to_MWR['BJT'] = ERA5_interp_to_MWR['BJT'].dt.strftime('%Y/%m/%d %H:%M:%S')
cols = ['BJT', 'timestamps','era5_tobe_interp','height'] + sorted(
    [c for c in ERA5_interp_to_MWR.columns if c not in ['BJT', 'timestamps','era5_tobe_interp','height']],
    key=lambda x: x.lower()
)
ERA5_interp_to_MWR = ERA5_interp_to_MWR[cols]



##############ERA5æ’å€¼åˆ°WL#############
filtered_final_df = final_df.query("pressure_level >= 250")
filtered_final_df = filtered_final_df.rename(columns={'valid_time':  'timestamps'})
filtered_final_df = filtered_final_df.set_index(['timestamps','height'])
target_heights = np.arange(50, 2776, 25)
starttime = pd.to_datetime('2024-08-05')
endtime = filtered_final_df.reset_index()['timestamps'].unique().max()
era5_tobe_interp = filtered_final_df[['t','r','u','v','q','vws(10â»Â² {m/s})']]
var_series = era5_tobe_interp.reset_index()

def interpolate_group_multi(group, target_heights, era5_tobe_interp):
    current_time = group.name
    
    # å¼ºåˆ¶è½¬æ¢ç›®æ ‡é«˜åº¦ä¸ºæµ®ç‚¹å‹
    target_heights = np.asarray(target_heights, dtype=np.float64)
    
    try:
        # ç¡®ä¿heightåˆ—æ˜¯æ•°å€¼å‹
        heights_df = era5_tobe_interp[era5_tobe_interp['timestamps'] == current_time].copy()
        heights_df['height'] = pd.to_numeric(heights_df['height'], errors='coerce')  # å®‰å…¨è½¬æ¢
        heights_df = heights_df.sort_values('height').dropna(subset=['height'])
    except KeyError as e:
        print(f"æ—¶é—´ {current_time}: å…³é”®åˆ—ç¼ºå¤± - {str(e)}")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns).astype(np.float64)
    
    if len(heights_df) == 0:
        print(f"æ—¶é—´ {current_time}: æœ‰æ•ˆé«˜åº¦æ•°æ®ä¸ºç©º")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns).astype(np.float64)
    
    # ç¡®ä¿é«˜åº¦æ•°æ®æ˜¯æµ®ç‚¹æ•°ç»„
    heights = heights_df['height'].values.astype(np.float64)
    if len(heights) != len(group):
        print(f"æ—¶é—´ {current_time}: é«˜åº¦æ•°æ®é•¿åº¦({len(heights)})ä¸å˜é‡æ•°æ®({len(group)})ä¸åŒ¹é…")
        return pd.DataFrame(np.nan, index=target_heights, columns=group.columns).astype(np.float64)
    
    interpolated_data = {}
    for col in group.columns:
        # å®‰å…¨æ•°æ®ç±»å‹è½¬æ¢
        try:
            values = pd.to_numeric(group[col], errors='coerce').values.astype(np.float64)
        except Exception as e:
            print(f"åˆ— {col} åŒ…å«éæ•°å€¼æ•°æ®: {str(e)}")
            values = np.full(len(group), np.nan, dtype=np.float64)
        
        if np.isnan(values).all():
            interpolated_data[col] = np.full(len(target_heights), np.nan, dtype=np.float64)
            continue
            
        try:
            # éªŒè¯æ’å€¼è¾“å…¥
            valid_mask = ~np.isnan(heights) & ~np.isnan(values)
            f = interp1d(heights[valid_mask], 
                         values[valid_mask], 
                         kind='linear', 
                         bounds_error=False, 
                         fill_value=np.nan)
            interpolated_values = f(target_heights)
        except Exception as e:
            print(f"å˜é‡ {col} åœ¨æ—¶é—´ {current_time} æ’å€¼å¤±è´¥: {str(e)}")
            interpolated_values = np.full(len(target_heights), np.nan, dtype=np.float64)
        
        interpolated_data[col] = interpolated_values
    
    # å¼ºåˆ¶è¾“å‡ºç±»å‹ä¸ºfloat64
    return pd.DataFrame(interpolated_data, index=target_heights).astype(np.float64)
# æŒ‰æ—¶é—´åˆ†ç»„å¹¶åº”ç”¨æ’å€¼
interpolated_df = var_series.groupby('timestamps').apply(
    interpolate_group_multi, 
    target_heights=target_heights,
    era5_tobe_interp=var_series,
    include_groups=False
)
# å±•å¼€å¤šå±‚ç´¢å¼•

interpolated_df = interpolated_df.reset_index().rename(columns={'level_1':  'era5_tobe_interp'})
interpolated_df['height'] = interpolated_df['height'] - Altitude
interpolated_df['hws(m/s)'] = np.sqrt(np.square(interpolated_df['u']) + np.square(interpolated_df['v']))
interpolated_df['hwd(deg)'] = np.degrees(np.arctan2(-interpolated_df['u'], -interpolated_df['v'])) % 360

sorted_df = interpolated_df.sort_values(
    by=['timestamps', 'height'],  # æŒ‰æ—¶é—´â†’æ°”å‹å±‚çº§åŒæ’åº
    ascending=[True, True]                # é»˜è®¤å‡åºï¼ˆæ—¶é—´ä»æ—©åˆ°æ™šï¼Œå±‚çº§ä»ä½åˆ°é«˜ï¼‰
)
# è®¾ç½®åŒé‡ç´¢å¼•
#sorted_df = sorted_df.set_index(['timestamps', 'height'])
ERA5_interp_to_WL = sorted_df#.reset_index()[['timestamps','tieta_tobe_interp','height','t', 'r','q','hws(m/s)', 'hwd(deg)','vws(10â»Â² {m/s})']]
ERA5_interp_to_WL.loc[:, 'q'] = ERA5_interp_to_WL['q'] * 100
ERA5_interp_to_WL = ERA5_interp_to_WL.rename(columns={'q':  'q*10^-2'})
ERA5_interp_to_WL['timestamps'] = pd.to_datetime(ERA5_interp_to_WL['timestamps'])
ERA5_interp_to_WL['BJT'] = ERA5_interp_to_WL['timestamps'] + pd.Timedelta(hours=8)
ERA5_interp_to_WL['BJT'] = ERA5_interp_to_WL['BJT'].dt.strftime('%Y/%m/%d %H:%M:%S')
cols = ['BJT', 'timestamps','era5_tobe_interp','height'] + sorted(
    [c for c in ERA5_interp_to_WL.columns if c not in ['BJT', 'timestamps','era5_tobe_interp','height']],
    key=lambda x: x.lower()
)
ERA5_interp_to_WL = ERA5_interp_to_WL[cols]

# with pd.ExcelWriter(output_path + 'ERA5æ’åˆ°é“å¡”ã€MWRå’ŒWL.xlsx', engine='openpyxl', date_format='yyyy/mm/dd hh:mm:ss') as writer:

#     ERA5_interp_to_65_80_280.to_excel(writer, sheet_name='ERA5_interp_to_65_80_280', index=False)

#     for sheet_name in writer.sheets:
#         worksheet = writer.sheets[sheet_name]
#             # è®¾ç½®Aåˆ°Fåˆ—
#         for col in ['A','B','C','L']:
#             worksheet.column_dimensions[col].width = 20
            
#     CRA_interp_to_WL.dropna().to_excel(writer, sheet_name='ERA5_to_WL', index=False)
#     CRA_interp_to_MWR.dropna().to_excel(writer, sheet_name='ERA5_to_MWR', index=False)
#     for sheet_name in writer.sheets:
#         worksheet = writer.sheets[sheet_name]
#             # è®¾ç½®Aåˆ°Fåˆ—
#         for col in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']:
#             worksheet.column_dimensions[col].width = 20            

######################################################################################################################################################


# hws_cra_wide = CRA_interp_to_WL.pivot(
#     index='timestamps',       # ä¿æŒæ—¶é—´æˆ³ä¸ºè¡Œç´¢å¼•
#     columns='height_plus_alt',    # å°†æ°”å‹å±‚çº§å±•å¼€ä¸ºåˆ—
#     values='hws(m/s)'        # æŒ‡å®šéœ€è¦è½¬æ¢çš„æ•°å€¼åˆ—
# ).dropna(axis=1)

# vws_cra_wide = CRA_interp_to_WL.pivot(
#     index='timestamps',       # ä¿æŒæ—¶é—´æˆ³ä¸ºè¡Œç´¢å¼•
#     columns='height_plus_alt',    # å°†æ°”å‹å±‚çº§å±•å¼€ä¸ºåˆ—
#     values='vws(10â»Â² {m/s})'        # æŒ‡å®šéœ€è¦è½¬æ¢çš„æ•°å€¼åˆ—
# ).dropna(axis=1)

# hws_era5_wide = ERA5_interp_to_WL.pivot(
#     index='timestamps',       # ä¿æŒæ—¶é—´æˆ³ä¸ºè¡Œç´¢å¼•
#     columns='era5_tobe_interp',    # å°†æ°”å‹å±‚çº§å±•å¼€ä¸ºåˆ—
#     values='hws(m/s)'        # æŒ‡å®šéœ€è¦è½¬æ¢çš„æ•°å€¼åˆ—
# ).dropna(axis=1)

# vws_era5_wide = ERA5_interp_to_WL.pivot(
#     index='timestamps',       # ä¿æŒæ—¶é—´æˆ³ä¸ºè¡Œç´¢å¼•
#     columns='era5_tobe_interp',    # å°†æ°”å‹å±‚çº§å±•å¼€ä¸ºåˆ—
#     values='vws(10â»Â² {m/s})'        # æŒ‡å®šéœ€è¦è½¬æ¢çš„æ•°å€¼åˆ—
# ).dropna(axis=1)

    
# hws_wl_wide = wind_60min_hws_joined.reset_index().query("height % 25 == 0").pivot(
#     index='BJT',       # ä¿æŒæ—¶é—´æˆ³ä¸ºè¡Œç´¢å¼•
#     columns='height',    # å°†æ°”å‹å±‚çº§å±•å¼€ä¸ºåˆ—
#     values='hws'        # æŒ‡å®šéœ€è¦è½¬æ¢çš„æ•°å€¼åˆ—
# )
    
# vws_wl_wide = wind_60min_vws_joined.reset_index().query("height % 25 == 0").pivot(
#     index='BJT',       # ä¿æŒæ—¶é—´æˆ³ä¸ºè¡Œç´¢å¼•
#     columns='height',    # å°†æ°”å‹å±‚çº§å±•å¼€ä¸ºåˆ—
#     values='vws'        # æŒ‡å®šéœ€è¦è½¬æ¢çš„æ•°å€¼åˆ—
# )
    

# wl_hws_minus_cra = hws_wl_wide.sub(hws_cra_wide)
# wl_vws_minus_cra = (vws_wl_wide).sub(-vws_cra_wide/100)#å†åˆ†æèµ„æ–™ä¸é£é›·è¾¾çš„ç¬¦å·ç›¸å

# wl_hws_minus_era5 = hws_wl_wide.sub(hws_era5_wide)
# wl_vws_minus_era5 = (vws_wl_wide).sub(-vws_era5_wide/100)

# with pd.ExcelWriter(output_path + 'é£é›·è¾¾å‡å†åˆ†æå·®å€¼.xlsx', engine='openpyxl', date_format='yyyy/mm/dd hh:mm:ss') as writer:
    
#     wl_hws_minus_cra.reset_index().to_excel(writer, sheet_name='WL-CRA_hws', index=False)
    
#     wl_vws_minus_cra.reset_index().to_excel(writer, sheet_name='WL-CRA_vws', index=False)
    
#     wl_hws_minus_era5.reset_index().to_excel(writer, sheet_name='WL-ERA5_hws', index=False)
    
#     wl_vws_minus_era5.reset_index().to_excel(writer, sheet_name='WL-ERA5_vws', index=False)
    
#     writer.book.create_sheet("æˆ‘æ˜¯åˆ†éš”ç¬¦")
    
#     hws_wl_wide.reset_index().to_excel(writer, sheet_name='hws_wl_wide', index=False)
    
#     vws_wl_wide.reset_index().to_excel(writer, sheet_name='vws_wl_wide', index=False)
    
#     hws_cra_wide.reset_index().to_excel(writer, sheet_name='hws_cra_wide', index=False)
    
#     vws_cra_wide.reset_index().to_excel(writer, sheet_name='vws_cra_wide', index=False)
    
#     hws_era5_wide.reset_index().to_excel(writer, sheet_name='hws_era5_wide', index=False)
    
#     vws_era5_wide.reset_index().to_excel(writer, sheet_name='vws_era5_wide', index=False)
    
#     for sheet_name in writer.sheets:
#         worksheet = writer.sheets[sheet_name]
#             # è®¾ç½®Aåˆ°Fåˆ—
#         for col in ['A']:
#             worksheet.column_dimensions[col].width = 20
    
######################################################################################################################################################

# cra_temp = cra_regular.pivot(
#     index='timestamps',       # ä¿æŒæ—¶é—´æˆ³ä¸ºè¡Œç´¢å¼•
#     columns='Level (hPa)',    # å°†æ°”å‹å±‚çº§å±•å¼€ä¸ºåˆ—
#     values='Temp (K)'        # æŒ‡å®šéœ€è¦è½¬æ¢çš„æ•°å€¼åˆ—
# )

# cra_hws = cra_regular.pivot(
#     index='timestamps',       # ä¿æŒæ—¶é—´æˆ³ä¸ºè¡Œç´¢å¼•
#     columns='Level (hPa)',    # å°†æ°”å‹å±‚çº§å±•å¼€ä¸ºåˆ—
#     values='hws(m/s)'        # æŒ‡å®šéœ€è¦è½¬æ¢çš„æ•°å€¼åˆ—
# )
# cra_hws = cra_regular.pivot(
#     index='timestamps',       # ä¿æŒæ—¶é—´æˆ³ä¸ºè¡Œç´¢å¼•
#     columns='Level (hPa)',    # å°†æ°”å‹å±‚çº§å±•å¼€ä¸ºåˆ—
#     values='vws(10â»Â² {m/s})'        # æŒ‡å®šéœ€è¦è½¬æ¢çš„æ•°å€¼åˆ—
# )

#################################################ä¸‹é¢æ˜¯ç”»å•ä¸ªå›¾çš„ä»£ç 

# # === è¯»å–æ¢ç©ºæ•°æ® (Excel) ===
# # å‡è®¾åŸå§‹ Excel æ–‡ä»¶åä¸º "original combined2.xlsx"ï¼Œç›®æ ‡å·¥ä½œè¡¨åä¸º '2024080508'
# snd = pd.read_excel("E:\\Beijing2024\\æ¢ç©ºæ•°æ®-54511\\original combined2.xlsx", sheet_name="2024080508")  # :contentReference[oaicite:3]{index=3}

# # === è¿‡æ»¤å…¶ä»–æ•°æ®æºåœ¨2024-08-05 08:00çš„å‰–é¢ ===
# target_time = pd.to_datetime('2024-08-05 08:00')
# cra_regular['timestamps'] = pd.to_datetime(cra_regular['timestamps'])
# # å‡å®š ERA5_interp_BJã€cra_regularã€df_mwr_60min å·²ç»ä»¥ DataFrame å½¢å¼åŠ è½½
# era5_profile = ERA5_interp_BJ[ERA5_interp_BJ['valid_time'] == target_time].copy()
# cra_profile = cra_regular[cra_regular['timestamps'] == target_time].copy()
# mwr_profile = df_mwr_60min.reset_index().loc[df_mwr_60min.reset_index()['BJT'] == target_time].copy()

# # === å•ä½è½¬æ¢ä¸è®¡ç®—é«˜åº¦ ===
# # ERA5 ä¸ CRA æ•°æ®ï¼šå‹åŠ› (hPa) -> é«˜åº¦ (m)
# era5_profile['height'] = mpcalc.pressure_to_height_std(era5_profile['pressure_level'].to_list() * units('hPa')).to('m').magnitude  
# cra_profile['height'] = mpcalc.pressure_to_height_std(cra_profile['Level (hPa)'].to_list() * units.hPa).to('m').magnitude  

# # æ¢ç©ºæ•°æ®ï¼šæ¸©åº¦æ‘„æ°åº¦è½¬ä¸ºå¼€å°”æ–‡ï¼Œå¹¶å°†å‹åŠ› -> é«˜åº¦
# snd['temperature_K'] = snd['temperature_C'] + 273.15
# snd['height'] = mpcalc.pressure_to_height_std(snd['pressure_hPa'].to_list() * units.hPa).to('m').magnitude

# # MWR æ•°æ®ï¼šå‡è®¾å·²å«é«˜åº¦ (m) å’Œæ¸©åº¦ (K)
# # ï¼ˆæ— éœ€è½¬æ¢é«˜åº¦ï¼Œåªéœ€æ’åºï¼‰
# mwr_profile = mwr_profile.sort_values('height')

# # å¯¹å„å‰–é¢æŒ‰é«˜åº¦æ’åºï¼ˆä¾¿äºç»˜å›¾ï¼‰
# era5_profile = era5_profile.sort_values('height')
# cra_profile = cra_profile.sort_values('height')[0:37]
# snd = snd.sort_values('height')

# # === ç»˜å›¾ ===
# plt.rcParams.update({'font.size': 30,
#                      'axes.linewidth':3,
#                      'axes.labelsize': 30,
#                      'xtick.labelsize': 30,
#                      'ytick.labelsize': 30})

# fig, ax = plt.subplots(figsize=(10, 13))

# # ç»˜åˆ¶æ¸©åº¦-é«˜åº¦æ›²çº¿ï¼Œå„æ•°æ®æºä¸åŒé¢œè‰²çº¿æ¡
# ax.plot(era5_profile['t'], era5_profile['height'], color='blue',   linewidth=3)
# ax.plot(cra_profile['Temp (K)'], cra_profile['height'],     color='red',    linewidth=3)
# ax.plot(mwr_profile['T(K)'],    mwr_profile['height'],     color='magenta',linewidth=3)
# ax.plot(snd['temperature_K'],   snd['height'],              color='black',  linewidth=3)

# # è®¾ç½®å·¦ä¾§åæ ‡è½´ï¼šé«˜åº¦ (çº¢è‰²)ï¼Œå¹¶å¯ç”¨å·¦å³åŒä¾§åˆ»åº¦çº¿

# ax.spines['left'].set_color('red') 
# ax.spines['right'].set_color('blue') 
# ax.spines['bottom'].set_color('black') 
# ax.spines['top'].set_color('black') 

# ax.set_xlabel('Temperature(K)')
# ax.set_ylabel('Height(m a.g.l.)',color='red')

# ax.tick_params(axis='y', colors='red', length = 12,width=2)

# # æ·»åŠ å³ä¾§è¾…åŠ©åæ ‡è½´ï¼šæ°”å‹ (è“è‰²)ï¼Œä½¿ç”¨MetPyè½¬æ¢å‡½æ•°&#8203;:contentReference[oaicite:7]{index=7}
# secax = ax.secondary_yaxis('right',
#     functions=(lambda h: mpcalc.height_to_pressure_std(h * units.m).to('hPa').magnitude,
#                lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude))
# secax.set_ylabel('Pressure(hPa)', color='blue',rotation = 270, labelpad = 20)
# secax.yaxis.label.set_color('blue')
# secax.tick_params(axis='y', colors='blue',length=12,width=2)

# # ç»˜åˆ¶æ°´å¹³è™šçº¿ï¼šç¤ºä¾‹æ ‡ç¤º 2000 m (çº¢) å’Œå¯¹åº” 500 hPa (è“)
# site_elev = 49
# alt_ticks = np.array([0, 500, 2000, 
#                       3000, 5000, 8000, 10000, 12500, 15000])        # AGL
# p_ticks   = np.array([1000, 925, 850,
#                       700, 500, 275])                  # hPa
# p2alt = lambda p: mpcalc.pressure_to_height_std(
#         p*units.hPa).to('m').magnitude

# for y in alt_ticks:
#     ax.axhline(y, color='red', lw=2, zorder=0, linestyle=(0,(5,10))) 
# for p in p_ticks:
#     ax.axhline(p2alt(p), color='blue', lw=2, zorder=0, linestyle=(0,(5,10)))
# ax.set_yticks(alt_ticks)  # è®¾ç½®å·¦ä¾§ä¸»åˆ»åº¦
# secax.set_yticks(p_ticks)   # è®¾ç½®å³ä¾§ä¸»åˆ»åº¦
# secax.set_ylim(1000, 275)   # æ°”å‹è½´èŒƒå›´å€’ç½®ï¼ˆç¬¦åˆå¤§æ°”ç§‘å­¦æƒ¯ä¾‹ï¼‰
# ax.set_ylim(0, 10000) 
# ax.xaxis.set_major_locator(MultipleLocator(10))
# ax.xaxis.set_minor_locator(MultipleLocator(5))
# ax.tick_params(axis='x',which='minor',length=6,width=2,color='black')
# plt.tick_params(axis='x', length=12, width=2)
# ax.set_xlim(240, 310)
# plt.title(f"{target_time}", loc='center', pad=20, y=1.01,fontsize = 25)
# plt.tight_layout()
# plt.show()

# -*- coding: utf-8 -*-

############é“å¡”æ•°æ®æ•£ç‚¹å¯¹æ¯”####################
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŸºæœ¬è·¯å¾„ä¸æ–‡ä»¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#ultra_path  = r"E:\Beijing2024\æ•°æ®å¤„ç†ç»“æœ2nd\ultrasonic_1_5_60.xlsx"
#tieta_path  = r"E:\Beijing2024\æ•°æ®å¤„ç†ç»“æœ2nd\tieta0805-0810_1-5-60.xlsx"
#output_dir  = r"E:\Beijing2024\å‡ºå›¾TIF"
#os.makedirs(output_dir, exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â˜… æ–°å¢ï¼šæ—¶é—´çª—å£å‚æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TIME_START1 = pd.Timestamp("2024-08-09 12:46")   # â† æ ¹æ®éœ€è¦ä¿®æ”¹
TIME_END1   = pd.Timestamp("2024-08-10 00:03")
# ç¬¬äºŒä¸ªæ—¶é—´çª—å£ï¼ˆæ–°å¢ï¼‰
TIME_START2 = pd.Timestamp("2024-08-10 16:20")   # â† æ–°å¢æ—¶é—´çª—å£å¼€å§‹
TIME_END2   = pd.Timestamp("2024-08-10 17:30")   # â† æ–°å¢æ—¶é—´çª—å£ç»“æŸ

# ç¬¬äºŒä¸ªæ—¶é—´çª—å£ï¼ˆæ–°å¢ï¼‰
TIME_START3 = pd.Timestamp("2024-06-07 09:15")   # â† æ–°å¢æ—¶é—´çª—å£å¼€å§‹
TIME_END3   = pd.Timestamp("2024-06-07 15:00")   # â† æ–°å¢æ—¶é—´çª—å£ç»“æŸ

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¯»å– Excel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¶…å£°ï¼ˆå–å‰26åˆ—ï¼‰
ultra = turb_calibrated_1min   #pd.read_excel(ultra_path,  sheet_name="turb_1min_corrected", usecols=range(26))
# é“å¡”ï¼ˆå–å‰8åˆ—ï¼‰
tieta = tieta_1min.reset_index()   #pd.read_excel(tieta_path, sheet_name="tieta0805-0810_1min",     usecols=range(8))
# ---- ç¡®ä¿æ—¶é—´åˆ—æ˜¯ datetime ç±»å‹ ----
ultra["timestamps"] = pd.to_datetime(ultra["timestamps"], errors="coerce")
tieta["timestamps"] = pd.to_datetime(tieta["timestamps"], errors="coerce")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç­›é€‰ç›®æ ‡é«˜åº¦å±‚ & é¢„å¤„ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
heights = [280, 200, 140, 80]
ultra = ultra[ultra["Height"].isin(heights)]
ultra["rh"] = ultra["rh"].clip(upper=100)           # RH ä¸Šé™ 100 %
tieta = tieta[tieta["H(m)"].isin(heights)]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åˆå¹¶ï¼ˆæ—¶é—´ & é«˜åº¦ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
merged = (
    pd.merge(
        ultra[["timestamps", "Height", "rh", "hws_corrected", "T (K)", "wd_corrected"]],
        tieta[["timestamps", "H(m)",  "RH_tieta", "ws_tieta", "T(K)_tieta", "wd_tieta"]],
        left_on=["timestamps", "Height"],
        right_on=["timestamps", "H(m)"],
        suffixes=("_ultra", "_tieta")
    )
    .dropna()
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å˜é‡æ˜ å°„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
variables = {
    "temp": ("T (K)",       "T(K)_tieta"),
    "hws" : ("hws_corrected","ws_tieta"),
    "rh"  : ("rh",          "RH_tieta"),
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ é¢„è®¡ç®—ç»Ÿè®¡é‡ & ä¿å­˜æ—¶é—´æˆ³ â˜…æ–°å¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
results = {}
for h in heights:
    subset = merged[merged["Height"] == h]
    results[h] = {}
    for var, (ultra_col, tieta_col) in variables.items():
        x = subset[ultra_col]
        y = subset[tieta_col]

        # åŸºæœ¬ç»Ÿè®¡
        pearson_r, _ = stats.pearsonr(x, y)
        X = sm.add_constant(x)
        model = sm.OLS(y, X).fit()
        r2 = model.rsquared
        adj_r2 = 1 - (1 - r2) * (len(x) - 1) / (len(x) - 2)

        # ç½®ä¿¡åŒºé—´
        pred = model.get_prediction(X)
        ci = pred.conf_int(alpha=0.05)

        results[h][var] = {
            "x": x,
            "y": y,
            "t": subset["timestamps"],   # â˜…æ–°å¢ï¼šä¿å­˜å¯¹åº”æ—¶é—´æˆ³
            "pearson_r": pearson_r,
            "r2": r2,
            "adj_r2": adj_r2,
            "ci": ci,
            "model": model,              # å›å½’æ¨¡å‹å¤‡ç”¨
        }
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç”»å›¾é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fig = plt.figure(figsize=(30, 40), dpi=100)
gs  = GridSpec(nrows=4, ncols=6, figure=fig,
               width_ratios=[1, 0.3]*3, height_ratios=[1]*4)
plt.rcParams.update(plt.rcParamsDefault)

color_map = {"temp": "#ff0000", "hws": "#0000ff", "rh": "#00aa00"}
palette   = {"X": "#4C72B0", "Y": "#DD8452"}
sns.set_theme(style="whitegrid", font_scale=1.2)
# â˜…æ—¶é—´çª—å£å¸ƒå°”æ©ç ï¼šä¸‰ä¸ªæ—¶é—´æ®µä¸€èµ·é«˜äº®


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¾ªç¯ç»˜åˆ¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for row, height in enumerate(heights):
    for col, var in enumerate(variables.keys()):
        data          = results[height][var]
        x, y, t       = data["x"], data["y"], data["t"]
        current_color = color_map[var]

        # ä¸¤ä¸ªæ—¶é—´çª—å£åˆå¹¶ä¸ºä¸€ä¸ªæ©ç 
        mask_1 = (t >= TIME_START1) & (t <= TIME_END1)
        mask_2 = (t >= TIME_START2) & (t <= TIME_END2)
        mask_3 = (t >= TIME_START3) & (t <= TIME_END3)

        mask_time  = mask_1 | mask_2 | mask_3   # ä¸‰ä¸ªæ—¶é—´çª—å£åˆå¹¶
        mask_other = ~mask_time                 # å…¶ä»–æ—¶é—´ç‚¹

        # â”€â”€â”€â”€â”€ æ•£ç‚¹ & å›å½’çº¿ â”€â”€â”€â”€â”€
        ax_scatter = fig.add_subplot(gs[row, 2*col])

        # å›å½’çº¿ï¼ˆä¸ç»˜åˆ¶é»˜è®¤æ•£ç‚¹ï¼‰- äº¤æ¢xå’Œy
        sns.regplot(
            x=y, y=x, ax=ax_scatter, scatter=False,
            line_kws={"color": "#949494", "lw": 4},
            ci=95,scatter_kws={"alpha":0},
            
        )

        # # æ‰€æœ‰ç‚¹ï¼ˆä¸»æ•°æ®ï¼‰ - åœ†ç‚¹ - äº¤æ¢xå’Œy
        ax_scatter.scatter(
            y[~mask_time], x[~mask_time],
            marker="o", color=current_color, alpha=1, s=25, edgecolors="none"
        )
        # â˜…ç¬¬ä¸€ä¸ªæ—¶é—´çª—å£ç‚¹ - ä¸‰è§’æ ‡è®° - äº¤æ¢xå’Œy
        ax_scatter.scatter(
            y[mask_time], x[mask_time],
            marker="o", color='orange', alpha=1,
            s=50, edgecolors="none", linewidths=0.5, 
        )

        # 1:1 å‚è€ƒè™šçº¿ - äº¤æ¢xå’Œy
        ax_scatter.plot([y.min(), y.max()], [y.min(), y.max()], "k--", lw=4)

        # ç»Ÿè®¡æ–‡å­—
        ax_scatter.text(
            0.025, 0.90,
            f"Pearson R = {data['pearson_r']:.2f}\nAdjusted RÂ² = {data['adj_r2']:.2f}",
            transform=ax_scatter.transAxes, fontsize=32, fontname="Arial",
            bbox={'facecolor': 'none', 'edgecolor': 'none'}
        )

        # ç»Ÿä¸€åæ ‡è½´ã€åˆ»åº¦ & æ ·å¼ï¼ˆä¿æŒåŸé€»è¾‘ï¼Œç•¥ï¼‰
        ax_scatter.xaxis.set_major_locator(MultipleLocator(5))
        ax_scatter.xaxis.set_minor_locator(AutoMinorLocator(2))
        ax_scatter.yaxis.set_minor_locator(AutoMinorLocator(2))
        ax_scatter.tick_params(axis='both', labelsize=36, direction='out',
                               length=20, width=3, color='black',
                               bottom=True, left=True)
        ax_scatter.tick_params(which='minor', axis='both',
                               length=10, width=3, direction='out',
                               bottom=True, left=True)
        ax_scatter.grid(False)
        ax_scatter.spines[['top', 'right']].set_visible(False)
        ax_scatter.spines[['left', 'bottom']].set_linewidth(3)
        ax_scatter.spines[['left', 'bottom']].set_color('black')

        # å˜é‡ä¸“å±åæ ‡èŒƒå›´ - äº¤æ¢xå’Œy
        if var == 'temp':
            ax_scatter.set_xlim(287, 310); ax_scatter.set_ylim(287, 310)
            ax_scatter.set_xticks(np.arange(290, 311, 5))
            ax_scatter.set_yticks(np.arange(290, 311, 5))
        elif var == 'hws':
            ax_scatter.set_xlim(-0.2, 16); ax_scatter.set_ylim(-0.2, 16)
            ax_scatter.set_xticks(np.arange(0, 17, 4))
            ax_scatter.set_yticks(np.arange(0, 17, 4))
        elif var == 'rh':
            ax_scatter.set_xlim(30, 105); ax_scatter.set_ylim(30, 105)
            ax_scatter.set_xticks(np.arange(30, 105, 10))
            ax_scatter.set_yticks(np.arange(30, 105, 10))

        # è½´æ ‡é¢˜ & æ ‡ç­¾ - äº¤æ¢xå’Œyæ ‡ç­¾
        if row == 0:
            title_map = {'temp': "Temperature (K)",
                         'hws' : "Horizontal Wind Speed (m/s)",
                         'rh'  : "RH (%)"}
            ax_scatter.set_title(title_map[var], fontsize=36, pad=25, fontweight='bold')
        if row == len(heights)-1 and col == 1:
            ax_scatter.set_xlabel(
                "Automatic Weather Station (AWS)",  # äº¤æ¢ä¸ºAWS
                fontsize=40, fontweight='bold', labelpad=15
            )
        else:
            ax_scatter.set_xlabel('')
        ax_scatter.set_ylabel('')

        # â”€â”€â”€â”€â”€ åŠå°æç´å›¾ï¼ˆä¿æŒåŸé€»è¾‘ï¼Œä»…æ ·å¼å¾®è°ƒï¼‰ â”€â”€â”€â”€â”€
        ax_violin = fig.add_subplot(gs[row, 2*col+1])
        # äº¤æ¢xå’Œy - ç°åœ¨xæ˜¯AWSï¼Œyæ˜¯ECM
        df_melt = pd.DataFrame({
            "value": pd.concat([y, x]),  # äº¤æ¢xå’Œy
            "source": ["X"]*len(y) + ["Y"]*len(x)  # äº¤æ¢xå’Œy
        })
        sns.violinplot(
            x="source", y="value", data=df_melt, ax=ax_violin,
            hue="source", palette=palette, linewidth=3, linecolor='black',
            inner="box", legend=False, split=True,
            inner_kws=dict(box_width=20, whis_width=3, color="0.75")
        )

        # å°æç´åæ ‡ä¸æ•£ç‚¹ä¿æŒä¸€è‡´ - äº¤æ¢xå’Œy
        if var == 'temp':
            ax_violin.set_ylim(287, 310); ax_violin.set_yticks(np.arange(287, 311, 5))
        elif var == 'hws':
            ax_violin.set_ylim(-0.2, 16); ax_violin.set_yticks(np.arange(0, 16.01, 4))
        elif var == 'rh':
            ax_violin.set_ylim(10, 106.1); ax_violin.set_yticks(np.arange(10, 106.1, 10))

        ax_violin.tick_params(axis='both', which='major', labelsize=36,
                              direction='out', length=20, width=3, color='black',
                              bottom=True, left=True)
        ax_violin.yaxis.set_minor_locator(AutoMinorLocator(2))
        ax_violin.tick_params(which='minor', axis='both', length=10, width=3,
                              direction='out', bottom=False, left=True, color='black')
        ax_violin.grid(False)
        ax_violin.spines[['top', 'right']].set_visible(False)
        ax_violin.spines[['left', 'bottom']].set_linewidth(3)
        ax_violin.spines[['left', 'bottom']].set_color('black')
        ax_violin.set_facecolor('none')
        ax_violin.set_xlabel(''); ax_violin.set_ylabel('')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å…¨å±€ Y è½´æ ‡ç­¾ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fig.text(-0.015, 0.5,
         'Eddy Covariance Measurement (ECM)',  # äº¤æ¢ä¸ºECM
         rotation='vertical', va='center', fontsize=40, fontweight='bold')

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä¿å­˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
plt.tight_layout()
plt.savefig(
    os.path.join("E:\\Beijing2024\\å‡ºå›¾TIF\\tieta_vs_ultra_selected2.tif"),
    dpi=600, bbox_inches="tight", pad_inches=0.1, format="tif",
    facecolor='none', pil_kwargs={"compression": "tiff_adobe_deflate"}
)
plt.close()
gc.collect()


# """
# -------------------------------------------------------------------
# é‡æ–°åšé£é›·è¾¾è´¨é‡æ§åˆ¶
# -------------------------------------------------------------------
# """
# import os
# import numpy as np
# import pandas as pd
# import matplotlib.pyplot as plt
# import metpy.calc as mpcalc
# from metpy.units import units

# # ---------- 0. å…¨å±€å¸¸é‡ ----------
# RAW_PATH1 = r"E:\Beijing2024\Wind Lidar\åŒ—äº¬202310-202408\åŒ—äº¬202310-202408.csv"
# RAW_PATH2 = r"E:\Beijing2024\Wind Lidar\0805-0810\merged_sorted_data.csv"
# OUT_DIR   = r"E:\Beijing2024\å‡ºå›¾TIF\lidar qc"
# os.makedirs(OUT_DIR, exist_ok=True)

# START_BJT = "2024-08-04 00:00:00"
# END_BJT   = "2024-08-11 00:00:00"
# start_dt  = pd.to_datetime(START_BJT)
# end_dt    = pd.to_datetime(END_BJT)


# WINDOW_TXT = f"{START_BJT} â€“ {END_BJT}"
# TIME_TAG   = f"{start_dt:%Y%m%d}_{end_dt:%Y%m%d}"
# # é¢å¤–å¢åŠ ä¸€ä¸ªæ—¶é—´çª—ï¼ˆä¾‹å¦‚ç»™ 0606-0609ï¼‰
# EXTRA_START_BJT = "2024-06-06 00:00:00"
# EXTRA_END_BJT   = "2024-06-09 23:59:59"
# extra_start_dt  = pd.to_datetime(EXTRA_START_BJT)
# extra_end_dt    = pd.to_datetime(EXTRA_END_BJT)

# # ---- CNR é˜ˆå€¼ï¼ˆæ°´å¹³ / å‚ç›´ï¼‰ ----
# CNR_LIM_H = -22     # Horizontal dB
# CNR_LIM_V = -25     # Vertical dB

# # ---- å…¨å±€é£é€Ÿé˜ˆå€¼ï¼ˆéå¯¹ç§°ï¼‰ ----
# HWS_MIN, HWS_MAX =  0, 60   # m s-Â¹
# VWS_MIN, VWS_MAX = -8,6   # m s-Â¹

# # ---- é«˜åº¦ä¸Šé™ï¼ˆåŒºåˆ†æ°´å¹³ / å‚ç›´ï¼‰ ----
# HEIGHT_LIM_H = 2700   # m
# HEIGHT_LIM_V = 2500   # m   â† ä¸¾ä¾‹ï¼ŒæŒ‰éœ€è°ƒæ•´

# # ---- åˆ†å±‚é£é€Ÿä¸Šé™ ----
# HWS_LAYER_LIMITS = {300: 18, 3000: 60}
# # ä¸Šå‡æ°”æµï¼ˆvws > 0ï¼‰ï¼šå„å±‚æœ€å¤§å…è®¸å€¼
# VWS_LAYER_LIMITS_UP = {
#     (0,   650):  5,
#     (650, 1800): 10,
#     (1800, 3000): 2
# }
# VWS_LAYER_LIMITS_DN = {
#     (0,   500):  -9,
#     (500, 1000): -7,
#     (1000,1500): -6,
#     (1500,2300): -3.5,
#     (2300,2500): -2
# }

# USE_LAYER_LIMITS_H = True
# USE_LAYER_LIMITS_V = True

# # ---------- 1. ç»˜å›¾é£æ ¼ ----------
# gc.collect()
# plt.rcParams.update({
#     "font.size": 16,
#     "axes.titlesize": 16,
#     "axes.labelsize": 16
# })
# # --------------------------------------------------
# # 2. è¯»å–ä¸é¢„å¤„ç†
# # --------------------------------------------------
# print("[INFO] è¯»å–åŸå§‹æ–‡ä»¶ â€¦")

# RAW_PATH1 = r"E:\Beijing2024\Wind Lidar\åŒ—äº¬202310-202408\åŒ—äº¬202310-202408.csv"
# RAW_PATH2 = r"E:\Beijing2024\Wind Lidar\0805-0810\merged_sorted_data.csv"
# w1 = pd.read_csv(RAW_PATH1).drop(columns=["Unnamed: 0"], errors="ignore")
# w2 = pd.read_csv(RAW_PATH2)
# # æ–°å¢ï¼š0606-0609 çš„æ°´å¹³ / å‚ç›´æ–‡ä»¶
# RAW_PATH3_H = r"E:\Beijing2024\Wind Lidar\0606-0609\wl_0606_h.xlsx"  # æ°´å¹³é£é€Ÿ
# RAW_PATH3_V = r"E:\Beijing2024\Wind Lidar\0606-0609\wl_0606_v.xlsx"  # å‚ç›´é£é€Ÿ

# # æ–°å¢ï¼š0606-0609 æ°´å¹³ / å‚ç›´
# w3_h = pd.read_excel(RAW_PATH3_H)   # æ°´å¹³é£é€Ÿæ–‡ä»¶ wl_0606_h.xlsx
# w3_v = pd.read_excel(RAW_PATH3_V)   # å‚ç›´é£é€Ÿæ–‡ä»¶ wl_0606_v.xlsx


# def preprocess_horizontal(df: pd.DataFrame, label: str,
#                           time_col_guess=("Timestamp", "timestamp")) -> pd.DataFrame:
#     """å¤„ç†å¸¦æ°´å¹³é£(å¿…æœ‰ hws/wd)çš„æ–‡ä»¶ï¼Œç”Ÿæˆ: BJT, height, hws, wd, u, v, vws(å¦‚æœ‰), CNR, Level(hPa)."""
#     print(f"[INFO] é¢„å¤„ç†æ°´å¹³é£ DataFrame {label} ({len(df):,} rows)â€¦")
#     df = df.copy()

#     # ------- æ—¶é—´åˆ—ç»Ÿä¸€ä¸º BJT -------
#     for cand in time_col_guess:
#         if cand in df.columns:
#             df.rename(columns={cand: "timestamps"}, inplace=True)
#             break
#     if "timestamps" not in df.columns:
#         raise ValueError(f"{label} ä¸­æ²¡æœ‰æ—¶é—´åˆ— (Timestamp/timestamp)")

#     df["timestamps"] = pd.to_datetime(df["timestamps"])
#     df["BJT"] = df["timestamps"] + pd.Timedelta(hours=8)
#     df.drop(columns="timestamps", inplace=True)

#     # ------- é«˜åº¦ -------
#     df.rename(columns={"Altitude [m]": "height"}, inplace=True, errors="ignore")

#     # ------- æ°´å¹³é£é€Ÿ + é£å‘ -------
#     df.rename(columns={
#         "Horizontal Wind Speed [m/s]": "hws",
#         "Horizontal Wind Direction [Â°]": "wd"
#     }, inplace=True, errors="ignore")

#     if not {"hws", "wd"}.issubset(df.columns):
#         raise ValueError(f"{label} ç¼ºå°‘ hws / wd åˆ—")

#     # è®¡ç®— u, v
#     df["u"] = -df["hws"] * np.sin(np.radians(df["wd"]))
#     df["v"] = -df["hws"] * np.cos(np.radians(df["wd"]))

#     # ------- å‚ç›´é£é€Ÿ(å¦‚æœæœ¬æ–‡ä»¶æœ‰çš„è¯) -------
#     df.rename(columns={"Vertical Wind Speed [m/s]": "vws"}, inplace=True, errors="ignore")
#     if "vws" not in df.columns:
#         df["vws"] = np.nan   # å¯¹äºçº¯æ°´å¹³é£æ–‡ä»¶å…ˆå ä½ï¼Œåé¢ç”¨å‚ç›´æ–‡ä»¶è¡¥

#     # ------- CNR -------
#     df.rename(columns={"CNR [dB]": "CNR"}, inplace=True, errors="ignore")
#     if "CNR" not in df.columns:
#         df["CNR"] = np.nan

#     # ------- æ ‡å‡†å¤§æ°”å‹é«˜åº¦ -> å‹åŠ› -------
#     if "height" in df.columns:
#         df["Level (hPa)"] = mpcalc.height_to_pressure_std(df["height"].values * units.m).m
#     else:
#         df["Level (hPa)"] = np.nan

#     df.sort_values(["BJT", "height"], inplace=True)
#     return df.reset_index(drop=True)


# def preprocess_vertical(df: pd.DataFrame, label: str,
#                         time_col_guess=("Timestamp", "timestamp")) -> pd.DataFrame:
#     """å¤„ç†å‚ç›´é£æ–‡ä»¶ï¼Œåªå…³å¿ƒ: BJT, height, vwsï¼ˆå’Œå¯é€‰ CNRï¼‰ã€‚"""
#     print(f"[INFO] é¢„å¤„ç†å‚ç›´é£ DataFrame {label} ({len(df):,} rows)â€¦")
#     df = df.copy()

#     # ------- æ—¶é—´åˆ— -> BJT -------
#     for cand in time_col_guess:
#         if cand in df.columns:
#             df.rename(columns={cand: "timestamps"}, inplace=True)
#             break
#     if "timestamps" not in df.columns:
#         raise ValueError(f"{label} ä¸­æ²¡æœ‰æ—¶é—´åˆ— (Timestamp/timestamp)")

#     df["timestamps"] = pd.to_datetime(df["timestamps"])
#     df["BJT"] = df["timestamps"] + pd.Timedelta(hours=8)
#     df.drop(columns="timestamps", inplace=True)

#     # ------- é«˜åº¦ -------
#     df.rename(columns={"Altitude [m]": "height"}, inplace=True, errors="ignore")

#     # å‚ç›´é£é€Ÿ
#     df.rename(columns={"Vertical Wind Speed [m/s]": "vws"}, inplace=True, errors="ignore")
#     if "vws" not in df.columns:
#         raise ValueError(f"{label} ä¸­æ²¡æœ‰ Vertical Wind Speed [m/s] åˆ—ï¼Ÿ")

#     # CNRï¼ˆå¦‚æœæœ‰ï¼Œå¯ä»¥ä¸€èµ·å¸¦ä¸Šï¼‰
#     df.rename(columns={"CNR [dB]": "CNR_v"}, inplace=True, errors="ignore")

#     df.sort_values(["BJT", "height"], inplace=True)
#     return df.reset_index(drop=True)


# # ===== 2.1 å…ˆåˆ†åˆ«å¤„ç† w1, w2ï¼ˆåŸæœ‰é€»è¾‘ä¸å˜ï¼‰ =====
# w1_proc = preprocess_horizontal(w1, "#1_202310-202408", time_col_guess=("Timestamp",))
# w2_proc = preprocess_horizontal(w2, "#2_0805-0810",      time_col_guess=("timestamp",))


# # ===== 2.2 å•ç‹¬å¤„ç† 0606-0609 çš„æ°´å¹³ / å‚ç›´ï¼Œç„¶ååˆå¹¶æˆåŒæ—¶æœ‰ hws+vws çš„ DataFrame =====
# w3_h_proc = preprocess_horizontal(w3_h, "#3_0606-0609_h", time_col_guess=("Timestamp", "timestamp"))
# w3_v_proc = preprocess_vertical(w3_v, "#3_0606-0609_v",   time_col_guess=("Timestamp", "timestamp"))

# # ä¸ºäº†ç”¨å‚ç›´æ–‡ä»¶çš„ vws æ›¿æ¢æ‰æ°´å¹³æ–‡ä»¶ä¸­å ä½çš„ NaN vwsï¼š
# w3_h_proc = w3_h_proc.drop(columns=["vws"], errors="ignore")

# # åœ¨ (BJT, height) ä¸Šåˆå¹¶ï¼ŒæŠŠ vws åŠ è¿›å»
# w3_merged = pd.merge(
#     w3_h_proc,
#     w3_v_proc[["BJT", "height", "vws"]],   # è¿™é‡ŒåªæŠŠ vws merge è¿›æ¥
#     on=["BJT", "height"],
#     how="left"
# )

# print(f"[INFO] 0606-0609 åˆå¹¶åè¡Œæ•°ï¼š{len(w3_merged):,}")


# # ===== 2.3 æœ€ç»ˆ raw_allï¼šåŒ…æ‹¬æ°´å¹³å’Œå‚ç›´é€Ÿåº¦ =====
# all_df = [w1_proc, w2_proc, w3_merged]
# raw_all = pd.concat(all_df, ignore_index=True)
# print(f"[INFO] åˆå¹¶åè¡Œæ•°ï¼š{len(raw_all):,}")

# # æŒ‰æ—¶é—´çª—è£å‰ª
# raw_all = raw_all[(raw_all["BJT"] >= start_dt) & (raw_all["BJT"] <= end_dt)].reset_index(drop=True)
# print(f"[INFO] æ—¶é—´çª—å†…è¡Œæ•°ï¼š{len(raw_all):,}")

# # --------------------------------------------------
# # 2. è¯»å–ä¸é¢„å¤„ç†
# # --------------------------------------------------
# print("[INFO] è¯»å– CSV â€¦")
# w1 = pd.read_csv(RAW_PATH1).drop(columns=["Unnamed: 0"], errors="ignore")
# w2 = pd.read_csv(RAW_PATH2)

# w1.rename(columns={"Timestamp": "timestamps"}, inplace=True)
# w2.rename(columns={"timestamp": "timestamps"}, inplace=True)

# all_df = []
# for idx, df in enumerate([w1, w2], 1):
#     print(f"[INFO] é¢„å¤„ç† DataFrame #{idx} ({len(df):,} rows)â€¦")
#     df["timestamps"] = pd.to_datetime(df["timestamps"])
#     df["BJT"] = df["timestamps"] + pd.Timedelta(hours=8)
#     df.drop(columns="timestamps", inplace=True)

#     df.rename(columns={"Altitude [m]": "height"}, inplace=True, errors="ignore")
#     if {"Horizontal Wind Speed [m/s]", "Horizontal Wind Direction [Â°]"}.issubset(df.columns):
#         df.rename(columns={
#             "Horizontal Wind Speed [m/s]": "hws",
#             "Horizontal Wind Direction [Â°]": "wd"
#         }, inplace=True)
#     if not {"hws", "wd"}.issubset(df.columns):
#         raise ValueError("ç¼ºå°‘ hws / wd åˆ—")

#     df["u"] = -df["hws"] * np.sin(np.radians(df["wd"]))
#     df["v"] = -df["hws"] * np.cos(np.radians(df["wd"]))

#     df.rename(columns={"Vertical Wind Speed [m/s]": "vws"}, inplace=True, errors="ignore")
#     if "vws" not in df.columns:
#         df["vws"] = np.nan

#     df.rename(columns={"CNR [dB]": "CNR"}, inplace=True, errors="ignore")
#     if "CNR" not in df.columns:
#         df["CNR"] = np.nan

#     df["Level (hPa)"] = mpcalc.height_to_pressure_std(df["height"].values*units.m).m
#     df.sort_values(["BJT", "height"], inplace=True)
#     all_df.append(df.reset_index(drop=True))

# raw_all = pd.concat(all_df, ignore_index=True)
# print(f"[INFO] åˆå¹¶åè¡Œæ•°ï¼š{len(raw_all):,}")

# # ä¸»æ—¶é—´çª— + é¢å¤–æ—¶é—´çª—ï¼Œä¸€èµ·ä¿ç•™
# mask_main  = (raw_all["BJT"] >= start_dt)      & (raw_all["BJT"] <= end_dt)
# mask_extra = (raw_all["BJT"] >= extra_start_dt) & (raw_all["BJT"] <= extra_end_dt)

# raw_all = raw_all[mask_main | mask_extra].reset_index(drop=True)
# print(
#     f"[INFO] ä¸»æ—¶é—´çª—({START_BJT}â€“{END_BJT}) + "
#     f"é¢å¤–æ—¶é—´çª—({EXTRA_START_BJT}â€“{EXTRA_END_BJT}) è¿‡æ»¤åè¡Œæ•°ï¼š{len(raw_all):,}"
# )

# # vertical_all=raw_all.dropna(subset=['vws'])
# # vertical_all=vertical_all.set_index("BJT")
# # horizontal_all = raw_all.dropna(subset=['hws'])
# # horizontal_all=horizontal_all.set_index("BJT")
# # horizontal_all.reset_index().to_csv("E:\\20240805-20240810_h.csv",index=False)
# # vertical_all.reset_index().to_csv("E:\\20240805-20240810_v.csv",index=False)
# # --------------------------------------------------
# # 3. åŸå§‹ç»Ÿè®¡ï¼ˆÂ±k Ïƒï¼‰
# # --------------------------------------------------
# def bands(mu, sigma, ks=(1,1.5,2,2.5,3)):
#     return {f"Â±{k}Ïƒ": (mu - k*sigma, mu + k*sigma) for k in ks}

# for col, tag in [("hws", "Horizontal"), ("vws", "Vertical")]:
#     mu = raw_all[col].mean(skipna=True)
#     sd = raw_all[col].std(skipna=True)
#     print(f"[STAT] {tag} Speed  mean={mu:.3f}, Ïƒ={sd:.3f}")
#     for k, (lo, hi) in bands(mu, sd).items():
#         print(f"       {k}: ({lo:.3f}, {hi:.3f}) m/s")

# # --------------------------------------------------
# # 4. QC æ©ç 
# # --------------------------------------------------
# def build_qc_mask(df: pd.DataFrame, speed_col: str) -> pd.Series:
#     """speed_col='hws' / 'vws' â†’ ç”Ÿæˆ QC å¸ƒå°”æ©ç """
#     if speed_col == "hws":
#         mask = (df["CNR"] >= CNR_LIM_H) & df["hws"].between(HWS_MIN, HWS_MAX)
#         if HEIGHT_LIM_H is not None:
#             mask &= df["height"] <= HEIGHT_LIM_H
#         if USE_LAYER_LIMITS_H:
#             for z_top, lim in HWS_LAYER_LIMITS.items():
#                 mask &= ~((df["height"] <= z_top) & (df["hws"] > lim))
#     elif speed_col == "vws":
#         # â‘  CNR + å…¨å±€éå¯¹ç§°åŒºé—´
#         mask = (df["CNR"] >= CNR_LIM_V) & df["vws"].between(VWS_MIN, VWS_MAX)
    
#         # â‘¡ é«˜åº¦ä¸Šé™
#         if HEIGHT_LIM_V is not None:
#             mask &= df["height"] <= HEIGHT_LIM_V
    
#         # â‘¢ å±‚å†…ä¸Šé™ï¼ˆåŒºåˆ†æ­£ / è´Ÿï¼‰
#         if USE_LAYER_LIMITS_V:
#             # -- ä¸Šå‡ï¼švws > 0 --
#             for (z_lo, z_hi), max_up in VWS_LAYER_LIMITS_UP.items():
#                 cond = (df["height"] > z_lo) & (df["height"] <= z_hi) & (df["vws"] > max_up)
#                 mask &= ~cond
    
#             # -- ä¸‹æ²‰ï¼švws < 0 --
#             for (z_lo, z_hi), min_dn in VWS_LAYER_LIMITS_DN.items():
#                 cond = (
#                     (df["height"] >  z_lo) &        # ä½äºè¯¥å±‚ä¸‹ç•Œä¹‹ä¸Š
#                     (df["height"] <= z_hi) &        # ä¸”ä½äºè¯¥å±‚ä¸Šç•Œä¹‹å†…
#                     (df["vws"]      <  min_dn)      # ä¸”ä¸‹æ²‰å¹…åº¦è¶…è¿‡é˜ˆå€¼ï¼ˆæ›´è´Ÿï¼‰
#                 )
#                 mask &= ~cond       # æ»¡è¶³ cond â†’ å¼‚å¸¸ï¼Œå–åå & è¿›æ€»æ©ç 

#     else:
#         raise ValueError("speed_col å¿…é¡» 'hws' æˆ– 'vws'")
#     return mask

# mask_h = build_qc_mask(raw_all, "hws")
# mask_v = build_qc_mask(raw_all, "vws")
# cleaned_h = raw_all[mask_h].reset_index(drop=True)
# cleaned_v = raw_all[mask_v].reset_index(drop=True)

# print(f"[INFO] QC åæ°´å¹³è¡Œæ•°ï¼š{len(cleaned_h):,}")
# print(f"[INFO] QC åå‚ç›´è¡Œæ•°ï¼š{len(cleaned_v):,}")

# import pandas as pd
# import dask.dataframe as dd
# from dask.diagnostics import ProgressBar


# # ----------------- 1. å®šä¹‰ä¼˜åŒ–çš„æ•°æ®ç±»å‹ -----------------
# dtype_spec = {
#     # ID ç±»åˆ—ï¼Œä½¿ç”¨ int32 èŠ‚çœç©ºé—´
#     'Settings ID': 'Int32',
#     'Resolution ID': 'Int32',
#     'Scan ID': 'Int32',
#     'LOS ID': 'Int32',
#     'Sequence ID': 'Int32',

#     # æ‰€æœ‰æµ‹é‡å€¼ï¼Œä½¿ç”¨ float32 ç²¾åº¦è¶³å¤Ÿä¸”çœç©ºé—´
#     'Azimuth [Â°]': 'float32',
#     'Elevation [Â°]': 'float32',
#     'height': 'float32',
#     'hws': 'float32',
#     'vws': 'float32',
#     'wd': 'float32',
#     'Radial Wind Speed [m/s]': 'float32',
#     'CNR': 'float32',
#     'Confidence Index [%]': 'float32',
#     'u': 'float32',
#     'v': 'float32',
#     'Level (hPa)': 'float32',
#     'ws_ci': 'float32',
#     'rws_ci': 'float32',
#     'rws': 'float32',
#     'doppler_spectrum_Mean_Error': 'float32',
#     'doppler_spectrum_width': 'float32',
#     'range_to_measurement_volume': 'float32',

#     # çŠ¶æ€ç±»åˆ—ï¼Œä½¿ç”¨ category ç±»å‹ï¼ŒèŠ‚çœç©ºé—´æ•ˆæœæœ€ä½³
#     'Confidence Index Status': 'category',
#     'ws_status': 'category',
#     'rws_status': 'category',
# }

# # ----------------- 2. åº”ç”¨æ•°æ®ç±»å‹è½¬æ¢ -----------------
# # å…ˆè½¬æ¢é™¤äº†æ—¶é—´åˆ—ä¹‹å¤–çš„æ‰€æœ‰åˆ—
# cleaned_v_optimized = cleaned_v.astype(dtype_spec)

# # å•ç‹¬å¤„ç†æ—¶é—´åˆ— 'BJT'ï¼Œè½¬æ¢ä¸ºæ ‡å‡† datetime æ ¼å¼
# # errors='coerce' ä¼šå°†æ— æ³•è½¬æ¢çš„æ—¥æœŸè®¾ä¸º NaT (Not a Time)ï¼Œé¿å…æŠ¥é”™
# #cleaned_h_optimized['BJT'] = pd.to_datetime(cleaned_h_optimized['BJT'], errors='coerce')

# # ----------------- 3. å†™å…¥ Parquet -----------------
# output_parquet = r'E:/Beijing2024/Wind Lidar/cleaned_v_data.parquet'

# # å°†ä¼˜åŒ–åçš„ Pandas DataFrame è½¬ä¸º Dask DataFrame ä»¥ä¾¿åˆ†å—å†™å…¥
# ddf = dd.from_pandas(cleaned_v_optimized, npartitions=1) # npartitionså¯æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´

# with ProgressBar():
#     ddf.to_parquet(
#         output_parquet,
#         engine='pyarrow',
#         compression='zstd'  # æˆ– 'zstd'
#     )

# print(f"æ•°æ®å·²æˆåŠŸå†™å…¥ {output_parquet}")







# # --------------------------------------------------
# # 5. ç»˜å›¾å·¥å…·
# # --------------------------------------------------
# def _ensure_raw_not_exist(fname: str, tag: str) -> bool:
#     if tag.lower() == "raw" and os.path.exists(fname):
#         print(f"[SKIP] Raw å›¾å·²å­˜åœ¨ï¼š{os.path.basename(fname)}")
#         return False
#     return True

# def scatter_cnr_speed(df, speed_col, label_tag,
#                       cnr_lim, s_min, s_max,
#                       height_lim, tag, show_qc_info):
#     """Heightâ€“Wind-Speed æ•£ç‚¹"""
#     speed_sig = f"{speed_col}{s_min}to{s_max}ms"
#     fname = (os.path.join(
#         OUT_DIR,
#         f"{label_tag}_{tag}_{TIME_TAG}.png"
#     ) if not show_qc_info else
#         os.path.join(
#             OUT_DIR,
#             f"{label_tag}_{tag}_CNR{cnr_lim}dB_{speed_sig}_z{height_lim}m_{TIME_TAG}.png"
#         ))
#     if not _ensure_raw_not_exist(fname, tag):
#         return
#     if df.empty:
#         print(f"[WARN] {label_tag} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
#         return

#     fig, ax = plt.subplots(figsize=(8,10))
#     ax.scatter(df[speed_col], df["height"], color="dodgerblue", s=12, linewidths=0)
#     ax.set_xlabel(f"{label_tag} Wind Speed (m/s)")
#     ax.set_ylabel("Height (m)")

#     if show_qc_info:
#         thres = f"CNR â‰¥ {cnr_lim} dB, {s_min} â‰¤ {speed_col} â‰¤ {s_max} m/s, z â‰¤ {height_lim} m"
#         title = f"{tag} {label_tag} Wind Speed vs Height\n({thres})\n{WINDOW_TXT}"
#     else:
#         title = f"{tag} {label_tag} Wind Speed vs Height\n{WINDOW_TXT}"
#     ax.set_title(title, fontsize=16)
#     plt.tight_layout()
#     fig.savefig(fname, dpi=150)
#     plt.close(fig)
#     print(f"[SAVED] {fname}")

# def scatter_speed_vs_cnr(df, speed_col, label_tag,
#                          cnr_lim, s_min, s_max,
#                          height_lim, tag, show_qc_info):
#     """CNRâ€“Wind-Speed æ•£ç‚¹"""
#     speed_sig = f"{speed_col}{s_min}to{s_max}ms"
#     fname = (os.path.join(
#         OUT_DIR,
#         f"CNR_vs_{label_tag}_{tag}_{TIME_TAG}.png"
#     ) if not show_qc_info else
#         os.path.join(
#             OUT_DIR,
#             f"CNR_vs_{label_tag}_{tag}_CNR{cnr_lim}dB_{speed_sig}_z{height_lim}m_{TIME_TAG}.png"
#         ))
#     if not _ensure_raw_not_exist(fname, tag):
#         return
#     if df.empty:
#         print(f"[WARN] {label_tag} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
#         return

#     fig, ax = plt.subplots(figsize=(8,8))
#     ax.scatter(df[speed_col], df["CNR"], color="dodgerblue", s=12, linewidths=0)
#     ax.set_xlabel(f"{label_tag} Wind Speed (m/s)")
#     ax.set_ylabel("CNR (dB)")

#     if show_qc_info:
#         thres = f"CNR â‰¥ {cnr_lim} dB, {s_min} â‰¤ {speed_col} â‰¤ {s_max} m/s, z â‰¤ {height_lim} m"
#         title = f"{tag} CNR vs {label_tag} Wind Speed\n({thres})\n{WINDOW_TXT}"
#     else:
#         title = f"{tag} CNR vs {label_tag} Wind Speed\n{WINDOW_TXT}"
#     ax.set_title(title, fontsize=16)
#     plt.tight_layout()
#     fig.savefig(fname, dpi=150)
#     plt.close(fig)
#     print(f"[SAVED] {fname}")

# # --------------------------------------------------
# # 6. è°ƒç”¨ç»˜å›¾
# # --------------------------------------------------
# # --- Raw ---
# scatter_cnr_speed(raw_all, "hws", "Horizontal",
#                   CNR_LIM_H, HWS_MIN, HWS_MAX, HEIGHT_LIM_H, "Raw", False)
# scatter_cnr_speed(raw_all, "vws", "Vertical",
#                   CNR_LIM_V, VWS_MIN, VWS_MAX, HEIGHT_LIM_V, "Raw", False)

# scatter_speed_vs_cnr(raw_all, "hws", "Horizontal",
#                      CNR_LIM_H, HWS_MIN, HWS_MAX, HEIGHT_LIM_H, "Raw", False)
# scatter_speed_vs_cnr(raw_all, "vws", "Vertical",
#                      CNR_LIM_V, VWS_MIN, VWS_MAX, HEIGHT_LIM_V, "Raw", False)

# # --- QC ---
# scatter_cnr_speed(cleaned_h, "hws", "Horizontal",
#                   CNR_LIM_H, HWS_MIN, HWS_MAX, HEIGHT_LIM_H, "QC", True)
# scatter_cnr_speed(cleaned_v, "vws", "Vertical",
#                   CNR_LIM_V, VWS_MIN, VWS_MAX, HEIGHT_LIM_V, "QC", True)

# scatter_speed_vs_cnr(cleaned_h, "hws", "Horizontal",
#                      CNR_LIM_H, HWS_MIN, HWS_MAX, HEIGHT_LIM_H, "QC", True)
# scatter_speed_vs_cnr(cleaned_v, "vws", "Vertical",
#                      CNR_LIM_V, VWS_MIN, VWS_MAX, HEIGHT_LIM_V, "QC", True)

# print(f"[DONE] æ‰€æœ‰å›¾å·²è¾“å‡ºè‡³ {OUT_DIR}")

# def scatter_compare_in_out(df_good, df_raw, mask,  # good=é€šè¿‡QC
#                            x_col, y_col,           # è½´å˜é‡
#                            x_lab, y_lab,           # è½´æ ‡ç­¾
#                            title_tag, fname_tag):  # å›¾æ ‡é¢˜ & æ–‡ä»¶ç­¾å
#     """
#     åŒå±‚æ•£ç‚¹ï¼šQC é€šè¿‡ç‚¹(è“) + Outlier(çº¢)
#     df_good : é€šè¿‡ QC çš„è¡Œ
#     df_raw  : åŸå§‹å…¨éƒ¨è¡Œ
#     mask    : å¸ƒå°”æ©ç  (True=good, False=outlier)
#     x_col/y_col : åˆ—å
#     """
#     fname = os.path.join(
#         OUT_DIR,
#         f"{fname_tag}_Compare_{TIME_TAG}.png"
#     )
#     # è‹¥æƒ³é¿å…é‡å¤ç”Ÿæˆå¯åŠ è·³è¿‡é€»è¾‘
#     fig, ax = plt.subplots(figsize=(8, 8 if 'CNR' in [x_lab, y_lab] else 10))
#     # ---- â‘¡ Outlierï¼ˆçº¢ï¼‰----
#     df_out = df_raw[~mask]
#     ax.scatter(df_out[x_col], df_out[y_col],
#                s=12, linewidths=0, color="red", label="outlier")

#     # ---- â‘  QC é€šè¿‡ï¼ˆè“ï¼‰----
#     ax.scatter(df_good[x_col], df_good[y_col],
#                s=12, linewidths=0, color="dodgerblue", label="QC passed")


#     ax.set_xlabel(x_lab)
#     ax.set_ylabel(y_lab)
#     ax.set_title(f"{title_tag}\n{WINDOW_TXT}", fontsize=16)

#     # legend å³ä¸Š
#     ax.legend(loc="upper right", markerscale=1.2, fontsize=12, frameon=True)

#     plt.tight_layout()
#     fig.savefig(fname, dpi=150)
#     plt.close(fig)
#     print(f"[SAVED] {fname}")

# # â€”â€” é¢å¤–ï¼šoutlier è¡Œ â€”â€” #
# outlier_h = raw_all[~mask_h].reset_index(drop=True)
# outlier_v = raw_all[~mask_v].reset_index(drop=True)

# # ---------- 6-B. Compareï¼šQC vs Outlier ----------

# # 1) CNR vs HWS
# scatter_compare_in_out(cleaned_h, raw_all, mask_h,
#                        x_col="hws", y_col="CNR",
#                        x_lab="Horizontal Wind Speed (m/s)",
#                        y_lab="CNR (dB)",
#                        title_tag="CNR vs Horizontal Wind Speed (QC vs Outlier)",
#                        fname_tag="CNR_vs_HWS")

# # 2) CNR vs VWS
# scatter_compare_in_out(cleaned_v, raw_all, mask_v,
#                        x_col="vws", y_col="CNR",
#                        x_lab="Vertical Wind Speed (m/s)",
#                        y_lab="CNR (dB)",
#                        title_tag="CNR vs Vertical Wind Speed (QC vs Outlier)",
#                        fname_tag="CNR_vs_VWS")

# # 3) Height vs HWS
# scatter_compare_in_out(cleaned_h, raw_all, mask_h,
#                        x_col="hws", y_col="height",
#                        x_lab="Horizontal Wind Speed (m/s)",
#                        y_lab="Height (m)",
#                        title_tag="Height vs Horizontal Wind Speed (QC vs Outlier)",
#                        fname_tag="Height_vs_HWS")

# # 4) Height vs VWS
# scatter_compare_in_out(cleaned_v, raw_all, mask_v,
#                        x_col="vws", y_col="height",
#                        x_lab="Vertical Wind Speed (m/s)",
#                        y_lab="Height (m)",
#                        title_tag="Height vs Vertical Wind Speed (QC vs Outlier)",
#                        fname_tag="Height_vs_VWS")

cleaned_v = pd.read_parquet("E:\\Beijing2024\\Wind Lidar\\cleaned_v_data.parquet\\cleaned_v_data.parquet", engine='pyarrow')
cleaned_h = pd.read_parquet("E:\\Beijing2024\\Wind Lidar\\cleaned_h_data.parquet\\cleaned_h_data.parquet", engine='pyarrow')

# --------------------------------------------------
# 7. å…ˆæ—¶é—´å¹³å‡ (ç”¨ u/v) â†’ å†å‚ç›´æ’å€¼
# --------------------------------------------------

TARGET_Z = np.array([80, 140, 200, 280])   # m
COLS     = [f"{z}m" for z in TARGET_Z]

def interp_profile(group, val_col):
    """å•æ¡æ—¶é—´å»“çº¿ -> 4 ä¸ªæ’å€¼å€¼ï¼›ç¦æ­¢å¤–æ¨"""
    z   = group["height"].values
    val = group[val_col].values
    msk = ~np.isnan(val)
    z, val = z[msk], val[msk]

    if len(z) < 4:              # ç‚¹å¤ªå°‘ï¼Œå…¨éƒ¨ NaN
        return np.full_like(TARGET_Z, np.nan, dtype=float)

    idx = np.argsort(z)         # ä¿è¯é«˜åº¦å•è°ƒ
    z, val = z[idx], val[idx]

    f = interp1d(z, val, kind="linear",
                 bounds_error=False, fill_value=np.nan)
    return f(TARGET_Z)

def interpolate_df(df, val_col):
    """
    æŒ‰æ—¶é—´æˆ³ groupby åå¯¹ val_col åšå‚ç›´æ’å€¼ï¼Œ
    è¾“å‡ºï¼šindex = BJTï¼Œcolumns = [80m, 140m, 200m, 280m]
    """
    arr = df.groupby("BJT")[["height", val_col]].apply(
        lambda g: interp_profile(g, val_col)
    ).to_numpy()
    out = pd.DataFrame(
        np.vstack(arr), index=df["BJT"].unique(), columns=COLS
    ).sort_index()
    return out


# --------- 7.1 æ°´å¹³é£ï¼šç”¨å·²æœ‰ u/vï¼Œå…ˆæ—¶é—´å¹³å‡å†æ’å€¼ ---------
def resample_uv_then_interp(df_h,
                            freqs=("1min",  "60min")):#"5min", "30min",
    """
    df_h: å¿…é¡»è‡³å°‘åŒ…å« ['BJT', 'height', 'u', 'v'] åˆ—
    è¿”å›ï¼š
      hws_avg: {freq: DataFrame (BJT Ã— 4 é«˜åº¦)}
      wd_avg:  {freq: DataFrame (BJT Ã— 4 é«˜åº¦)}
    """
    # åªå–éœ€è¦çš„åˆ—ï¼Œä¸¢æ‰ u/v ä¸º NaN çš„è¡Œ
    df = df_h[["BJT", "height", "u", "v"]].copy()
    df = df.dropna(subset=["u", "v"])

    # ä»¥ BJT ä¸ºæ—¶é—´ç´¢å¼•ï¼Œæ–¹ä¾¿ resample
    df = df.set_index("BJT")

    hws_out = {}
    wd_out  = {}

    for freq in freqs:
        # æŒ‰é«˜åº¦åˆ†ç»„ï¼Œå†å¯¹æ—¶é—´åšé‡é‡‡æ ·å¹³å‡
        # ç»“æœåˆ—ï¼š["height", "BJT", "u", "v"]
        uv_avg = (
            df
            .groupby("height")[["u", "v"]]
            .resample(freq)
            .mean()
            .reset_index()
        )

        # --- ç”¨å¹³å‡åçš„ u/v é‡ç®—é£é€Ÿå’Œé£å‘ ---
        u = uv_avg["u"].to_numpy()
        v = uv_avg["v"].to_numpy()

        # é£é€Ÿ
        hws = np.sqrt(u * u + v * v)

        # é£å‘ï¼ˆæ°”è±¡é£å‘ï¼Œæ¥è‡ªçš„æ–¹å‘ï¼Œå•ä½ï¼šåº¦ï¼‰
        # atan2(y, x) = atan2(v, u)
        wd_rad = np.arctan2(v, u)
        wd_deg = (270.0 - np.degrees(wd_rad)) % 360.0

        uv_avg["hws"] = hws
        uv_avg["wd"]  = wd_deg

        # --- å¯¹è¯¥æ—¶é—´åˆ†è¾¨ç‡ä¸‹çš„ hws / wd åšå‚ç›´æ’å€¼ ---
        hws_i = interpolate_df(uv_avg[["BJT", "height", "hws"]], "hws")
        wd_i  = interpolate_df(uv_avg[["BJT", "height", "wd"]],  "wd")

        hws_out[freq] = hws_i
        wd_out[freq]  = wd_i

    return hws_out, wd_out


# --------- 7.2 å‚ç›´é£ï¼šæ ‡é‡å…ˆæ—¶é—´å¹³å‡ï¼Œå†æ’å€¼ ---------
def resample_scalar_then_interp(df, val_col,
                                freqs=("1min", "60min")):#"5min", "30min",
    """
    å¯¹æ ‡é‡ï¼ˆå¦‚ vwsï¼‰å…ˆæŒ‰é«˜åº¦+æ—¶é—´å¹³å‡ï¼Œå†æ’å€¼åˆ° TARGET_Z
    è¿”å›ï¼š{freq: DataFrame (BJT Ã— 4 é«˜åº¦)}
    """
    df2 = df.set_index("BJT")
    out = {}

    for freq in freqs:
        avg = (
            df2
            .groupby("height")[[val_col]]
            .resample(freq)
            .mean()
            .reset_index()
        )
        out[freq] = interpolate_df(avg[["BJT", "height", val_col]], val_col)

    return out


from scipy.interpolate import interp1d
import numpy as np
import pandas as pd

def time_interp_60min_small_gaps(df_60, windows):
    """
    å¯¹ 60min å¹³å‡é£é€Ÿæ²¿æ—¶é—´è½´åšçº¿æ€§æ’å€¼ï¼Œè§„åˆ™ï¼š
      - åªåœ¨ç»™å®šçš„è‹¥å¹²æ—¶é—´çª— windows å†…æ’å€¼ï¼›
      - åªå¡«â€œè¿ç»­ NaN é•¿åº¦ <= 2â€çš„å°æ´ï¼›
      - è¿™ä¸€æ®µ NaN å‰åå¿…é¡»éƒ½æœ‰é NaN æ•°æ®ï¼›
      - ç¦æ­¢å¤–æ¨ï¼šåªåœ¨å…¨å±€æœ‰æ•ˆæ•°æ®æ—¶é—´èŒƒå›´å†…æ’å€¼ã€‚

    å‚æ•°
    ----
    df_60 : DataFrame
        index ä¸º DatetimeIndexï¼ˆ60minï¼‰ï¼Œåˆ—ä¸ºå„é«˜åº¦ï¼ˆå¦‚ '80m','140m','200m','280m'ï¼‰
    windows : list[tuple[pd.Timestamp, pd.Timestamp]]
        ä¾‹å¦‚ï¼š
        [
            (pd.Timestamp("2024-06-06 00:00:00"), pd.Timestamp("2024-06-10 23:59:59")),
            (pd.Timestamp("2024-08-05 00:00:00"), pd.Timestamp("2024-08-10 23:59:59")),
        ]
    """
    df = df_60.copy()

    # æ—¶é—´ â†’ æ•°å€¼ï¼ˆç§’ï¼‰ä½œä¸ºè‡ªå˜é‡
    t = df.index.view("int64") / 1e9   # nanosecond -> second

    # çª—å£è½¬æˆç§’
    win_secs = []
    for start, end in windows:
        start = pd.to_datetime(start)
        end   = pd.to_datetime(end)
        s_sec = start.value / 1e9
        e_sec = end.value   / 1e9
        win_secs.append((s_sec, e_sec))

    for col in df.columns:
        y = df[col].values.astype(float)
        mask_valid = ~np.isnan(y)

        # æœ‰æ•ˆç‚¹å¤ªå°‘ï¼Œä¸åšä»»ä½•æ’å€¼
        if mask_valid.sum() < 2:
            continue

        t_valid = t[mask_valid]
        y_valid = y[mask_valid]

        t_min = t_valid.min()
        t_max = t_valid.max()

        # æ„é€ çº¿æ€§æ’å€¼å‡½æ•°ï¼ˆåªç”¨äº t_min~t_max ä¹‹é—´ï¼‰
        f = interp1d(
            t_valid, y_valid,
            kind="linear"
        )

        y_new = y.copy()

        # ---- æ‰¾è¿ç»­ NaN åŒºæ®µ ----
        nan_mask = np.isnan(y)
        n = len(y)
        i = 0
        while i < n:
            if nan_mask[i]:
                # èµ·ç‚¹
                start = i
                # æ‰¾è¿™ä¸€æ®µè¿ç»­ NaN çš„ç»“æŸä½ç½®
                while i + 1 < n and nan_mask[i + 1]:
                    i += 1
                end = i
                length = end - start + 1

                # æ¡ä»¶ 1ï¼šé•¿åº¦ <= 2
                # æ¡ä»¶ 2ï¼šä¸¤ä¾§æœ‰é NaNï¼ˆä¸æ˜¯é¦–å°¾ï¼Œè€Œä¸”å·¦å³é‚»æ¥ç‚¹éƒ½æ˜¯ validï¼‰
                if (length <= 3 and
                    start > 0 and end < n - 1 and
                    (not nan_mask[start - 1]) and
                    (not nan_mask[end + 1])):

                    # è¿™ä¸€å°æ®µ NaN é€ç‚¹åˆ¤æ–­æ˜¯å¦åœ¨çª—å£å†… & åœ¨æœ‰æ•ˆæ•°æ®æ—¶é—´èŒƒå›´å†…
                    for j in range(start, end + 1):
                        tj = t[j]

                        # åœ¨ä»»æ„ä¸€ä¸ªçª—å£å†…ï¼Ÿ
                        in_window = any((tj >= ws) and (tj <= we)
                                        for (ws, we) in win_secs)
                        if (not in_window):
                            continue

                        # ç¦æ­¢å¤–æ¨ï¼šå¿…é¡»åœ¨ [t_min, t_max] å†…
                        if (tj < t_min) or (tj > t_max):
                            continue

                        # ç¬¦åˆæ‰€æœ‰æ¡ä»¶ï¼Œæ‰æ’å€¼
                        y_new[j] = float(f(tj))

                # ç§»åŠ¨åˆ°ä¸‹ä¸€æ®µ
                i += 1
            else:
                i += 1

        df[col] = y_new

    return df

# --------- 7.3 è°ƒç”¨ ---------
# æ°´å¹³é£ï¼šå¾—åˆ°æ¯ä¸ªæ—¶é—´åˆ†è¾¨ç‡ä¸‹æ’å€¼åçš„ hwsã€wd
hws_avg, wd_avg = resample_uv_then_interp(cleaned_h)

# å‚ç›´é£ï¼šå¾—åˆ°æ¯ä¸ªæ—¶é—´åˆ†è¾¨ç‡ä¸‹æ’å€¼åçš„ vws
vws_avg = resample_scalar_then_interp(cleaned_v, "vws")

# å®šä¹‰ä¸¤ä¸ªæ—¶é—´çª—ï¼ˆç¤ºä¾‹ï¼ŒæŒ‰ä½ è‡ªå·±çš„æ—¶é—´æ”¹ï¼‰
WIN1 = (pd.Timestamp("2024-06-06 00:00:00"), pd.Timestamp("2024-06-10 23:59:59"))
WIN2 = (pd.Timestamp("2024-08-04 00:00:00"), pd.Timestamp("2024-08-10 23:59:59"))

windows = [WIN1, WIN2]

# å¯¹ 60min å¹³å‡é£é€Ÿï¼Œåœ¨ä¸¤ä¸ªæŒ‡å®šæ—¶é—´çª—å†…åšæ—¶é—´æ’å€¼ï¼ˆç¦æ­¢å¤–æ¨ï¼‰
hws_avg["60min"] = time_interp_60min_small_gaps(hws_avg["60min"], windows)
hws_avg["1min"] = time_interp_60min_small_gaps(hws_avg["1min"], windows)

# â€”â€” ç¤ºä¾‹ï¼šè®¿é—®æ°´å¹³é£é€Ÿ 5 min å‡å€¼ DataFrame â€”â€”
# hws_avg["5min"]
# vws_avg["60min"]

# å¦‚éœ€ä¿å­˜ï¼š
# hws_avg["5min"].to_csv(os.path.join(OUT_DIR, "hws_5min_mean.csv"))
# vws_avg["60min"].to_csv(os.path.join(OUT_DIR, "vws_60min_mean.csv"))



#80-75m    140-150m   200-200m    280-275m

# import seaborn as sns
# import matplotlib.pyplot as plt
# import matplotlib.ticker as ticker
# from mpl_toolkits.axes_grid1.inset_locator import inset_axes
# import matplotlib.patches as mpatches   # ç”¨æ¥ç”Ÿæˆè‡ªå®šä¹‰å›¾ä¾‹æ‰‹æŸ„

# plt.figure(figsize=(6, 6))

# # ---------- 1. ä¸»ç›´æ–¹å›¾ + KDE ----------
# ax = sns.histplot(
#     raw_all['hws'],
#     bins=50,
#     kde=True,
#     color='blue',
#     line_kws={'color': 'black', 'lw': 1.5},
#     ax=None,              # è®© seaborn è‡ªåŠ¨åˆ›å»ºè½´
#     label='HWS Histogram'     # ç»™ç›´æ–¹å›¾ä¸€ä¸ªåå­—
# )

# # å•ç‹¬ç»™ KDE çº¿æ¡æ”¹æ ‡ç­¾
# ax.lines[0].set_label('Gaussian KDE')

# # ---------- 2. ä¸‹æ–¹åµŒå…¥ç®±çº¿å›¾ ----------
# # åœ¨ä¸»åæ ‡ç³»å†…éƒ¨å†å¼€ä¸€æ¡â€œæ¨ªæ¡å½¢â€å­åæ ‡è½´
# ax_box = inset_axes(
#     ax,
#     width="100%", height="10%",      # 100% å®½ã€10% é«˜
#     loc='lower center',
#     bbox_to_anchor=(0, -0.28, 1, 1), # å‘ä¸‹åç§»ä¸€äº›ï¼Œä¸é®ä½ç›´æ–¹å›¾
#     bbox_transform=ax.transAxes,
#     borderpad=0
# )

# sns.boxplot(
#     x=raw_all['hws'],
#     ax=ax_box,
#     width=0.6,
#     color='gray',
#     fliersize=0            # ä¸æ˜¾ç¤ºå¼‚å¸¸å€¼ç‚¹
# )

# # ç®±çº¿å›¾å­è½´ç¾åŒ–ï¼ˆå»æ‰ y è½´ & å­—æ³¨ï¼‰
# ax_box.set(yticks=[], ylabel='', xlabel='')
# for spine in ax_box.spines.values():
#     spine.set_color('black')
#     spine.set_linewidth(2)

# # ---------- 3. è½´åˆ»åº¦ & æ–‡å­— ----------
# ax.xaxis.set_major_locator(ticker.MultipleLocator(20))
# ax.yaxis.set_major_formatter(ticker.ScalarFormatter(useMathText=False))
# ax.yaxis.offsetText.set_visible(False)   # éšè—ç§‘å­¦è®¡æ•° offset
# ax.set_ylabel(r"Frequency ($\times10^{6}$)", fontsize=14)
# ax.set_xlabel("Horizontal Wind Speed (m/s)", fontsize=14)
# ax.set_title("Distribution of Horizontal Wind Speed", pad=0, fontsize=14)

# # åæ ‡è½´è¾¹æ¡†
# for spine in ['left', 'right', 'top', 'bottom']:
#     ax.spines[spine].set_color('black')
#     ax.spines[spine].set_linewidth(2)

# # ä¸»/å‰¯åˆ»åº¦
# ax.tick_params(axis='both', which='major', direction='out',
#                length=12, width=2, bottom=True, left=True)
# ax.tick_params(axis='both', which='minor', direction='out',
#                length=6, width=2, bottom=True, left=True)
# ax.grid(False)

# # ---------- 4. å›¾ä¾‹ ----------
# # è‡ªå®šä¹‰ç®±çº¿å›¾æ‰‹æŸ„ï¼ˆç°è‰²çŸ©å½¢ï¼‰
# box_handle = mpatches.Patch(facecolor='gray', edgecolor='black', label='Box plot')
# handles, labels = ax.get_legend_handles_labels()
# handles.append(box_handle); labels.append('HWS Box plot')

# ax.legend(handles, labels, loc='upper right', frameon=False)

# plt.tight_layout()
# plt.show()


"""
å…ˆå¤„ç†å¾®æ³¢è¾å°„è®¡æ•°æ®
-------------------------------------------------------------------
"""

# ---------- 0. é€‰æ‹©å¹¶æ ‡å‡†åŒ–åˆ— ---------- #
columns_needed = ['timestamps', 'height_plus_alt', 'T(K)', 'RH(%)']
mwr_selected   = df_mwr[columns_needed].copy()
mwr_selected['timestamps'] = (
    pd.to_datetime(mwr_selected['timestamps']) + pd.Timedelta(hours=8)
)
mwr_selected = mwr_selected.rename(columns={'height_plus_alt': 'height_m'})  # è§‚æµ‹é«˜åº¦ (m)

# ---------- 1. é€è§†ä¸ºâ€œè¡Œ=æ—¶é—´ã€åˆ—=é«˜åº¦â€ ---------- #
temperature_wide = (
    mwr_selected
    .pivot_table(index='timestamps', columns='height_m', values='T(K)')
    .sort_index(axis=1)
)

humidity_wide = (
    mwr_selected
    .pivot_table(index='timestamps', columns='height_m', values='RH(%)')
    .sort_index(axis=1)
)

# ---------- 2. å‚ç›´çº¿æ€§æ’å€¼ï¼ˆç¦æ­¢å¤–æ¨ï¼‰ ---------- #
target_heights_m = [80, 140, 200, 280]

def interpolate_to_target_levels(wide_dataframe, target_levels):
    """åœ¨åˆ—æ–¹å‘åšçº¿æ€§æ’å€¼ï¼Œä»…ä¿ç•™ç›®æ ‡é«˜åº¦ï¼›è‹¥ç¼ºå±‚åˆ™æ•´è¡Œå‰”é™¤ã€‚"""
    # å…ˆæŠŠç›®æ ‡é«˜åº¦å¹¶å…¥åˆ—ï¼Œå†æ’å€¼
    dataframe_with_targets = wide_dataframe.reindex(
        columns=sorted(set(wide_dataframe.columns).union(target_levels))
    )
    interpolated_dataframe = dataframe_with_targets.interpolate(axis=1, method='values')
    # ä»…ä¿ç•™ç›®æ ‡é«˜åº¦åˆ—ï¼Œå¹¶å»æ‰ä»å­˜åœ¨ NaN çš„è¡Œï¼ˆä»£è¡¨å¤–æ¨ä¼šäº§ç”Ÿç¼ºå€¼ï¼‰
    return interpolated_dataframe[target_levels].dropna(how='any')

temperature_interpolated = interpolate_to_target_levels(temperature_wide, target_heights_m)
humidity_interpolated    = interpolate_to_target_levels(humidity_wide,    target_heights_m)

# ---------- 3. åˆå¹¶æ¸©åº¦ä¸æ¹¿åº¦å‰–é¢ ---------- #
# å¾—åˆ°å¤šå±‚åˆ—ç´¢å¼•ï¼šç¬¬ä¸€å±‚å˜é‡åï¼Œç¬¬äºŒå±‚é«˜åº¦
combined_interpolated_profiles = pd.concat(
    {'T(K)': temperature_interpolated, 'RH(%)': humidity_interpolated},
    axis=1
).sort_index(axis=1, level=0)

# ---------- 4. æ—¶é—´å¹³å‡ ---------- #
mean_1min_profiles  = combined_interpolated_profiles.resample('1min').mean().dropna(how='all')
mean_5min_profiles  = combined_interpolated_profiles.resample('5min').mean().dropna(how='all')
mean_30min_profiles  = combined_interpolated_profiles.resample('30min').mean().dropna(how='all')
mean_60min_profiles = combined_interpolated_profiles.resample('60min').mean().dropna(how='all')

# # ---------- 5. ä¿å­˜ ---------- #
# mean_5min_profiles.to_parquet('MWR_mean_5min_80-280m.parquet')
# mean_60min_profiles.to_parquet('MWR_mean_60min_80-280m.parquet')
# ä¹Ÿå¯ä»¥ç”¨ Excelï¼š
# mean_5min_profiles.to_excel('MWR_mean_5min_80-280m.xlsx',   merge_cells=False)
# mean_60min_profiles.to_excel('MWR_mean_60min_80-280m.xlsx', merge_cells=False)
"""
Tower multi-level timeâ€“series (lines) + interâ€‘dataset scatter matrix

1min
-------------------------------------------------------------------
"""
#####
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.gridspec import GridSpec
from matplotlib.ticker import MultipleLocator, AutoMinorLocator, FixedLocator
from matplotlib.ticker import FuncFormatter

# --------------------------------------------------
# 0. Constants & rcParams
# --------------------------------------------------
HEIGHTS = [280, 200, 140, 80]
VAR_GROUPS = ["Temp", "RH", "HWS", "VWS"]
COLMAP = dict(MWR="red", 
              LiDAR="darkorange",
              TowerAvg="black", 
              TowerTurb="slategray", 
              CRA="magenta", 
              ERA5="blue", 
              )

DATA_START = pd.Timestamp("2024-06-05 00:00")
DATA_END   = pd.Timestamp("2024-08-11 00:00")
# æ•°æ®ç­›é€‰çª—å£ï¼ˆåªæŠŠè¿™æ®µæ—¶é—´çš„æ•°æ®è¯»è¿›æ¥ã€åš QCï¼‰
PLOT_START = pd.Timestamp("2024-08-05 01:30")
PLOT_END   = pd.Timestamp("2024-08-11 00:00")
# ==== æ–°å¢ï¼šä¸¤ä¸ªä¸è¿ç»­çš„ç»˜å›¾æ—¶é—´çª—å£ï¼ˆè‡ªå·±æ”¹æˆæƒ³è¦çš„æ—¶é—´æ®µï¼‰ ====
SEG1_START = pd.Timestamp("2024-06-06 00:00")
SEG1_END   = pd.Timestamp("2024-06-10 00:00")
SEG2_START = pd.Timestamp("2024-08-05 01:30")
SEG2_END   = pd.Timestamp("2024-08-11 00:00")

ALPHA_MAP = {
    'MWR'      : 0.4,
    'TowerAvg' : 0.4,
    'TowerTurb': 0.4,
    'CRA'      : 0.6,
    'ERA5'     : 0.6,
    'LiDAR'    : 0.4,
}
ALPHA_MAP2 = {
    'MWR'      : 1,
    'TowerAvg' : 1,
    'TowerTurb': 0.5,
    'CRA'      : 1,
    'ERA5'     : 1,
    'LiDAR'    : 0.5,
}

LABEL_MAP = {
    'MWR'      : 'MWR',
    'LiDAR'    : 'DWL',
    'TowerAvg' : 'AWS',
    'TowerTurb': 'ECM',#eddy covariance flux measurement system
    'CRA'      : 'CRA',
    'ERA5'     : 'ERA5',
}
# axis limits for each variable
VAR_RANGE = {
    'Temp': (288, 310),
    'RH'  : (10, 103),
    'HWS' : (-0.99, 18),
    'VWS' : (-7, 4)
}
title_map = {
    'Temp': 'Temperature (T)',
    'RH'  : 'Relative Humidity (RH)',
    'HWS' : 'Horizontal Wind Speed (HWS)',
    'VWS' : 'Vertical Wind Speed (VWS)'
}
OUT_DIR = r"E:\Beijing2024\å‡ºå›¾TIF"; os.makedirs(OUT_DIR, exist_ok=True)
OUT_FILE = os.path.join(OUT_DIR, "Tower_MultiLevel_TimeScatter2-1min3.tif")
plt.rcParams.update({    
    'font.size': 50,
    'font.family': 'sans-serif',                # å…ˆæŒ‡å®šå®¶æ—
    'font.sans-serif': ['Arial', 'DejaVu Sans'],     # æŠŠ Arial è®¾ä¸ºé¦–é€‰
    'axes.titlepad': 8,
    'legend.fontsize': 50,
    'axes.labelsize': 50,
    'xtick.labelsize': 50,
    'ytick.labelsize': 50,
    'xtick.major.size': 30,
    'xtick.minor.size': 15,
    'ytick.major.size': 30,
    'ytick.minor.size': 15,
    'xtick.direction': 'out',
    'ytick.direction': 'out',
    'xtick.major.width': 6,
    'xtick.minor.width': 6,
    'ytick.major.width': 6,
    'ytick.minor.width': 6,
})
# --------------------------------------------------
# 1. Helpers
# --------------------------------------------------

def ensure_dt(ser: pd.Series) -> pd.Series:
    ser = ser.copy(); ser.index = pd.to_datetime(ser.index); return ser.sort_index()

def pivot_height(df: pd.DataFrame, *, idx: str, col: str, val: str, h: int) -> pd.Series:
    tmp = df.reset_index(); tmp[idx] = pd.to_datetime(tmp[idx])
    return ensure_dt(tmp.pivot(index=idx, columns=col, values=val).loc[:, h])

def align_x_to_ref(ref: pd.Series, other: pd.Series) -> pd.DataFrame:
    return pd.concat([ref, other], axis=1, join='inner').dropna(how='any')

# --------------------------------------------------
# 2.  Build Series dictionary
# --------------------------------------------------
turb_calibrated_1min['rh'] = turb_calibrated_1min['rh'].clip(upper=100)
series_dict = {v: {h: {} for h in HEIGHTS} for v in VAR_GROUPS}

# ---- Temperature -----------------------------------------------------------
for h in HEIGHTS:
    series_dict['Temp'][h]['TowerAvg']  = pivot_height(tieta_1min, idx='timestamps', col='H(m)', val='T(K)_tieta', h=h)
    series_dict['Temp'][h]['TowerTurb'] = pivot_height(turb_calibrated_1min, idx='timestamps', col='Height', val='T (K)', h=h)
    series_dict['Temp'][h]['MWR']  = ensure_dt(mean_1min_profiles.xs('T(K)', level=0, axis=1)[h])
    series_dict['Temp'][h]['CRA']       = ensure_dt(
        CRA_interp_to_65_80_280.query('height_plus_alt == @h').set_index('BJT')['Temp (K)'])
    series_dict['Temp'][h]['ERA5']      = ensure_dt(
        ERA5_interp_to_65_80_280.query('height == @h').set_index('BJT')['t'])

# ---- Relative Humidity -----------------------------------------------------
for h in HEIGHTS:
    series_dict['RH'][h]['TowerAvg']  = pivot_height(tieta_1min, idx='timestamps', col='H(m)', val='RH_tieta', h=h)
    series_dict['RH'][h]['TowerTurb'] = pivot_height(turb_calibrated_1min, idx='timestamps', col='Height', val='rh', h=h)
    series_dict['RH'][h]['MWR']  = ensure_dt(mean_1min_profiles.xs('RH(%)', level=0, axis=1)[h])
    series_dict['RH'][h]['CRA']       = ensure_dt(
        CRA_interp_to_65_80_280.query('height_plus_alt == @h').set_index('BJT')['rh (%)'])
    series_dict['RH'][h]['ERA5']      = ensure_dt(
        ERA5_interp_to_65_80_280.query('height == @h').set_index('BJT')['r'])

# ---- Horizontal Wind Speed -------------------------------------------------
hws_qc_1min = (
    hws_avg["1min"]
    .rename(columns=lambda x: x.replace('m', ''))  # å…ˆå¤„ç†åˆ—åï¼ˆç§»é™¤'m'ï¼‰
    .stack()
    .reset_index()
    .rename(columns={'level_1': 'height', 0: 'hws'})
    .astype({'height': int})  # ç¡®ä¿heightä¸ºæ•´æ•°
)

for h in HEIGHTS:
    series_dict['HWS'][h]['LiDAR']    = ensure_dt(
        hws_qc_1min.query('height == @h').set_index('level_0')['hws'])
    series_dict['HWS'][h]['TowerAvg'] = pivot_height(tieta_1min, idx='timestamps', col='H(m)', val='ws_tieta', h=h)
    series_dict['HWS'][h]['TowerTurb']= pivot_height(turb_calibrated_1min, idx='timestamps', col='Height', val='hws_corrected', h=h)
    series_dict['HWS'][h]['CRA']      = ensure_dt(
        CRA_interp_to_65_80_280.query('height_plus_alt == @h').set_index('BJT')['hws(m/s)'])
    series_dict['HWS'][h]['ERA5']     = ensure_dt(
        ERA5_interp_to_65_80_280.query('height == @h').set_index('BJT')['hws(m/s)'])

# ---- Vertical Wind Speed ---------------------------------------------------
vws_qc_1min = (
    vws_avg["1min"]
    .rename(columns=lambda x: x.replace('m', ''))  # å…ˆå¤„ç†åˆ—åï¼ˆç§»é™¤'m'ï¼‰
    .stack()
    .reset_index()
    .rename(columns={'level_1': 'height', 0: 'vws'})
    .astype({'height': int})  # ç¡®ä¿heightä¸ºæ•´æ•°
)

for h in HEIGHTS:
    series_dict['VWS'][h]['LiDAR']    = ensure_dt(
        vws_qc_1min.reset_index().query('height == @h').set_index('level_0')['vws'])
    series_dict['VWS'][h]['TowerTurb'] = pivot_height(turb_calibrated_1min, idx='timestamps', col='Height', val='W (m/s)', h=h)
    series_dict['VWS'][h]['CRA']       = ensure_dt(
        CRA_interp_to_65_80_280.query('height_plus_alt == @h').set_index('BJT')['vws(10â»Â² {m/s})'] * -1)
    series_dict['VWS'][h]['ERA5']      = ensure_dt(
        ERA5_interp_to_65_80_280.query('height == @h').set_index('BJT')['vws(10â»Â² {m/s})'] * -100)

for v in VAR_GROUPS:
    for h in HEIGHTS:
        for src, ser in series_dict[v][h].items():
            series_dict[v][h][src] = ser.loc[DATA_START:DATA_END]

series_dict_1min = series_dict
# ==== å®šä¹‰ä¸¤ä¸ªæ—¶é—´çª—å£ ====
WIN1_START = pd.Timestamp("2024-06-06 00:00")   # æ–°å¢çª—å£ï¼š6æœˆ6â€“10æ—¥
WIN1_END   = pd.Timestamp("2024-06-10 00:00")

WIN2_START = PLOT_START                         # åŸæ¥çš„ 8 æœˆçª—å£
WIN2_END   = PLOT_END

def make_month_first_formatter(first_date):
    """
    ç¬¬ä¸€ä¸ª tick æ˜¾ç¤º 'Jun 06'ï¼Œåé¢çš„ tick åªæ˜¾ç¤º '07', '08' ...
    first_date: è¿™ä¸ªæ—¶é—´æ®µçš„èµ·å§‹æ—¥æœŸï¼ˆæ¯”å¦‚ WIN1_START æˆ– WIN2_STARTï¼‰
    """
    first_date = pd.to_datetime(first_date).normalize()

    def _fmt(x, pos=None):
        dt = mdates.num2date(x)          # matplotlib å†…éƒ¨æµ®ç‚¹ -> datetime
        d  = pd.Timestamp(dt).normalize()

        if d == first_date:
            # ç¬¬ä¸€ä¸ªåˆ»åº¦ï¼šè‹±æ–‡æœˆä»½ç¼©å†™ + æ—¥
            return d.strftime('%b %d')   # ä¾‹å¦‚ 'Jun 06'
        else:
            # å…¶å®ƒåˆ»åº¦ï¼šåªæ˜¾ç¤ºæ—¥
            return d.strftime('%d')      # ä¾‹å¦‚ '07'
    return FuncFormatter(_fmt)

# --------------------------------------------------
# 3. Plot with broken x-axis
# --------------------------------------------------
fig = plt.figure(figsize=(74, 60))  # , constrained_layout=True
outer = GridSpec(2, 2, figure=fig, hspace=0.22, wspace=0.125)

for g_idx, var in enumerate(VAR_GROUPS):
    row, col = divmod(g_idx, 2)
    gspec = outer[row, col].subgridspec(
        len(HEIGHTS), 2,
        width_ratios=[3, 1.2],
        wspace=0.18,
        hspace=0.55
    )

    # column header
    ax_head = fig.add_subplot(gspec[0, 0])
    ax_head.axis('off')
    if var == 'VWS':
        ax_head.set_title(
            "Vertical Wind Speed (VWS)\n"           # ç¬¬ä¸€è¡Œæ™®é€šæ–‡å­—ï¼Œè‡ªåŠ¨æ˜¯æ­£ä½“
            r"$(VWS_{80/140/200/280}^{\mathrm{ERA5,CRA}}\times 35)$",  # ç¬¬äºŒè¡Œæ•°å­¦å…¬å¼ï¼Œä¿ç•™ä¸Šä¸‹æ ‡
            pad=35, x=0.5, fontweight='bold', fontsize=60  # æ•´ä½“åŠ ç²—ï¼Œç¬¬ä¸€è¡Œè‚¯å®šæ˜¯ç²—ä½“
        )
    else:
        ax_head.set_title(title_map.get(var, var),
                          pad=35, fontweight='bold', fontsize=60)

    vmin, vmax = VAR_RANGE[var]
    
    for r_idx, h in enumerate(HEIGHTS):
        # ---------------- Line with broken x-axis ------------------
        # å·¦åˆ—å†æ‹†æˆä¸¤ä¸ªå­è½´ï¼šå·¦=6 æœˆï¼Œå³=8 æœˆ
        line_gs = gspec[r_idx, 0].subgridspec(1, 2, width_ratios=[1, 1],
                                              wspace=0.05)
        ax_left  = fig.add_subplot(line_gs[0, 0])
        ax_right = fig.add_subplot(line_gs[0, 1], sharey=ax_left)
    
        # ç”»æ›²çº¿ï¼šä¸¤ä¸ªæ—¶é—´æ®µ
        for src, ser in series_dict[var][h].items():
            if var == 'VWS' and src == 'TowerAvg':
                continue
            if ser is None or ser.empty:
                continue
    
            color = COLMAP.get(src, 'k')
            alpha = ALPHA_MAP2.get(src, 0.6)
            lw    = 4
    
            s1 = ser.loc[WIN1_START:WIN1_END]
            s2 = ser.loc[WIN2_START:WIN2_END]
    
            if not s1.empty:
                ax_left.plot(s1.index, s1.values,
                             color=color, alpha=alpha, lw=lw)
            if not s2.empty:
                ax_right.plot(s2.index, s2.values,
                              color=color, alpha=alpha, lw=lw)
    
        # x èŒƒå›´
        ax_left.set_xlim(WIN1_START, WIN1_END)
        ax_right.set_xlim(WIN2_START, WIN2_END)
    
        # y èŒƒå›´ & åˆ»åº¦ï¼ˆåªè®¾ç½®åœ¨å·¦è½´ä¸Šï¼‰
        ax_left.set_ylim(vmin, vmax)
        if var == 'Temp':
            ax_left.yaxis.set_major_locator(MultipleLocator(4))
            ax_left.yaxis.set_minor_locator(AutoMinorLocator(2))
        elif var == 'RH':
            ax_left.yaxis.set_major_locator(MultipleLocator(20))
            ax_left.yaxis.set_minor_locator(AutoMinorLocator(2))
        elif var == 'HWS':
            ax_left.yaxis.set_major_locator(MultipleLocator(4))
            ax_left.yaxis.set_minor_locator(AutoMinorLocator(2))
        else:  # VWS
            for ax in (ax_left, ax_right):
                ax.axhline(
                    0,
                    color='black',
                    linewidth=6,
                    zorder=1
                )
            ax_left.yaxis.set_major_locator(MultipleLocator(2))
            ax_left.yaxis.set_minor_locator(AutoMinorLocator(2))
    
        # å³è½´éšè— y è½´åˆ»åº¦å’Œæ ‡ç­¾ï¼ˆåªä¿ç•™ä¸€ä¸ª y è½´ï¼‰
        ax_right.tick_params(
            axis='y', which='both',
            left=False, right=False,
            labelleft=False, labelright=False
        )
    
        # é«˜åº¦æ ‡ç­¾ï¼ˆå†™åœ¨å·¦è½´ä¸Šï¼‰
        ax_left.text(
            0.1, 1.05, f"{h} m",
            transform=ax_left.transAxes,
            ha='center', va='bottom',
            fontsize=56, fontweight='bold'
        )
    
        # y-labelï¼šç¬¬ä¸‰è¡Œå†™å•ä½
        if r_idx == 2:
            if var == 'Temp':
                ylab = "T (K)"
            elif var == 'RH':
                ylab = "RH (%)"
            elif var == 'HWS':
                ylab = "HWS (m/s)"
            elif var == 'VWS':
                ylab = "VWS (m/s)"
            else:
                ylab = ""
    
            ax_left.text(
                -0.2, 1.5, ylab,
                transform=ax_left.transAxes,
                fontsize=50, ha='right', va='center',
                rotation=90, fontweight="bold"
            )
    
        # è¾¹æ¡† & x è½´åˆ»åº¦æ ¼å¼
        for ax in (ax_left, ax_right):
            for sp in ['top', 'right']:
                ax.spines[sp].set_visible(False)
            for sp in ['bottom', 'left']:
                ax.spines[sp].set_linewidth(6)
    
            # ---- x è½´åˆ»åº¦ï¼šDayLocator + è‡ªå®šä¹‰ formatter ----
            # ä¸»åˆ»åº¦ï¼šæ¯å¤©ä¸€ä¸ª
            ax.xaxis.set_major_locator(mdates.DayLocator())
            # å‰¯åˆ»åº¦ï¼šæ¯å¤©ä¸­åˆ 12 ç‚¹
            ax.xaxis.set_minor_locator(mdates.HourLocator(byhour=[12]))
    
        # å·¦è¾¹ï¼ˆç¬¬ä¸€ä¸ªæ—¶é—´çª—ï¼‰ï¼šç¬¬ä¸€ä¸ªåˆ»åº¦æ˜¾ç¤º 'Jun 06'ï¼Œåé¢ '07' '08' ...
        ax_left.xaxis.set_major_formatter(
            make_month_first_formatter(WIN1_START)
        )
    
        # å³è¾¹ï¼ˆç¬¬äºŒä¸ªæ—¶é—´çª—ï¼‰ï¼šç¬¬ä¸€ä¸ªåˆ»åº¦æ˜¾ç¤º 'Aug 10'ï¼Œåé¢ '11' ...
        ax_right.xaxis.set_major_formatter(
            make_month_first_formatter(WIN2_START)
        )
    
        # broken axisï¼šåªåœ¨åº•éƒ¨ç”»ä¸¤ä¸ªæ–œæ 
        ax_left.spines['right'].set_visible(False)
        ax_right.spines['left'].set_visible(False)
    
        d = .015
        kwargs = dict(color='k', clip_on=False, linewidth=4)
    
        # å·¦è½´å³ä¾§ï¼ˆåº•éƒ¨ï¼‰æ–œæ 
        ax_left.plot(
            (1 - d, 1 + d), (-d, +d),
            transform=ax_left.transAxes, **kwargs
        )
        # å³è½´å·¦ä¾§ï¼ˆåº•éƒ¨ï¼‰æ–œæ 
        ax_right.plot(
            (-d, +d), (-d, +d),
            transform=ax_right.transAxes, **kwargs
        )
    
        # æœ€åä¸€è¡Œæ˜¾ç¤º x è½´æ ‡ç­¾ï¼Œå…¶ä½™è¡Œéšè—
        if r_idx == len(HEIGHTS) - 1:
            # ====== æ–°å¢éƒ¨åˆ†å¼€å§‹ ======
            # åœ¨æ¯ä¸ªxè½´ä¸‹æ–¹æ·»åŠ æœˆä»½æ ‡ç­¾
            month1 = WIN1_START.strftime('%b') # è·å–æœˆä»½ç¼©å†™ï¼Œå¦‚ 'Jun'
            month2 = WIN2_START.strftime('%b') # è·å–æœˆä»½ç¼©å†™ï¼Œå¦‚ 'Aug'
    
            ax_left.text(
                0.04, -0.27, month1,
                transform=ax_left.transAxes,
                ha='center', va='top',
                fontsize=50, fontweight='bold'
            )
            ax_right.text(
                0.085, -0.27, month2,
                transform=ax_right.transAxes,
                ha='center', va='top',
                fontsize=50, fontweight='bold'
            )    
            ax_left.set_xlabel("Datetime (BJT)", fontsize=50, x=1, labelpad = 45)
            ax_left.tick_params(labelbottom=True)
            ax_right.tick_params(labelbottom=True)
        else:
            ax_left.tick_params(labelbottom=False)
            ax_right.tick_params(labelbottom=False)

        # ---------------- Scatter å³ä¾§ --------------
        ax_scat = fig.add_subplot(gspec[r_idx, 1])

        # ç¡®å®šæ•£ç‚¹å‚è€ƒ ref
        ref = series_dict[var][h].get('TowerAvg')
        if ref is not None and not ref.empty:
            ref_source = 'AWS'
        else:
            ref = series_dict[var][h].get('TowerTurb')
            if ref is not None and not ref.empty:
                ref_source = 'ECM'
            else:
                ref = None
                ref_source = 'Other Source'
                for _s in series_dict[var][h].values():
                    if _s is not None and not _s.empty:
                        ref = _s
                        break

        # åªæœ‰æœ€åº•è¡Œå†™ Ref æ–‡æœ¬
        if r_idx == len(HEIGHTS) - 1:
            ax_scat.text(
                0.5, -0.35, f'Ref.: {ref_source}',
                transform=ax_scat.transAxes,
                fontsize=50, ha='center', va='top'
            )
        else:
            ax_scat.tick_params(labelbottom=False)

        # 1:1 çº¿ & åŸºæœ¬èŒƒå›´
        ax_scat.plot(
            [vmin, vmax], [vmin, vmax],
            ls=(0, (5, 10)), lw=3, color='black',
            zorder=0, alpha=0.5
        )
        ax_scat.set_xlim(vmin, vmax)
        ax_scat.set_ylim(vmin, vmax)

        # ç”»æ•£ç‚¹
        for src, ser in series_dict[var][h].items():
            if src == 'TowerAvg':
                continue
            if var == 'VWS' and src == 'TowerTurb':
                continue
            if ref is None or ser is None or ser.empty:
                continue

            aligned = align_x_to_ref(ref, ser)
            if aligned.empty:
                continue

            ax_scat.scatter(
                aligned.iloc[:, 0], aligned.iloc[:, 1],
                s=200, linewidths=0, marker='o',
                color=COLMAP.get(src, 'k'),
                alpha=ALPHA_MAP.get(src, 0.5)
            )

        # æ ¹æ®å˜é‡è°ƒæ•´æ•£ç‚¹è½´åˆ»åº¦
        if var == 'HWS':
            ax_scat.set_xlim(0, 16)
            ax_scat.xaxis.set_major_locator(MultipleLocator(4))
            ax_scat.xaxis.set_minor_locator(MultipleLocator(2))
            ax_scat.yaxis.set_major_locator(MultipleLocator(4))
            ax_scat.yaxis.set_minor_locator(MultipleLocator(2))

        elif var == 'VWS':
            ax_scat.set_xlim(-3, 3)
            ax_scat.xaxis.set_major_locator(MultipleLocator(2))
            ax_scat.xaxis.set_minor_locator(MultipleLocator(1))
            ax_scat.yaxis.set_major_locator(MultipleLocator(2))
            ax_scat.yaxis.set_minor_locator(MultipleLocator(1))

        elif var == 'RH':
            ax_scat.xaxis.set_major_locator(FixedLocator([30, 65, 100]))
            ax_scat.xaxis.set_minor_locator(AutoMinorLocator(2))
            ax_scat.yaxis.set_major_locator(FixedLocator([30, 65, 100]))
            ax_scat.yaxis.set_minor_locator(AutoMinorLocator(2))

        elif var == 'Temp':
            ax_scat.xaxis.set_major_locator(MultipleLocator(4))
            ax_scat.xaxis.set_minor_locator(AutoMinorLocator(2))
            ax_scat.yaxis.set_major_locator(MultipleLocator(4))
            ax_scat.yaxis.set_minor_locator(AutoMinorLocator(2))

        # æ•£ç‚¹å›¾è¾¹æ¡†
        for sp in ['top', 'right']:
            ax_scat.spines[sp].set_visible(False)
        for sp in ['bottom', 'left']:
            ax_scat.spines[sp].set_linewidth(6)

# --------------------------------------------------
# 4. Legend & save
# --------------------------------------------------
handles = [
    plt.Line2D([], [],
               color=COLMAP[k],
               lw=15,
               label=LABEL_MAP[k])
    for k in COLMAP
]
fig.legend(
    handles, [h.get_label() for h in handles],
    loc='upper center', ncol=3, frameon=False,
    title_fontsize=80, bbox_to_anchor=(0.5, 0.935)
)

fig.savefig(
    OUT_FILE, dpi=300, format='tif',
    transparent=True, bbox_inches='tight',
    pil_kwargs={'compression': 'tiff_adobe_deflate'}
)
plt.close(fig)
print(f"Plot saved â†’ {OUT_FILE}")
gc.collect()


# # å®šä¹‰è¾“å‡ºè·¯å¾„
# excel_path_1min = os.path.join(OUT_DIR, "Tower_MultiLevel_TimeScatter2-1min.xlsx")

# # åˆ›å»ºExcelå†™å…¥å™¨
# with pd.ExcelWriter(excel_path_1min, engine='xlsxwriter') as writer:
#     # éå†æ‰€æœ‰å˜é‡ç»„ï¼ˆTemp/RH/HWS/VWSï¼‰
#     for var_group in VAR_GROUPS:
#         # åˆ›å»ºç©ºåˆ—è¡¨å­˜å‚¨æ‰€æœ‰æ•°æ®
#         all_data = []
        
#         # éå†æ‰€æœ‰é«˜åº¦å’Œæ¥æº
#         for height in HEIGHTS:
#             for source, series in series_dict_1min[var_group][height].items():
#                 # åˆ›å»ºä¸´æ—¶DataFrame
#                 temp_df = pd.DataFrame({
#                     'DateTime': series.index,
#                     'Value': series.values,
#                     'Height': height,
#                     'Source': source,
#                     'Variable': var_group
#                 })
#                 all_data.append(temp_df)
        
#         # åˆå¹¶æ‰€æœ‰æ•°æ®
#         combined_df = pd.concat(all_data, ignore_index=True)
        
#         # å°†æ•°æ®é€è§†ä¸ºå®½æ ¼å¼ï¼ˆæ¯ä¸ªæ¥æºä¸€åˆ—ï¼‰
#         pivot_df = combined_df.pivot_table(
#             index=['DateTime', 'Height', 'Variable'],
#             columns='Source',
#             values='Value'
#         ).reset_index()
        
#         # é‡å‘½ååˆ—åå’Œç´¢å¼•
#         pivot_df.columns.name = None
#         pivot_df = pivot_df.rename(columns={'DateTime': 'æ—¶é—´ (UTC)'})
        
#         # æŒ‰æ—¶é—´æ’åº
#         pivot_df.sort_values('æ—¶é—´ (UTC)', inplace=True)
        
#         # ä¿å­˜åˆ°Excelå·¥ä½œè¡¨
#         sheet_name = f"{var_group}_1min"
#         pivot_df.to_excel(writer, sheet_name=sheet_name, index=False)
        
#         # è·å–å·¥ä½œç°¿å’Œå·¥ä½œè¡¨å¯¹è±¡ç”¨äºæ ¼å¼è®¾ç½®
#         workbook = writer.book
#         worksheet = writer.sheets[sheet_name]
        
#         # è®¾ç½®åˆ—å®½
#         for i, col in enumerate(pivot_df.columns):
#             # æ—¶é—´åˆ—è®¾ç½®æ›´å®½
#             if 'æ—¶é—´' in col:
#                 worksheet.set_column(i, i, 25)
#             else:
#                 worksheet.set_column(i, i, 15)
                
#         # æ·»åŠ ç­›é€‰å™¨
#         worksheet.autofilter(0, 0, 0, len(pivot_df.columns)-1)

# print(f"1åˆ†é’Ÿæ•°æ®å·²æˆåŠŸå¯¼å‡ºåˆ°: {excel_path_1min}")


"""
Tower multi-level timeâ€“series (lines) + interâ€‘dataset scatter matrix

60min
-------------------------------------------------------------------
"""
#####
# é‡ç½®æ‰€æœ‰å‚æ•°ä¸ºé»˜è®¤å€¼
plt.rcParams.update(plt.rcParamsDefault)


import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.gridspec import GridSpec
from matplotlib.ticker import MultipleLocator, AutoMinorLocator, FixedLocator

# --------------------------------------------------
# 0. Constants & rcParams
# --------------------------------------------------
HEIGHTS = [280, 200, 140, 80]
VAR_GROUPS = ["Temp", "RH", "HWS", "VWS"]
COLMAP = dict(MWR="red", 
              LiDAR="darkorange",
              TowerAvg="black", 
              TowerTurb="slategray", 
              CRA="magenta", 
              ERA5="blue", 
              )

DATA_START = pd.Timestamp("2024-06-05 00:00")
DATA_END   = pd.Timestamp("2024-08-11 00:00")
# æ•°æ®ç­›é€‰çª—å£ï¼ˆåªæŠŠè¿™æ®µæ—¶é—´çš„æ•°æ®è¯»è¿›æ¥ã€åš QCï¼‰
PLOT_START = pd.Timestamp("2024-08-05 01:30")
PLOT_END   = pd.Timestamp("2024-08-11 00:00")
# ==== æ–°å¢ï¼šä¸¤ä¸ªä¸è¿ç»­çš„ç»˜å›¾æ—¶é—´çª—å£ï¼ˆè‡ªå·±æ”¹æˆæƒ³è¦çš„æ—¶é—´æ®µï¼‰ ====
SEG1_START = pd.Timestamp("2024-06-06 00:00")
SEG1_END   = pd.Timestamp("2024-06-10 00:00")
SEG2_START = pd.Timestamp("2024-08-05 01:30")
SEG2_END   = pd.Timestamp("2024-08-11 00:00")

ALPHA_MAP = {
    'MWR'      : 0.4,
    'TowerAvg' : 0.4,
    'TowerTurb': 0.4,
    'CRA'      : 0.6,
    'ERA5'     : 0.6,
    'LiDAR'    : 0.4,
}
ALPHA_MAP2 = {
    'MWR'      : 1,
    'TowerAvg' : 1,
    'TowerTurb': 0.5,
    'CRA'      : 1,
    'ERA5'     : 1,
    'LiDAR'    : 0.5,
}

LABEL_MAP = {
    'MWR'      : 'MWR',
    'LiDAR'    : 'DWL',
    'TowerAvg' : 'AWS',
    'TowerTurb': 'ECM',#eddy covariance flux measurement system
    'CRA'      : 'CRA',
    'ERA5'     : 'ERA5',
}
# axis limits for each variable
VAR_RANGE = {
    'Temp': (288, 310),
    'RH'  : (10, 103),
    'HWS' : (-0.99, 14),
    'VWS' : (-4, 4)
}
title_map = {
    'Temp': 'Temperature (T)',
    'RH'  : 'Relative Humidity (RH)',
    'HWS' : 'Horizontal Wind Speed (HWS)',
    'VWS' : 'Vertical Wind Speed (VWS)'
}
OUT_DIR = r"E:\Beijing2024\å‡ºå›¾TIF"; os.makedirs(OUT_DIR, exist_ok=True)
OUT_FILE = os.path.join(OUT_DIR, "Tower_MultiLevel_TimeScatter2-60min3.tif")
plt.rcParams.update({    
    'font.size': 50,
    'font.family': 'sans-serif',                # å…ˆæŒ‡å®šå®¶æ—
    'font.sans-serif': ['Arial', 'DejaVu Sans'],     # æŠŠ Arial è®¾ä¸ºé¦–é€‰
    'axes.titlepad': 8,
    'legend.fontsize': 50,
    'axes.labelsize': 50,
    'xtick.labelsize': 50,
    'ytick.labelsize': 50,
    'xtick.major.size': 30,
    'xtick.minor.size': 15,
    'ytick.major.size': 30,
    'ytick.minor.size': 15,
    'xtick.direction': 'out',
    'ytick.direction': 'out',
    'xtick.major.width': 6,
    'xtick.minor.width': 6,
    'ytick.major.width': 6,
    'ytick.minor.width': 6,
})
# --------------------------------------------------
# 1. Helpers
# --------------------------------------------------

def ensure_dt(ser: pd.Series) -> pd.Series:
    ser = ser.copy(); ser.index = pd.to_datetime(ser.index); return ser.sort_index()

def pivot_height(df: pd.DataFrame, *, idx: str, col: str, val: str, h: int) -> pd.Series:
    tmp = df.reset_index(); tmp[idx] = pd.to_datetime(tmp[idx])
    return ensure_dt(tmp.pivot(index=idx, columns=col, values=val).loc[:, h])

def align_x_to_ref(ref: pd.Series, other: pd.Series) -> pd.DataFrame:
    return pd.concat([ref, other], axis=1, join='inner').dropna(how='any')

# --------------------------------------------------
# 2.  Build Series dictionary
# --------------------------------------------------
turb_calibrated_60min['rh'] = turb_calibrated_60min['rh'].clip(upper=100)
series_dict = {v: {h: {} for h in HEIGHTS} for v in VAR_GROUPS}

# ---- Temperature -----------------------------------------------------------
for h in HEIGHTS:
    series_dict['Temp'][h]['TowerAvg']  = pivot_height(tieta_60min, idx='timestamps', col='H(m)', val='T(K)_tieta', h=h)
    series_dict['Temp'][h]['TowerTurb'] = pivot_height(turb_calibrated_60min, idx='timestamps', col='Height', val='T (K)', h=h)
    series_dict['Temp'][h]['MWR'] = ensure_dt(mean_60min_profiles.xs('T(K)', level=0, axis=1)[h])
    series_dict['Temp'][h]['CRA']       = ensure_dt(
        CRA_interp_to_65_80_280.query('height_plus_alt == @h').set_index('BJT')['Temp (K)'])
    series_dict['Temp'][h]['ERA5']      = ensure_dt(
        ERA5_interp_to_65_80_280.query('height == @h').set_index('BJT')['t'])

# ---- Relative Humidity -----------------------------------------------------
for h in HEIGHTS:
    series_dict['RH'][h]['TowerAvg']  = pivot_height(tieta_60min, idx='timestamps', col='H(m)', val='RH_tieta', h=h)
    series_dict['RH'][h]['TowerTurb'] = pivot_height(turb_calibrated_60min, idx='timestamps', col='Height', val='rh', h=h)
    series_dict['RH'][h]['MWR']       = ensure_dt(mean_60min_profiles.xs('RH(%)', level=0, axis=1)[h])
    series_dict['RH'][h]['CRA']       = ensure_dt(
        CRA_interp_to_65_80_280.query('height_plus_alt == @h').set_index('BJT')['rh (%)'])
    series_dict['RH'][h]['ERA5']      = ensure_dt(
        ERA5_interp_to_65_80_280.query('height == @h').set_index('BJT')['r'])

# ---- Horizontal Wind Speed -------------------------------------------------
hws_qc_60min = (
    hws_avg["60min"]
    .rename(columns=lambda x: x.replace('m', ''))  # å…ˆå¤„ç†åˆ—åï¼ˆç§»é™¤'m'ï¼‰
    .stack()
    .reset_index()
    .rename(columns={'level_1': 'height', 0: 'hws'})
    .astype({'height': int})  # ç¡®ä¿heightä¸ºæ•´æ•°
)

for h in HEIGHTS:
    series_dict['HWS'][h]['LiDAR']    = ensure_dt(
        hws_qc_60min.query('height == @h').set_index('level_0')['hws'])
    series_dict['HWS'][h]['TowerAvg'] = pivot_height(tieta_60min, idx='timestamps', col='H(m)', val='ws_tieta', h=h)
    series_dict['HWS'][h]['TowerTurb']= pivot_height(turb_calibrated_60min, idx='timestamps', col='Height', val='hws_corrected', h=h)
    series_dict['HWS'][h]['CRA']      = ensure_dt(
        CRA_interp_to_65_80_280.query('height_plus_alt == @h').set_index('BJT')['hws(m/s)'])
    series_dict['HWS'][h]['ERA5']     = ensure_dt(
        ERA5_interp_to_65_80_280.query('height == @h').set_index('BJT')['hws(m/s)'])

# ---- Vertical Wind Speed ---------------------------------------------------
vws_qc_60min = (
    vws_avg["60min"]
    .rename(columns=lambda x: x.replace('m', ''))  # å…ˆå¤„ç†åˆ—åï¼ˆç§»é™¤'m'ï¼‰
    .stack()
    .reset_index()
    .rename(columns={'level_1': 'height', 0: 'vws'})
    .astype({'height': int})  # ç¡®ä¿heightä¸ºæ•´æ•°
)

for h in HEIGHTS:
    series_dict['VWS'][h]['LiDAR']    = ensure_dt(
        vws_qc_60min.reset_index().query('height == @h').set_index('level_0')['vws'])
    series_dict['VWS'][h]['TowerTurb'] = pivot_height(turb_calibrated_60min, idx='timestamps', col='Height', val='W (m/s)', h=h)
    series_dict['VWS'][h]['CRA']       = ensure_dt(
        CRA_interp_to_65_80_280.query('height_plus_alt == @h').set_index('BJT')['vws(10â»Â² {m/s})'] * -0.35)
    series_dict['VWS'][h]['ERA5']      = ensure_dt(
        ERA5_interp_to_65_80_280.query('height == @h').set_index('BJT')['vws(10â»Â² {m/s})'] * -35)

for v in VAR_GROUPS:
    for h in HEIGHTS:
        for src, ser in series_dict[v][h].items():
            series_dict[v][h][src] = ser.loc[DATA_START:DATA_END]

series_dict_60min = series_dict

# ==== å®šä¹‰ä¸¤ä¸ªæ—¶é—´çª—å£ ====
WIN1_START = pd.Timestamp("2024-06-06 00:00")   # æ–°å¢çª—å£ï¼š6æœˆ6â€“10æ—¥
WIN1_END   = pd.Timestamp("2024-06-10 00:00")

WIN2_START = PLOT_START                         # åŸæ¥çš„ 8 æœˆçª—å£
WIN2_END   = PLOT_END

def make_month_first_formatter(first_date):
    """
    ç¬¬ä¸€ä¸ª tick æ˜¾ç¤º 'Jun 06'ï¼Œåé¢çš„ tick åªæ˜¾ç¤º '07', '08' ...
    first_date: è¿™ä¸ªæ—¶é—´æ®µçš„èµ·å§‹æ—¥æœŸï¼ˆæ¯”å¦‚ WIN1_START æˆ– WIN2_STARTï¼‰
    """
    first_date = pd.to_datetime(first_date).normalize()

    def _fmt(x, pos=None):
        dt = mdates.num2date(x)          # matplotlib å†…éƒ¨æµ®ç‚¹ -> datetime
        d  = pd.Timestamp(dt).normalize()

        if d == first_date:
            # ç¬¬ä¸€ä¸ªåˆ»åº¦ï¼šè‹±æ–‡æœˆä»½ç¼©å†™ + æ—¥
            return d.strftime('%b %d')   # ä¾‹å¦‚ 'Jun 06'
        else:
            # å…¶å®ƒåˆ»åº¦ï¼šåªæ˜¾ç¤ºæ—¥
            return d.strftime('%d')      # ä¾‹å¦‚ '07'
    return FuncFormatter(_fmt)

# # å®šä¹‰è¾“å‡ºè·¯å¾„
# excel_path = os.path.join(OUT_DIR, "Tower_MultiLevel_TimeScatter2-60min.xlsx")

# # åˆ›å»ºExcelå†™å…¥å™¨
# with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:
#     # éå†æ‰€æœ‰å˜é‡ç»„ï¼ˆTemp/RH/HWS/VWSï¼‰
#     for var_group in VAR_GROUPS:
#         # åˆ›å»ºç©ºåˆ—è¡¨å­˜å‚¨æ‰€æœ‰æ•°æ®
#         all_data = []
        
#         # éå†æ‰€æœ‰é«˜åº¦å’Œæ¥æº
#         for height in HEIGHTS:
#             for source, series in series_dict_60min[var_group][height].items():
#                 # åˆ›å»ºä¸´æ—¶DataFrame
#                 temp_df = pd.DataFrame({
#                     'DateTime': series.index,
#                     'Value': series.values,
#                     'Height': height,
#                     'Source': source,
#                     'Variable': var_group
#                 })
#                 all_data.append(temp_df)
        
#         # åˆå¹¶æ‰€æœ‰æ•°æ®
#         combined_df = pd.concat(all_data, ignore_index=True)
        
#         # å°†æ•°æ®é€è§†ä¸ºå®½æ ¼å¼ï¼ˆæ¯ä¸ªæ¥æºä¸€åˆ—ï¼‰
#         pivot_df = combined_df.pivot_table(
#             index=['DateTime', 'Height', 'Variable'],
#             columns='Source',
#             values='Value'
#         ).reset_index()
        
#         # é‡å‘½ååˆ—åå’Œç´¢å¼•
#         pivot_df.columns.name = None
#         pivot_df = pivot_df.rename(columns={'DateTime': 'æ—¶é—´ (UTC)'})
        
#         # æŒ‰æ—¶é—´æ’åº
#         pivot_df.sort_values('æ—¶é—´ (UTC)', inplace=True)
        
#         # ä¿å­˜åˆ°Excelå·¥ä½œè¡¨
#         sheet_name = f"{var_group}_60min"
#         pivot_df.to_excel(writer, sheet_name=sheet_name, index=False)
        
#         # è·å–å·¥ä½œç°¿å’Œå·¥ä½œè¡¨å¯¹è±¡ç”¨äºæ ¼å¼è®¾ç½®
#         workbook = writer.book
#         worksheet = writer.sheets[sheet_name]
        
#         # è®¾ç½®åˆ—å®½
#         for i, col in enumerate(pivot_df.columns):
#             # æ—¶é—´åˆ—è®¾ç½®æ›´å®½
#             if 'æ—¶é—´' in col:
#                 worksheet.set_column(i, i, 25)
#             else:
#                 worksheet.set_column(i, i, 15)
                
#         # æ·»åŠ ç­›é€‰å™¨
#         worksheet.autofilter(0, 0, 0, len(pivot_df.columns)-1)

# print(f"æ•°æ®å·²æˆåŠŸå¯¼å‡ºåˆ°: {excel_path}")

# --------------------------------------------------
# 3. Plot with broken x-axis
# --------------------------------------------------
fig = plt.figure(figsize=(74, 60))  # , constrained_layout=True
outer = GridSpec(2, 2, figure=fig, hspace=0.22, wspace=0.125)

for g_idx, var in enumerate(VAR_GROUPS):
    row, col = divmod(g_idx, 2)
    gspec = outer[row, col].subgridspec(
        len(HEIGHTS), 2,
        width_ratios=[3, 1.2],
        wspace=0.18,
        hspace=0.55
    )

    # column header
    ax_head = fig.add_subplot(gspec[0, 0])
    ax_head.axis('off')
    if var == 'VWS':
        ax_head.set_title(
            "Vertical Wind Speed (VWS)\n"           # ç¬¬ä¸€è¡Œæ™®é€šæ–‡å­—ï¼Œè‡ªåŠ¨æ˜¯æ­£ä½“
            r"$(VWS_{80/140/200/280}^{\mathrm{ERA5,CRA}}\times 35)$",  # ç¬¬äºŒè¡Œæ•°å­¦å…¬å¼ï¼Œä¿ç•™ä¸Šä¸‹æ ‡
            pad=35, x=0.5, fontweight='bold', fontsize=60  # æ•´ä½“åŠ ç²—ï¼Œç¬¬ä¸€è¡Œè‚¯å®šæ˜¯ç²—ä½“
        )
    else:
        ax_head.set_title(title_map.get(var, var),
                          pad=35, fontweight='bold', fontsize=60)

    vmin, vmax = VAR_RANGE[var]
    
    for r_idx, h in enumerate(HEIGHTS):
        # ---------------- Line with broken x-axis ------------------
        # å·¦åˆ—å†æ‹†æˆä¸¤ä¸ªå­è½´ï¼šå·¦=6 æœˆï¼Œå³=8 æœˆ
        line_gs = gspec[r_idx, 0].subgridspec(1, 2, width_ratios=[1, 1],
                                              wspace=0.05)
        ax_left  = fig.add_subplot(line_gs[0, 0])
        ax_right = fig.add_subplot(line_gs[0, 1], sharey=ax_left)
    
        # ç”»æ›²çº¿ï¼šä¸¤ä¸ªæ—¶é—´æ®µ
        for src, ser in series_dict[var][h].items():
            if var == 'VWS' and src == 'TowerAvg':
                continue
            if ser is None or ser.empty:
                continue
    
            color = COLMAP.get(src, 'k')
            alpha = ALPHA_MAP2.get(src, 0.6)
            lw    = 4
    
            s1 = ser.loc[WIN1_START:WIN1_END]
            s2 = ser.loc[WIN2_START:WIN2_END]
    
            if not s1.empty:
                ax_left.plot(s1.index, s1.values,
                             color=color, alpha=alpha, lw=lw)
            if not s2.empty:
                ax_right.plot(s2.index, s2.values,
                              color=color, alpha=alpha, lw=lw)
    
        # x èŒƒå›´
        ax_left.set_xlim(WIN1_START, WIN1_END)
        ax_right.set_xlim(WIN2_START, WIN2_END)
    
        # y èŒƒå›´ & åˆ»åº¦ï¼ˆåªè®¾ç½®åœ¨å·¦è½´ä¸Šï¼‰
        ax_left.set_ylim(vmin, vmax)
        if var == 'Temp':
            ax_left.yaxis.set_major_locator(MultipleLocator(4))
            ax_left.yaxis.set_minor_locator(AutoMinorLocator(2))
        elif var == 'RH':
            ax_left.yaxis.set_major_locator(MultipleLocator(20))
            ax_left.yaxis.set_minor_locator(AutoMinorLocator(2))
        elif var == 'HWS':
            ax_left.yaxis.set_major_locator(MultipleLocator(4))
            ax_left.yaxis.set_minor_locator(AutoMinorLocator(2))
        else:  # VWS
            for ax in (ax_left, ax_right):
                ax.axhline(
                    0,
                    color='black',
                    linewidth=6,
                    zorder=1
                )
            ax_left.yaxis.set_major_locator(MultipleLocator(2))
            ax_left.yaxis.set_minor_locator(AutoMinorLocator(2))
    
        # å³è½´éšè— y è½´åˆ»åº¦å’Œæ ‡ç­¾ï¼ˆåªä¿ç•™ä¸€ä¸ª y è½´ï¼‰
        ax_right.tick_params(
            axis='y', which='both',
            left=False, right=False,
            labelleft=False, labelright=False
        )
    
        # é«˜åº¦æ ‡ç­¾ï¼ˆå†™åœ¨å·¦è½´ä¸Šï¼‰
        ax_left.text(
            0.1, 1.05, f"{h} m",
            transform=ax_left.transAxes,
            ha='center', va='bottom',
            fontsize=56, fontweight='bold'
        )
    
        # y-labelï¼šç¬¬ä¸‰è¡Œå†™å•ä½
        if r_idx == 2:
            if var == 'Temp':
                ylab = "T (K)"
            elif var == 'RH':
                ylab = "RH (%)"
            elif var == 'HWS':
                ylab = "HWS (m/s)"
            elif var == 'VWS':
                ylab = "VWS (m/s)"
            else:
                ylab = ""
    
            ax_left.text(
                -0.2, 1.5, ylab,
                transform=ax_left.transAxes,
                fontsize=50, ha='right', va='center',
                rotation=90, fontweight="bold"
            )
    
        # è¾¹æ¡† & x è½´åˆ»åº¦æ ¼å¼
        for ax in (ax_left, ax_right):
            for sp in ['top', 'right']:
                ax.spines[sp].set_visible(False)
            for sp in ['bottom', 'left']:
                ax.spines[sp].set_linewidth(6)
    
            # ---- x è½´åˆ»åº¦ï¼šDayLocator + è‡ªå®šä¹‰ formatter ----
            # ä¸»åˆ»åº¦ï¼šæ¯å¤©ä¸€ä¸ª
            ax.xaxis.set_major_locator(mdates.DayLocator())
            # å‰¯åˆ»åº¦ï¼šæ¯å¤©ä¸­åˆ 12 ç‚¹
            ax.xaxis.set_minor_locator(mdates.HourLocator(byhour=[12]))
    
        # å·¦è¾¹ï¼ˆç¬¬ä¸€ä¸ªæ—¶é—´çª—ï¼‰ï¼šç¬¬ä¸€ä¸ªåˆ»åº¦æ˜¾ç¤º 'Jun 06'ï¼Œåé¢ '07' '08' ...
        ax_left.xaxis.set_major_formatter(
            make_month_first_formatter(WIN1_START)
        )
    
        # å³è¾¹ï¼ˆç¬¬äºŒä¸ªæ—¶é—´çª—ï¼‰ï¼šç¬¬ä¸€ä¸ªåˆ»åº¦æ˜¾ç¤º 'Aug 10'ï¼Œåé¢ '11' ...
        ax_right.xaxis.set_major_formatter(
            make_month_first_formatter(WIN2_START)
        )
    
        # broken axisï¼šåªåœ¨åº•éƒ¨ç”»ä¸¤ä¸ªæ–œæ 
        ax_left.spines['right'].set_visible(False)
        ax_right.spines['left'].set_visible(False)
    
        d = .015
        kwargs = dict(color='k', clip_on=False, linewidth=4)
    
        # å·¦è½´å³ä¾§ï¼ˆåº•éƒ¨ï¼‰æ–œæ 
        ax_left.plot(
            (1 - d, 1 + d), (-d, +d),
            transform=ax_left.transAxes, **kwargs
        )
        # å³è½´å·¦ä¾§ï¼ˆåº•éƒ¨ï¼‰æ–œæ 
        ax_right.plot(
            (-d, +d), (-d, +d),
            transform=ax_right.transAxes, **kwargs
        )
    
        # æœ€åä¸€è¡Œæ˜¾ç¤º x è½´æ ‡ç­¾ï¼Œå…¶ä½™è¡Œéšè—
        if r_idx == len(HEIGHTS) - 1:
            # ====== æ–°å¢éƒ¨åˆ†å¼€å§‹ ======
            # åœ¨æ¯ä¸ªxè½´ä¸‹æ–¹æ·»åŠ æœˆä»½æ ‡ç­¾
            month1 = WIN1_START.strftime('%b') # è·å–æœˆä»½ç¼©å†™ï¼Œå¦‚ 'Jun'
            month2 = WIN2_START.strftime('%b') # è·å–æœˆä»½ç¼©å†™ï¼Œå¦‚ 'Aug'
    
            ax_left.text(
                0.04, -0.27, month1,
                transform=ax_left.transAxes,
                ha='center', va='top',
                fontsize=50, fontweight='bold'
            )
            ax_right.text(
                0.085, -0.27, month2,
                transform=ax_right.transAxes,
                ha='center', va='top',
                fontsize=50, fontweight='bold'
            )    
            ax_left.set_xlabel("Datetime (BJT)", fontsize=50, x=1, labelpad = 45)
            ax_left.tick_params(labelbottom=True)
            ax_right.tick_params(labelbottom=True)
        else:
            ax_left.tick_params(labelbottom=False)
            ax_right.tick_params(labelbottom=False)

        # ---------------- Scatter å³ä¾§ --------------
        ax_scat = fig.add_subplot(gspec[r_idx, 1])

        # ç¡®å®šæ•£ç‚¹å‚è€ƒ ref
        ref = series_dict[var][h].get('TowerAvg')
        if ref is not None and not ref.empty:
            ref_source = 'AWS'
        else:
            ref = series_dict[var][h].get('TowerTurb')
            if ref is not None and not ref.empty:
                ref_source = 'AWS'
            else:
                ref = None
                ref_source = 'Other Source'
                for _s in series_dict[var][h].values():
                    if _s is not None and not _s.empty:
                        ref = _s
                        break

        # åªæœ‰æœ€åº•è¡Œå†™ Ref æ–‡æœ¬
        if r_idx == len(HEIGHTS) - 1:
            ax_scat.text(
                0.5, -0.35, f'Ref.: {ref_source}',
                transform=ax_scat.transAxes,
                fontsize=50, ha='center', va='top'
            )
        else:
            ax_scat.tick_params(labelbottom=False)

        # 1:1 çº¿ & åŸºæœ¬èŒƒå›´
        ax_scat.plot(
            [vmin, vmax], [vmin, vmax],
            ls=(0, (5, 10)), lw=3, color='black',
            zorder=0, alpha=0.5
        )
        ax_scat.set_xlim(vmin, vmax)
        ax_scat.set_ylim(vmin, vmax)

        # ç”»æ•£ç‚¹
        for src, ser in series_dict[var][h].items():
            if src == 'TowerAvg':
                continue
            if var == 'VWS' and src == 'TowerTurb':
                continue
            if ref is None or ser is None or ser.empty:
                continue

            aligned = align_x_to_ref(ref, ser)
            if aligned.empty:
                continue

            ax_scat.scatter(
                aligned.iloc[:, 0], aligned.iloc[:, 1],
                s=200, linewidths=0, marker='o',
                color=COLMAP.get(src, 'k'),
                alpha=ALPHA_MAP.get(src, 0.5)
            )

        # æ ¹æ®å˜é‡è°ƒæ•´æ•£ç‚¹è½´åˆ»åº¦
        if var == 'HWS':
            ax_scat.set_xlim(0, 16)
            ax_scat.xaxis.set_major_locator(MultipleLocator(4))
            ax_scat.xaxis.set_minor_locator(MultipleLocator(2))
            ax_scat.yaxis.set_major_locator(MultipleLocator(4))
            ax_scat.yaxis.set_minor_locator(MultipleLocator(2))

        elif var == 'VWS':
            ax_scat.set_xlim(-3, 3)
            ax_scat.xaxis.set_major_locator(MultipleLocator(2))
            ax_scat.xaxis.set_minor_locator(MultipleLocator(1))
            ax_scat.yaxis.set_major_locator(MultipleLocator(2))
            ax_scat.yaxis.set_minor_locator(MultipleLocator(1))

        elif var == 'RH':
            ax_scat.xaxis.set_major_locator(FixedLocator([30, 65, 100]))
            ax_scat.xaxis.set_minor_locator(AutoMinorLocator(2))
            ax_scat.yaxis.set_major_locator(FixedLocator([30, 65, 100]))
            ax_scat.yaxis.set_minor_locator(AutoMinorLocator(2))

        elif var == 'Temp':
            ax_scat.xaxis.set_major_locator(MultipleLocator(4))
            ax_scat.xaxis.set_minor_locator(AutoMinorLocator(2))
            ax_scat.yaxis.set_major_locator(MultipleLocator(4))
            ax_scat.yaxis.set_minor_locator(AutoMinorLocator(2))

        # æ•£ç‚¹å›¾è¾¹æ¡†
        for sp in ['top', 'right']:
            ax_scat.spines[sp].set_visible(False)
        for sp in ['bottom', 'left']:
            ax_scat.spines[sp].set_linewidth(6)

# --------------------------------------------------
# 4. Legend & save
# --------------------------------------------------
handles = [
    plt.Line2D([], [],
               color=COLMAP[k],
               lw=15,
               label=LABEL_MAP[k])
    for k in COLMAP
]
fig.legend(
    handles, [h.get_label() for h in handles],
    loc='upper center', ncol=3, frameon=False,
    title_fontsize=80, bbox_to_anchor=(0.5, 0.935)
)

fig.savefig(
    OUT_FILE, dpi=300, format='tif',
    transparent=True, bbox_inches='tight',
    pil_kwargs={'compression': 'tiff_adobe_deflate'}
)
plt.close(fig)
print(f"Plot saved â†’ {OUT_FILE}")
gc.collect()

"""
Generate **sideâ€‘byâ€‘side horizontal boxâ€¯+â€¯jitter** plots for error statistics of
four variables (rows) across three temporal resolutions (columns).
"""


# -----------------------------------------------------------------------------
# 0.  Configuration
# -----------------------------------------------------------------------------
#0607:0916-1500

plt.rcParams.update(plt.rcParamsDefault)
OUT_DIR = Path(r"E:\Beijing2024\å‡ºå›¾TIF")
OUT_DIR.mkdir(parents=True, exist_ok=True)
FIGSIZE = (16, 18)  # inches (width, height)

# â”€ Time-window for filtering data â”€
EXCLUDE_WINDOWS = [
    (pd.Timestamp("2024-08-09 12:46"), pd.Timestamp("2024-08-10 00:03")),
    (pd.Timestamp("2024-06-07 09:16"), pd.Timestamp("2024-06-07 15:00")),
    (pd.Timestamp("2024-08-10 16:20"), pd.Timestamp("2024-08-10 17:30"))
]

plt.rcParams.update({
    'font.family': 'sans-serif',                # å…ˆæŒ‡å®šå®¶æ—
    'font.sans-serif': ['Arial', 'DejaVu Sans'],     # æŠŠ Arial è®¾ä¸ºé¦–é€‰
    "font.size": 22,
    "axes.titlesize": 22,
    "axes.labelsize": 22,
    "xtick.labelsize": 22,
    "ytick.labelsize": 22,
    "legend.fontsize": 22,
    'xtick.major.width': 2,
    'xtick.minor.width': 2,
    'ytick.major.width': 2,
    'ytick.minor.width': 2,
})

COLMAP = {
    "MWR": "red",
    "TowerTurb": "slategray",
    "CRA": "magenta",
    "ERA5": "blue",
    "LiDAR": "darkorange",
}
DISPLAY_NAMES = {
    "TowerTurb": "ECFMS",   
    "LiDAR":"DWL"    
}
VAR_GROUPS = ["Temp", "RH", "HWS", "VWS"]
ROW_LABELS = {
    "Temp": "Temperature (K)\nRef. : AWS",
    "RH": "Relative Humidity (%)\nRef. : AWS",
    "HWS": "Horizontal Wind Speed (m/s)\nRef. : AWS",
    "VWS": "Vertical Wind Speed (m/s)\nRef. : ECM",
}
COL_LABELS = ["1min",  "60min"]#"30min",

# -----------------------------------------------------------------------------
# Expected data in memory
# -----------------------------------------------------------------------------
series_dict_1min  = globals().get("series_dict_1min")
#series_dict_30min = globals().get("series_dict_30min")
series_dict_60min = globals().get("series_dict_60min")
RESOLUTION_DICT = {
    "1min": series_dict_1min,
    #"30min": series_dict_30min,
    "60min": series_dict_60min,
}

REF_MAP = {"Temp": "TowerAvg", "RH": "TowerAvg", "HWS": "TowerAvg", "VWS": "TowerTurb"}
SRC_MAP = {
    "Temp": ["TowerTurb", "MWR", "CRA", "ERA5"],
    "RH":   ["TowerTurb", "MWR", "CRA", "ERA5"],
    "HWS":  ["LiDAR", "TowerTurb", "ERA5", "CRA"],
    "VWS":  ["LiDAR", "ERA5", "CRA"],
}

# -----------------------------------------------------------------------------
# Helper: build longâ€‘form dataframe of errors
# -----------------------------------------------------------------------------
def exclude_time_windows(series, windows):
    """é€ä¸ªæ—¶é—´æ®µæ’é™¤æ•°æ®"""
    for start, end in windows:
        series = series[(series.index < start) | (series.index > end)]
    return series

def align_diff(ref: pd.Series, tgt: pd.Series, *, inside: bool) -> pd.Series:
    """Return tgtâˆ’ref for either inside (True) or outside (False) time window."""
    # slice either inside or outside window
    if inside:
        ref = ref.loc[TIME_START:TIME_END]
        tgt = tgt.loc[TIME_START:TIME_END]
    else:
        ref = ref.loc[(ref.index < TIME_START) | (ref.index > TIME_END)]
        tgt = tgt.loc[(tgt.index < TIME_START) | (tgt.index > TIME_END)]
    aligned = pd.concat([ref, tgt], axis=1, join="inner").dropna()
    return aligned.iloc[:, 1] - aligned.iloc[:, 0]
# ---------------------------------------------------------------------------
# ä¸“é—¨ç»™ 1 min ç”¨çš„ source æ˜ å°„   â˜… CHG â˜…
# ---------------------------------------------------------------------------
SRC_MAP_1MIN = {
    "Temp": ["TowerTurb", "MWR"],
    "RH":   ["TowerTurb", "MWR"],
    "HWS":  ["LiDAR", "TowerTurb"],
    "VWS":  ["LiDAR"],
}

XLIMS_OUTSIDE = {"Temp": (-7, 7), "RH": (-35, 50),
                  "HWS": (-10, 7.5),     "VWS": (-7.5, 2.7)}
STEP_OUTSIDE  = {"Temp": 2, "RH": 20, "HWS": 5, "VWS": 2.5}
# ---------------------------------------------------------------------------
# Helper: build long-form dataframe of errors   â˜… NEW â˜…
# ---------------------------------------------------------------------------
def build_error_df() -> pd.DataFrame:
    """
    ç»Ÿè®¡ **å…¨æ—¶æ®µ** è¯¯å·®ã€‚  
    - å¯¹æ¸©åº¦(T)çš„ MWRï¼Œåœ¨ TIME_STARTâ€“TIME_END å†…çš„æ•°æ®ä¼šè¢«å‰”é™¤ã€‚
    """
    recs = []
    for res, sdict in RESOLUTION_DICT.items():
        if sdict is None:
            continue

        for var in VAR_GROUPS:
            ref_key  = REF_MAP[var]
            src_list = SRC_MAP_1MIN[var] if res == "1min" else SRC_MAP[var]

            for h, series_map in sdict[var].items():
                if ref_key not in series_map:              # å‚è€ƒå€¼ä¸å­˜åœ¨
                    continue
                ref = series_map[ref_key]

                for src in src_list:
                    if src == ref_key or src not in series_map:
                        continue
                    tgt = series_map[src]

                    # â”€â”€â”€ ä»…æ¸©åº¦-MWR éœ€å‰”é™¤æŒ‡å®šæ—¶æ®µ â”€â”€â”€
                    if var == "Temp" and src == "MWR":
                        tgt = exclude_time_windows(tgt, EXCLUDE_WINDOWS)

                    # å¯¹é½å¹¶æ±‚å·®
                    aligned = pd.concat([ref, tgt], axis=1, join="inner").dropna()
                    diff    = aligned.iloc[:, 1] - aligned.iloc[:, 0]

                    recs.extend({
                        "resolution": res,
                        "variable"  : var,
                        "source"    : src,
                        "error"     : d,
                    } for d in diff.values)

    return pd.DataFrame.from_records(recs)

def summarize_errors(df: pd.DataFrame) -> pd.DataFrame:
    """
    è®¡ç®—æ¯ä¸ª (resolution, variable, source) ç»„åˆçš„
    mean / median / q25 / q75 / IQR / whisker_low / whisker_highã€‚
    ä¸ matplotlib.boxplot é»˜è®¤è®¾ç½®ä¿æŒä¸€è‡´ï¼š
    whisker = q1 Â± 1.5 Ã— IQRï¼ˆå†æˆªæ–­åˆ°å…¨å±€ min/maxï¼‰ã€‚
    """
    grp = df.groupby(["resolution", "variable", "source"])["error"]

    summary = grp.agg(
        count  = "size",
        mean   = "mean",
        median = "median",
        q25    = lambda x: x.quantile(0.25),
        q75    = lambda x: x.quantile(0.75),
        min    = "min",
        max    = "max",
    )

    summary["iqr"] = summary.q75 - summary.q25
    summary["whisker_low"]  = (summary.q25 - 1.5 * summary.iqr).clip(lower=summary["min"])
    summary["whisker_high"] = (summary.q75 + 1.5 * summary.iqr).clip(upper=summary["max"])

    # è°ƒæ•´åˆ—é¡ºåºæ›´ç›´è§‚
    summary = summary[[
        "count", "mean", "median", "q25", "q75",
        "iqr", "whisker_low", "whisker_high", "min", "max"
    ]]

    return summary
# -----------------------------------------------------------------------------
# Plotting
# -----------------------------------------------------------------------------
from matplotlib.lines import Line2D
def make_plot(df: pd.DataFrame, outfile: Path, top_caption: str, bottom_caption: str, xlims: dict, steps: dict):
    
    fig, axes = plt.subplots(nrows=len(VAR_GROUPS), ncols=len(COL_LABELS) , figsize=FIGSIZE, sharex=False, sharey=False)
    fig.subplots_adjust(wspace=0.4, hspace=0.4)
    box_offset = 0.5  # left of tick
    scatter_offset = -0.5  # right of tick (more separation than before)
    box_width = 0.5
    scatter_size = 18
    scatter_alpha = 1
    row_spacing_factor = 1.7
    
    for r, var in enumerate(VAR_GROUPS):
        # Row labels -------------------------------------------------------------
        fig.text(0.08, 0.82 - r * 0.215, ROW_LABELS[var], rotation=90, va="center", ha="center",fontsize = 22)
    
        for c, res in enumerate(COL_LABELS):
            if r == 0:
                fig.text(0.13 + (c + 0.5) * 0.92 / len(COL_LABELS), 0.90, res, ha="center", va="bottom",fontsize = 22)
    
            ax = axes[r, c]
            subset = df.query("variable == @var and resolution == @res")
            # if subset.empty:
            #     ax.text(0.5, 0.5, "No data", ha="center", va="center", alpha=0.6)
            #     ax.set_xticks([]); ax.set_yticks([]); ax.set_frame_on(False)
            #     continue
    
            # â˜… CHG â˜…
            order = SRC_MAP_1MIN[var] if res == "1min" else SRC_MAP[var]
            display_order = [DISPLAY_NAMES.get(s, s) for s in order]

            y_pos = np.arange(len(order)) * row_spacing_factor   # â† greater spacing
            for i, src in enumerate(order):
                e = subset.loc[subset["source"] == src, "error"].values
                if e.size == 0:
                    continue
                ax.boxplot(e, zorder=2,
                           vert=False,
                           positions=[y_pos[i] + box_offset], 
                           widths=box_width,#showmeans=True,
                           patch_artist=True, manage_ticks=False,
                           boxprops=dict(facecolor=COLMAP[src], alpha=1, linewidth=2.5),
                           #meanprops=dict(marker="^", markerfacecolor="white", markeredgecolor='crimson', markersize=10, linewidth=0),
                           flierprops=dict(marker="x", markeredgecolor=COLMAP[src], markerfacecolor="none",
                                    markersize=7, linewidth=0.5, alpha=scatter_alpha),
                           medianprops=dict(color="lime", linewidth=2), 
                           whiskerprops=dict(color="black", linewidth=2.5), 
                           capprops=dict(color="black", linewidth=2.5)
                           )
                mean_val = e.mean()
                ax.scatter(mean_val, y_pos[i] + scatter_offset, marker="^",zorder=3,edgecolors="white",
                           color='crimson', s=180, linewidths=2, alpha=1)  # mean
                jitter_y = np.random.normal(y_pos[i] + scatter_offset, 0.08, size=len(e))
                ax.scatter(e, jitter_y, s=scatter_size, color=COLMAP[src], alpha=scatter_alpha, linewidths=0)
    
            ax.set_yticks(y_pos)
            ax.set_yticklabels(display_order)
            ax.set_ylim(y_pos[0] - 1, y_pos[-1] + 1)
            ax.grid(axis="x", linestyle=(0, (5, 10)), alpha=0.6,color = 'black',linewidth = 2.5,zorder=3)
            ax.spines["top"].set_visible(False)
            ax.spines["right"].set_visible(False)
            ax.spines["left"].set_visible(True)
            ax.spines["left"].set_linewidth(2)
            ax.spines["bottom"].set_linewidth(2)
            # â”€â”€â”€ x-limits & ticks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            ax.set_xlim(*xlims[var])                                # â˜… CHG â˜…
            major = steps[var]                                      # â˜… CHG â˜…
            ax.xaxis.set_major_locator(mticker.MultipleLocator(major))
            ax.xaxis.set_minor_locator(mticker.MultipleLocator(major / 2))
            ax.tick_params(axis="x", which="major", length=9)       # â˜… CHG â˜…
            ax.tick_params(axis="x", which="minor", length=4.5)     # â˜… CHG â˜…
            ax.tick_params(axis="y", which="major", length=9)
        
# -----------------------------------------------------------------------------
# Legend
# -----------------------------------------------------------------------------

    handles = [mlines.Line2D([], [], color=COLMAP[s], marker="s", linestyle="", markersize=16,
                             markerfacecolor=COLMAP[s], label=DISPLAY_NAMES.get(s, s))
               for s in COLMAP]
    # æŠŠ '\n' â†’ ' 'ï¼Œè¿™æ · legend é‡Œå°±æ˜¯å•è¡Œ
    legend_labels = [h.get_label().replace('\n', ' ') for h in handles]
    fig.legend(handles,legend_labels, loc="upper center", ncol=6, frameon=False, bbox_to_anchor=(0.55, 0.99))
    
    handle_mean   = Line2D([], [], marker="^", markersize=14,
                           linestyle="", markeredgecolor="white",
                           markerfacecolor="crimson", color="crimson",
                           label="Mean (â–²)")
    handle_median = Line2D([], [], linestyle="-", linewidth=4,
                           color="lime", label="Median (â€”)")
    
    fig.legend([handle_mean, handle_median],
               ["Mean", "Median"],
               loc="lower left",
               bbox_to_anchor=(0.04, 0.02),   # â† å·¦ä¸‹è§’ç•™ä¸€ç‚¹è¾¹è·
               frameon=False, fontsize=22)
    # fig.text(0.58, 0.045,
    #          "Observation Biases = Ground-based Remote Sensing Datasets/Reanalysis - Ref.",
    #          ha="center", va="bottom", fontsize=22)
    
    if top_caption:
        fig.text(0.55, 0.93, top_caption, ha="center", va="bottom",
                 fontsize=22, fontstyle="italic", fontweight="bold")
        
    fig.tight_layout(rect=[0.08, 0.05, 1, 0.92])
    fig.savefig(outfile, dpi=600, format="tif", transparent=True, bbox_inches="tight", pil_kwargs={"compression": "tiff_adobe_deflate"})
    print("Saved â†’", outfile)
    
# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# # 4.  Build two dataframes & plot
# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# print("Building DF (inside window)...")
# df_in = build_error_df(inside=True)
# make_plot(
#     df_in,
#     OUT_DIR / "Error_Eval_BoxJitter_WINDOW.tif",
#     top_caption=f"Rainstorm Events: {TIME_START.strftime('%Y-%m-%d %H:%M')} â€” {TIME_END.strftime('%Y-%m-%d %H:%M')}(BJT) Included",  ### CHG ###
#     bottom_caption=f"Bias inside {TIME_START} â€” {TIME_END}",
#     xlims=XLIMS_INSIDE, steps=STEP_INSIDE
# )

# print("Building DF (outside window)...")
# df_out = build_error_df(inside=False)
# make_plot(
#     df_out,
#     OUT_DIR / "Error_Eval_BoxJitter_EXCLUDE.tif",
#     top_caption=f"Rainstorm Events: {TIME_START.strftime('%Y-%m-%d %H:%M')} â€” {TIME_END.strftime('%Y-%m-%d %H:%M')}(BJT) Excluded",  ### CHG ###
#     bottom_caption=f"Bias excluding {TIME_START} â€” {TIME_END}",
#     xlims=XLIMS_OUTSIDE, steps=STEP_OUTSIDE
# )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4.  Build dataframe & plot   â˜… ONLY ONCE â˜…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("Building full-period dataframe â€¦")
df_all = build_error_df()

make_plot(
    df_all,
    OUT_DIR / "Error_Eval_BoxJitter_window.tif",
    top_caption = (#f"MWR-Temp data between "
                   #f"{TIME_START:%Y-%m-%d %H:%M} â€” {TIME_END:%m-%d %H:%M} (BJT) "
                   "Rainfall Period analysis"),
    bottom_caption = "",
    xlims = XLIMS_OUTSIDE,   # â† ç»§ç»­ç”¨ä½ åŸå…ˆçš„ä¸€å¥—èŒƒå›´
    steps = STEP_OUTSIDE
)

stats_df = summarize_errors(df_all)

# â€”â€” å†™ Excelï¼šæ¯ä¸ª variable å•ç‹¬ä¸€ä¸ª sheetï¼Œæ›´æ–¹ä¾¿æŸ¥çœ‹ â€”â€”
# out_excel = OUT_DIR / "error_stats.xlsx"
# with pd.ExcelWriter(out_excel, engine="openpyxl") as writer:
#     for var, sub in stats_df.groupby(level="variable"):
#         # å–æ¶ˆ variable è¿™ä¸€å±‚ç´¢å¼•ï¼Œä¿ç•™å…¶ä½™ä¸¤å±‚å¯è¯»æ€§æ›´å¥½
#         sub.droplevel("variable").to_excel(writer, sheet_name=var)

# print(f"Statistics saved â†’ {out_excel}")





#####è¿™ä¸ªä»£ç ä¸€æ¬¡èƒ½ç”Ÿæˆå…¨éƒ¨çš„ï¼ŒåŒ…å«é™æ°´æ—¶é—´æ®µçš„å’Œä¸åŒ…å«é™æ°´æ—¶é—´æ®µçš„ä¸‰å¼ å›¾####
#####åŒ…å«ç‰¹å®šæ—¶é—´çª—çš„ç»˜å›¾####
OUT_DIR = Path(r"E:\Beijing2024\å‡ºå›¾TIF")
OUT_DIR.mkdir(parents=True, exist_ok=True)
FIGSIZE = (16, 18)  # inches (width, height)
# â”€ Time-window for filtering data â”€
EXCLUDE_WINDOWS = [
    (pd.Timestamp("2024-08-09 12:46"), pd.Timestamp("2024-08-10 00:03")),
    (pd.Timestamp("2024-06-07 09:16"), pd.Timestamp("2024-06-07 15:00")),
    (pd.Timestamp("2024-08-10 16:20"), pd.Timestamp("2024-08-10 17:30"))
]
plt.rcParams.update({
    'font.family': 'sans-serif',                # å…ˆæŒ‡å®šå®¶æ—
    'font.sans-serif': ['Arial', 'DejaVu Sans'],     # æŠŠ Arial è®¾ä¸ºé¦–é€‰
    "font.size": 22,
    "axes.titlesize": 22,
    "axes.labelsize": 22,
    "xtick.labelsize": 22,
    "ytick.labelsize": 22,
    "legend.fontsize": 22,
    'xtick.major.width': 2,
    'xtick.minor.width': 2,
    'ytick.major.width': 2,
    'ytick.minor.width': 2,
})
COLMAP = {
    "MWR": "red",
    "TowerTurb": "slategray",
    "CRA": "magenta",
    "ERA5": "blue",
    "LiDAR": "darkorange",
}
DISPLAY_NAMES = {
    "TowerTurb": "ECM",   
    "LiDAR":"DWL"
}
VAR_GROUPS = ["Temp", "RH", "HWS", "VWS"]
ROW_LABELS = {
    "Temp": "Temperature (K)\nRef. : AWS",
    "RH": "Relative Humidity (%)\nRef. : AWS",
    "HWS": "Horizontal Wind Speed (m/s)\nRef. : AWS",
    "VWS": "Vertical Wind Speed (m/s)\nRef. : ECM",
}
COL_LABELS = ["1min",  "60min"]#"30min",
# -----------------------------------------------------------------------------
# Expected data in memory
# -----------------------------------------------------------------------------
series_dict_1min  = globals().get("series_dict_1min")
#series_dict_30min = globals().get("series_dict_30min")
series_dict_60min = globals().get("series_dict_60min")
RESOLUTION_DICT = {
    "1min": series_dict_1min,
    #"30min": series_dict_30min,
    "60min": series_dict_60min,
}
REF_MAP = {"Temp": "TowerAvg", "RH": "TowerAvg", "HWS": "TowerAvg", "VWS": "TowerTurb"}
SRC_MAP = {
    "Temp": ["TowerTurb", "MWR", "CRA", "ERA5"],
    "RH":   ["TowerTurb", "MWR", "CRA", "ERA5"],
    "HWS":  ["LiDAR", "TowerTurb", "ERA5", "CRA"],
    "VWS":  ["LiDAR", "ERA5", "CRA"],
}
# -----------------------------------------------------------------------------
# Helper: build longâ€‘form dataframe of errors
# -----------------------------------------------------------------------------
def include_time_windows(series, windows, inside=True):
    """æ ¹æ®insideå‚æ•°å†³å®šæ˜¯åŒ…å«è¿˜æ˜¯æ’é™¤æŒ‡å®šæ—¶é—´çª—å£å†…çš„æ•°æ®"""
    # å¦‚æœæ²¡æœ‰çª—å£ï¼Œè¿”å›åŸæ•°æ®
    if not windows:
        return series
    
    # åˆå§‹åŒ–ä¸€ä¸ªå…¨ä¸ºFalseçš„å¸ƒå°”Series
    mask = pd.Series(False, index=series.index)
    
    # å¯¹æ¯ä¸ªçª—å£ï¼Œå°†çª—å£å†…çš„æ•°æ®æ ‡è®°ä¸ºTrue
    for start, end in windows:
        mask = mask | ((series.index >= start) & (series.index <= end))
    
    # æ ¹æ®insideå‚æ•°è¿”å›æ•°æ®
    if inside:
        return series[mask]
    else:
        return series[~mask]

def align_diff(ref: pd.Series, tgt: pd.Series, *, inside: bool) -> pd.Series:
    """Return tgtâˆ’ref for either inside (True) or outside (False) time window."""
    # slice either inside or outside window
    if inside:
        ref = ref.loc[TIME_START:TIME_END]
        tgt = tgt.loc[TIME_START:TIME_END]
    else:
        ref = ref.loc[(ref.index < TIME_START) | (ref.index > TIME_END)]
        tgt = tgt.loc[(tgt.index < TIME_START) | (tgt.index > TIME_END)]
    aligned = pd.concat([ref, tgt], axis=1, join="inner").dropna()
    return aligned.iloc[:, 1] - aligned.iloc[:, 0]
# ---------------------------------------------------------------------------
# ä¸“é—¨ç»™ 1 min ç”¨çš„ source æ˜ å°„   â˜… CHG â˜…
# ---------------------------------------------------------------------------
SRC_MAP_1MIN = {
    "Temp": ["TowerTurb", "MWR"],
    "RH":   ["TowerTurb", "MWR"],
    "HWS":  ["LiDAR", "TowerTurb"],
    "VWS":  ["LiDAR"],
}

XLIMS_INSIDE = {"Temp": (-7.5, 17.5),   "RH": (-40, 40),
                "HWS": (-10, 15),    "VWS": (-7.5, 2.5)}
STEP_INSIDE  = {"Temp": 5, "RH": 10, "HWS": 2.5, "VWS": 2.5}
XLIMS_OUTSIDE = {"Temp": (-9, 13), "RH": (-60, 60),
                  "HWS": (-10, 7.5),     "VWS": (-7.5, 5)}
STEP_OUTSIDE  = {"Temp": 2, "RH": 20, "HWS": 2.5, "VWS": 2.5}
# ---------------------------------------------------------------------------
# Helper: build long-form dataframe of errors   â˜… NEW â˜…
# ---------------------------------------------------------------------------
def build_error_df(inside=True) -> pd.DataFrame:
    """
    ç»Ÿè®¡è¯¯å·®æ•°æ®ï¼Œæ ¹æ®insideå‚æ•°å†³å®šæ˜¯åŒ…å«è¿˜æ˜¯æ’é™¤ç‰¹å®šæ—¶é—´çª—å£å†…çš„æ•°æ®ã€‚
    - inside=True: åªä¿ç•™åœ¨EXCLUDE_WINDOWSå®šä¹‰çš„æ—¶é—´çª—å£å†…çš„æ•°æ®
    - inside=False: åªä¿ç•™åœ¨EXCLUDE_WINDOWSå®šä¹‰çš„æ—¶é—´çª—å£å¤–çš„æ•°æ®
    """
    recs = []
    for res, sdict in RESOLUTION_DICT.items():
        if sdict is None:
            continue
        for var in VAR_GROUPS:
            ref_key  = REF_MAP[var]
            src_list = SRC_MAP_1MIN[var] if res == "1min" else SRC_MAP[var]
            for h, series_map in sdict[var].items():
                if ref_key not in series_map:              # å‚è€ƒå€¼ä¸å­˜åœ¨
                    continue
                ref = series_map[ref_key]
                # â”€â”€â”€ å¯¹æ‰€æœ‰æ•°æ®åº”ç”¨æ—¶é—´çª—å£è¿‡æ»¤ â”€â”€â”€
                ref = include_time_windows(ref, EXCLUDE_WINDOWS, inside=inside)
                for src in src_list:
                    if src == ref_key or src not in series_map:
                        continue
                    tgt = series_map[src]
                    # â”€â”€â”€ å¯¹æ‰€æœ‰æ•°æ®åº”ç”¨æ—¶é—´çª—å£è¿‡æ»¤ â”€â”€â”€
                    tgt = include_time_windows(tgt, EXCLUDE_WINDOWS, inside=inside)
                    # å¯¹é½å¹¶æ±‚å·®
                    aligned = pd.concat([ref, tgt], axis=1, join="inner").dropna()
                    diff    = aligned.iloc[:, 1] - aligned.iloc[:, 0]
                    recs.extend({
                        "resolution": res,
                        "variable"  : var,
                        "source"    : src,
                        "error"     : d,
                    } for d in diff.values)
    return pd.DataFrame.from_records(recs)
def summarize_errors(df: pd.DataFrame) -> pd.DataFrame:
    """
    è®¡ç®—æ¯ä¸ª (resolution, variable, source) ç»„åˆçš„
    mean / median / q25 / q75 / IQR / whisker_low / whisker_highã€‚
    ä¸ matplotlib.boxplot é»˜è®¤è®¾ç½®ä¿æŒä¸€è‡´ï¼š
    whisker = q1 Â± 1.5 Ã— IQRï¼ˆå†æˆªæ–­åˆ°å…¨å±€ min/maxï¼‰ã€‚
    """
    grp = df.groupby(["resolution", "variable", "source"])["error"]
    summary = grp.agg(
        count  = "size",
        mean   = "mean",
        median = "median",
        q25    = lambda x: x.quantile(0.25),
        q75    = lambda x: x.quantile(0.75),
        min    = "min",
        max    = "max",
    )
    summary["iqr"] = summary.q75 - summary.q25
    summary["whisker_low"]  = (summary.q25 - 1.5 * summary.iqr).clip(lower=summary["min"])
    summary["whisker_high"] = (summary.q75 + 1.5 * summary.iqr).clip(upper=summary["max"])
    # è°ƒæ•´åˆ—é¡ºåºæ›´ç›´è§‚
    summary = summary[[
        "count", "mean", "median", "q25", "q75",
        "iqr", "whisker_low", "whisker_high", "min", "max"
    ]]
    return summary
# -----------------------------------------------------------------------------
# Plotting
# -----------------------------------------------------------------------------
from matplotlib.lines import Line2D
def make_plot(df: pd.DataFrame, outfile: Path, top_caption: str, bottom_caption: str, xlims: dict, steps: dict):
    
    fig, axes = plt.subplots(nrows=len(VAR_GROUPS), ncols=len(COL_LABELS) , figsize=FIGSIZE, sharex=False, sharey=False)
    fig.subplots_adjust(wspace=0.4, hspace=0.4)
    box_offset = 0.5  # left of tick
    scatter_offset = -0.5  # right of tick (more separation than before)
    box_width = 0.5
    scatter_size = 18
    scatter_alpha = 1
    row_spacing_factor = 1.7
    
    for r, var in enumerate(VAR_GROUPS):
        # Row labels -------------------------------------------------------------
        fig.text(0.08, 0.82 - r * 0.215, ROW_LABELS[var], rotation=90, va="center", ha="center",fontsize = 22)
    
        for c, res in enumerate(COL_LABELS):
            if r == 0:
                fig.text(0.13 + (c + 0.5) * 0.92 / len(COL_LABELS), 0.90, res, ha="center", va="bottom",fontsize = 22)
    
            ax = axes[r, c]
            subset = df.query("variable == @var and resolution == @res")
    
            # â˜… CHG â˜…
            order = SRC_MAP_1MIN[var] if res == "1min" else SRC_MAP[var]
            display_order = [DISPLAY_NAMES.get(s, s) for s in order]
            y_pos = np.arange(len(order)) * row_spacing_factor   # â† greater spacing
            for i, src in enumerate(order):
                e = subset.loc[subset["source"] == src, "error"].values
                if e.size == 0:
                    continue
                ax.boxplot(e, zorder=2,
                           vert=False,
                           positions=[y_pos[i] + box_offset], 
                           widths=box_width,#showmeans=True,
                           patch_artist=True, manage_ticks=False,
                           boxprops=dict(facecolor=COLMAP[src], alpha=1, linewidth=2.5),
                           #meanprops=dict(marker="^", markerfacecolor="white", markeredgecolor='crimson', markersize=10, linewidth=0),
                           flierprops=dict(marker="x", markeredgecolor=COLMAP[src], markerfacecolor="none",
                                    markersize=7, linewidth=0.5, alpha=scatter_alpha),
                           medianprops=dict(color="lime", linewidth=2), 
                           whiskerprops=dict(color="black", linewidth=2.5), 
                           capprops=dict(color="black", linewidth=2.5)
                           )
                mean_val = e.mean()
                ax.scatter(mean_val, y_pos[i] + scatter_offset, marker="^",zorder=3,edgecolors="white",
                           color='crimson', s=180, linewidths=2, alpha=1)  # mean
                jitter_y = np.random.normal(y_pos[i] + scatter_offset, 0.08, size=len(e))
                ax.scatter(e, jitter_y, s=scatter_size, color=COLMAP[src], alpha=scatter_alpha, linewidths=0)
    
            ax.set_yticks(y_pos)
            ax.set_yticklabels(display_order)
            ax.set_ylim(y_pos[0] - 1, y_pos[-1] + 1)
            ax.grid(axis="x", linestyle=(0, (5, 10)), alpha=0.6,color = 'black',linewidth = 2.5,zorder=3)
            ax.spines["top"].set_visible(False)
            ax.spines["right"].set_visible(False)
            ax.spines["left"].set_visible(True)
            ax.spines["left"].set_linewidth(2)
            ax.spines["bottom"].set_linewidth(2)
            # â”€â”€â”€ x-limits & ticks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            ax.set_xlim(*xlims[var])                                # â˜… CHG â˜…
            major = steps[var]                                      # â˜… CHG â˜…
            ax.xaxis.set_major_locator(mticker.MultipleLocator(major))
            ax.xaxis.set_minor_locator(mticker.MultipleLocator(major / 2))
            ax.tick_params(axis="x", which="major", length=9)       # â˜… CHG â˜…
            ax.tick_params(axis="x", which="minor", length=4.5)     # â˜… CHG â˜…
            ax.tick_params(axis="y", which="major", length=9)
        
# -----------------------------------------------------------------------------
# Legend
# -----------------------------------------------------------------------------
    handles = [mlines.Line2D([], [], color=COLMAP[s], marker="s", linestyle="", markersize=16,
                             markerfacecolor=COLMAP[s], label=DISPLAY_NAMES.get(s, s))
               for s in COLMAP]
    # æŠŠ '\n' â†’ ' 'ï¼Œè¿™æ · legend é‡Œå°±æ˜¯å•è¡Œ
    legend_labels = [h.get_label().replace('\n', ' ') for h in handles]
    fig.legend(handles,legend_labels, loc="upper center", ncol=6, frameon=False, bbox_to_anchor=(0.55, 0.99))
    
    handle_mean   = Line2D([], [], marker="^", markersize=14,
                           linestyle="", markeredgecolor="white",
                           markerfacecolor="crimson", color="crimson",
                           label="Mean (â–²)")
    handle_median = Line2D([], [], linestyle="-", linewidth=4,
                           color="lime", label="Median (â€”)")
    
    fig.legend([handle_mean, handle_median],
               ["Mean", "Median"],
               loc="lower left",
               bbox_to_anchor=(0.04, 0.02),   # â† å·¦ä¸‹è§’ç•™ä¸€ç‚¹è¾¹è·
               frameon=False, fontsize=22)
    fig.text(0.58, 0.045,
             "Observation Biases = Ground-based Remote Sensing Datasets/Reanalysis - Ref.",
             ha="center", va="bottom", fontsize=22)
    
    if top_caption:
        fig.text(0.55, 0.93, top_caption, ha="center", va="bottom",
                 fontsize=22, fontstyle="italic", fontweight="bold")
        
    fig.tight_layout(rect=[0.08, 0.05, 1, 0.92])
    fig.savefig(outfile, dpi=600, format="tif", transparent=True, bbox_inches="tight", pil_kwargs={"compression": "tiff_adobe_deflate"})
    print("Saved â†’", outfile)
    
# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# # 4.  Build two dataframes & plot
# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("Building DF (inside window)...")
df_in = build_error_df(inside=True)
make_plot(
    df_in,
    OUT_DIR / "Error_Eval_BoxJitter_WINDOW.tif",
    top_caption=f"",  #Rainstorm Events: {EXCLUDE_WINDOWS[0][0].strftime('%Y-%m-%d %H:%M')} â€” {EXCLUDE_WINDOWS[-1][1].strftime('%Y-%m-%d %H:%M')}(BJT) Included## CHG ###
    bottom_caption=f"Bias inside specified windows",
    xlims=XLIMS_INSIDE, steps=STEP_INSIDE
)
print("Building DF (outside window)...")
df_out = build_error_df(inside=False)
make_plot(
    df_out,
    OUT_DIR / "Error_Eval_BoxJitter_EXCLUDE.tif",
    top_caption=f"",  #Rainstorm Events: {EXCLUDE_WINDOWS[0][0].strftime('%Y-%m-%d %H:%M')} â€” {EXCLUDE_WINDOWS[-1][1].strftime('%Y-%m-%d %H:%M')}(BJT) Excluded## CHG ###
    bottom_caption=f"Bias excluding specified windows",
    xlims=XLIMS_OUTSIDE, steps=STEP_OUTSIDE
)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4.  Build dataframe & plot   â˜… ONLY ONCE â˜…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("Building full-period dataframe â€¦")
# å¯¹äºå…¨å‘¨æœŸæ•°æ®ï¼Œæˆ‘ä»¬ä¸ä½¿ç”¨æ—¶é—´çª—å£è¿‡æ»¤
def build_full_error_df() -> pd.DataFrame:
    """
    ç»Ÿè®¡å…¨å‘¨æœŸè¯¯å·®æ•°æ®ï¼Œä¸è¿›è¡Œæ—¶é—´çª—å£è¿‡æ»¤
    """
    recs = []
    for res, sdict in RESOLUTION_DICT.items():
        if sdict is None:
            continue
        for var in VAR_GROUPS:
            ref_key  = REF_MAP[var]
            src_list = SRC_MAP_1MIN[var] if res == "1min" else SRC_MAP[var]
            for h, series_map in sdict[var].items():
                if ref_key not in series_map:              # å‚è€ƒå€¼ä¸å­˜åœ¨
                    continue
                ref = series_map[ref_key]
                for src in src_list:
                    if src == ref_key or src not in series_map:
                        continue
                    tgt = series_map[src]
                    # å¯¹é½å¹¶æ±‚å·®
                    aligned = pd.concat([ref, tgt], axis=1, join="inner").dropna()
                    diff    = aligned.iloc[:, 1] - aligned.iloc[:, 0]
                    recs.extend({
                        "resolution": res,
                        "variable"  : var,
                        "source"    : src,
                        "error"     : d,
                    } for d in diff.values)
    return pd.DataFrame.from_records(recs)

df_all = build_full_error_df()
make_plot(
    df_all,
    OUT_DIR / "Error_Eval_BoxJitter_ALL.tif",
    top_caption = "",
    bottom_caption = "",
    xlims = XLIMS_OUTSIDE,   # â† ç»§ç»­ç”¨ä½ åŸå…ˆçš„ä¸€å¥—èŒƒå›´
    steps = STEP_OUTSIDE
)
stats_df = summarize_errors(df_all)

#â€”â€” å†™ Excelï¼šæ¯ä¸ª variable å•ç‹¬ä¸€ä¸ª sheetï¼Œæ›´æ–¹ä¾¿æŸ¥çœ‹ â€”â€”
out_excel = OUT_DIR / "error_stats.xlsx"
with pd.ExcelWriter(out_excel, engine="openpyxl") as writer:
    for var, sub in stats_df.groupby(level="variable"):
        # å–æ¶ˆ variable è¿™ä¸€å±‚ç´¢å¼•ï¼Œä¿ç•™å…¶ä½™ä¸¤å±‚å¯è¯»æ€§æ›´å¥½
        sub.droplevel("variable").to_excel(writer, sheet_name=var)
print(f"Statistics saved â†’ {out_excel}")

# å¯¹äºåŒ…å«ç‰¹å®šæ—¶é—´çª—çš„æ•°æ®ç»Ÿè®¡åŠä¿å­˜
stats_df_in = summarize_errors(df_in)

# å¯¹äºæ’é™¤ç‰¹å®šæ—¶é—´çª—çš„æ•°æ®ç»Ÿè®¡åŠä¿å­˜
stats_df_out = summarize_errors(df_out)

# å†™å…¥Excelï¼šæ¯ä¸ªvariableå•ç‹¬ä¸€ä¸ªsheetï¼Œå¯¹äºåŒ…å«ç‰¹å®šæ—¶é—´çª—çš„æ•°æ®
out_excel_in = OUT_DIR / "error_stats_inside_window.xlsx"
with pd.ExcelWriter(out_excel_in, engine="openpyxl") as writer:
    for var, sub in stats_df_in.groupby(level="variable"):
        # å–æ¶ˆvariableè¿™ä¸€å±‚ç´¢å¼•ï¼Œä¿ç•™å…¶ä½™ä¸¤å±‚å¯è¯»æ€§æ›´å¥½
        sub.droplevel("variable").to_excel(writer, sheet_name=var)
print(f"Statistics saved â†’ {out_excel_in}")

# å†™å…¥Excelï¼šæ¯ä¸ªvariableå•ç‹¬ä¸€ä¸ªsheetï¼Œå¯¹äºæ’é™¤ç‰¹å®šæ—¶é—´çª—çš„æ•°æ®
out_excel_out = OUT_DIR / "error_stats_exclude_window.xlsx"
with pd.ExcelWriter(out_excel_out, engine="openpyxl") as writer:
    for var, sub in stats_df_out.groupby(level="variable"):
        # å–æ¶ˆvariableè¿™ä¸€å±‚ç´¢å¼•ï¼Œä¿ç•™å…¶ä½™ä¸¤å±‚å¯è¯»æ€§æ›´å¥½
        sub.droplevel("variable").to_excel(writer, sheet_name=var)
print(f"Statistics saved â†’ {out_excel_out}")



import matplotlib.gridspec as gridspec  # æ·»åŠ è¿™ä¸€è¡Œ
import matplotlib as mpl
import matplotlib.pyplot as plt
try:
    import seaborn as sns
    sns.reset_defaults()       # è¿˜åŸ seaborn
except Exception:
    pass
mpl.rcParams.update(mpl.rcParamsDefault)  # è¿˜åŸ Matplotlib é»˜è®¤
plt.style.use('default')                  # è¿˜åŸæ ·å¼è¡¨

###############è¿‘åœ°å±‚æ¸©æ¹¿é£è¯¯å·®è¯„ä¼°############################
# =============================================================================
# 0. ä¾èµ–ä¸å…¨å±€å¸¸é‡ï¼ˆä¿æŒä¸å˜ï¼‹æ–°å¢ RH ç›¸å…³å¸¸é‡ï¼‰
# =============================================================================

# ---- ä½ çš„å·²æœ‰å¸¸é‡ ----
HEIGHTS      = [80, 140, 200, 280]
# â”€â”€ æ•°æ®æºé¢œè‰² & æ˜¾ç¤ºåï¼ˆåŒå‰ï¼‰
COLMAP = {"MWR":"red", "TowerTurb":"slategray",
          "CRA":"magenta", "ERA5":"blue", "LiDAR":"darkorange"}
DISPLAY_NAMES = {"TowerTurb":"ECM", "LiDAR":"DWL"}
# â”€â”€ æ¯ä¸ªåˆ†è¾¨ç‡å…è®¸å‡ºç°çš„æ•°æ®æº
RES_SRC_RH = {
    "1min" : ["TowerTurb", "MWR"],
    "60min": ["TowerTurb", "MWR", "ERA5", "CRA"],
}
RES_SRC_TEMP = {
    "1min" : ["TowerTurb", "MWR"],
    "60min": ["TowerTurb", "MWR", "ERA5", "CRA"],
}
RES_SRC_HWS = {
    "1min": ["LiDAR", "TowerTurb"],
    "60min": ["LiDAR", "TowerTurb", "ERA5", "CRA"],
}
plt.rcParams.update({
    'font.size': 26,
    'font.family': 'sans-serif',                
    'font.sans-serif': ['Arial', 'DejaVu Sans'],     
    'axes.titlepad': 8,
    'legend.fontsize': 26,
    'axes.labelsize': 26,
    'xtick.labelsize': 26,
    'ytick.labelsize': 26,
    'xtick.major.size': 10,
    'xtick.minor.size': 5,
    'ytick.major.size': 10,
    'ytick.minor.size': 5,
    'xtick.direction': 'out',
    'ytick.direction': 'out',
    'xtick.major.width': 2,
    'xtick.minor.width': 2,
    'ytick.major.width': 2,
    'ytick.minor.width': 2,
})

# ---- RH æ¡£åˆ’åˆ† & é¢œè‰² ----
RH_BINS = {                                           # å·¦é—­å³å¼€
    "Low RH (<50%)"      : (-np.inf, 50),
    "Middle RH (50â€“80%)"    : (50, 80),
    "High RH (>80%)"     : (80,  np.inf),
}
RH_ORDER  = list(RH_BINS.keys())                      # ä¸ºäº†å›ºå®šé¡ºåº
RH_COLORS = {                                         # ç®±/æ•£ç‚¹é¢œè‰²
    "Low RH (<50%)"   : "#1f77b4",   # è“
    "Middle RH (50â€“80%)" : "#2ca02c",   # ç»¿
    "High RH (>80%)"  : "#d62728",   # çº¢
}

# ---- Temp æ¡£åˆ’åˆ† & é¢œè‰² ----
TEMP_BINS = {                                # å·¦é—­å³å¼€
    "Low T (<300 K)"  : (-np.inf, 27+273),
    "Middle T (300â€“303 K)": (27+273 , 30+273),
    "High T (â‰¥303 K)" : (30+273 , np.inf),
}
TEMP_ORDER  = list(TEMP_BINS.keys())         # å›ºå®šç”»å›¾é¡ºåº
TEMP_COLORS = {
    "Low T (<300 K)"  : "#1f77b4",
    "Middle T (300â€“303 K)": "#2ca02c",
    "High T (â‰¥303 K)" : "#d62728",
}

# ---- HWS æ¡£åˆ’åˆ† & é¢œè‰² ----
HWS_BINS = {
    "Low HWS (<3 m/s)": (-np.inf, 3),
    "Middle HWS (3â€“7 m/s)": (3, 7),
    "High HWS (â‰¥7 m/s)": (7, np.inf),
}
HWS_ORDER = list(HWS_BINS.keys())
HWS_COLORS = {
    "Low HWS (<3 m/s)": "#1f77b4",
    "Middle HWS (3â€“7 m/s)": "#2ca02c",
    "High HWS (â‰¥7 m/s)": "#d62728",
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ—¶é—´çª—å£å®šä¹‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EXCLUDE_WINDOWS = [
    (pd.Timestamp("2024-08-09 12:46"), pd.Timestamp("2024-08-10 00:03")),
    (pd.Timestamp("2024-06-07 09:16"), pd.Timestamp("2024-06-07 15:00")),
    (pd.Timestamp("2024-08-10 16:20"), pd.Timestamp("2024-08-10 17:30"))
]

# =============================================================================
# 1. é€šç”¨å‡½æ•°ï¼šæ—¶é—´çª—å£è¿‡æ»¤
# =============================================================================
def filter_by_time_windows(series, windows, inside=True):
    """
    æ ¹æ®æ—¶é—´çª—å£è¿‡æ»¤æ•°æ®
    :param series: æ—¶é—´åºåˆ—æ•°æ®
    :param windows: æ—¶é—´çª—å£åˆ—è¡¨
    :param inside: True-ä¿ç•™çª—å£å†…æ•°æ®ï¼ŒFalse-ä¿ç•™çª—å£å¤–æ•°æ®
    :return: è¿‡æ»¤åçš„æ—¶é—´åºåˆ—
    """
    if not windows:
        return series
    
    mask = pd.Series(False, index=series.index)
    
    for start, end in windows:
        window_mask = (series.index >= start) & (series.index <= end)
        if inside:
            mask = mask | window_mask
        else:
            # å¯¹äºoutsideï¼Œæˆ‘ä»¬ä½¿ç”¨å–åé€»è¾‘
            pass
    
    if inside:
        return series[mask]
    else:
        # å¯¹äºoutsideï¼Œæˆ‘ä»¬éœ€è¦æ ‡è®°æ‰€æœ‰çª—å£å†…çš„ç‚¹ï¼Œç„¶åå–å
        inside_mask = pd.Series(False, index=series.index)
        for start, end in windows:
            inside_mask = inside_mask | ((series.index >= start) & (series.index <= end))
        return series[~inside_mask]

# =============================================================================
# 2. RH æ¡ä»¶è¯¯å·®æ•°æ®æ„å»º
# =============================================================================
def build_rh_error_df(inside=None):
    """
    é’ˆå¯¹ RH (TowerAvg å‚è€ƒ)ï¼š
        * è®¡ç®— src âˆ’ TowerAvg
        * æŒ‰ TowerAvg RH åˆ†å…¥ä½/ä¸­/é«˜æ¡£
        * æ ¹æ®insideå‚æ•°è¿‡æ»¤æ—¶é—´çª—å£
    """
    recs = []
    for res_key, sdict in (("1min",  series_dict_1min),
                           ("60min", series_dict_60min)):
        if sdict is None:
            continue
        src_list = RES_SRC_RH[res_key]
        
        for h in HEIGHTS:
            if "TowerAvg" not in sdict["RH"][h]:
                continue
            ref = sdict["RH"][h]["TowerAvg"].dropna()
            
            # åº”ç”¨æ—¶é—´çª—å£è¿‡æ»¤ï¼ˆå¦‚æœæŒ‡å®šäº†insideå‚æ•°ï¼‰
            if inside is not None:
                ref = filter_by_time_windows(ref, EXCLUDE_WINDOWS, inside=inside)
            
            for src in src_list:
                if src not in sdict["RH"][h]:
                    continue
                tgt = sdict["RH"][h][src].dropna()
                
                # åº”ç”¨æ—¶é—´çª—å£è¿‡æ»¤ï¼ˆå¦‚æœæŒ‡å®šäº†insideå‚æ•°ï¼‰
                if inside is not None:
                    tgt = filter_by_time_windows(tgt, EXCLUDE_WINDOWS, inside=inside)
                
                aligned = pd.concat([ref, tgt], axis=1,
                                    join="inner").dropna()
                diff = aligned.iloc[:, 1] - aligned.iloc[:, 0]
                ref_rh = aligned.iloc[:, 0]
                
                for ts, e in diff.items():
                    rh_val = ref_rh.loc[ts]
                    for rh_bin, (lo, hi) in RH_BINS.items():
                        if lo <= rh_val < hi:
                            recs.append({
                                "resolution": res_key,
                                "height"    : h,
                                "rh_bin"    : rh_bin,
                                "source"    : src,
                                "error"     : e,
                            })
                            break
    return pd.DataFrame.from_records(recs)

# =============================================================================
# 3. Temp æ¡ä»¶è¯¯å·®æ•°æ®æ„å»º
# =============================================================================
def build_temp_error_df(inside=None):
    """
    é’ˆå¯¹ Temp (TowerAvg å‚è€ƒ)ï¼š
        * è®¡ç®— src âˆ’ TowerAvg
        * æŒ‰ TowerAvg Temp åˆ†å…¥ä½/ä¸­/é«˜æ¡£
        * æ ¹æ®insideå‚æ•°è¿‡æ»¤æ—¶é—´çª—å£
    """
    recs = []
    for res_key, sdict in (("1min",  series_dict_1min),
                           ("60min", series_dict_60min)):
        if sdict is None:
            continue
        src_list = RES_SRC_TEMP[res_key]
        
        for h in HEIGHTS:
            if "TowerAvg" not in sdict["Temp"][h]:
                continue
            ref = sdict["Temp"][h]["TowerAvg"].dropna()
            
            # åº”ç”¨æ—¶é—´çª—å£è¿‡æ»¤ï¼ˆå¦‚æœæŒ‡å®šäº†insideå‚æ•°ï¼‰
            if inside is not None:
                ref = filter_by_time_windows(ref, EXCLUDE_WINDOWS, inside=inside)
            
            for src in src_list:
                if src not in sdict["Temp"][h]:
                    continue
                tgt = sdict["Temp"][h][src].dropna()
                
                # åº”ç”¨æ—¶é—´çª—å£è¿‡æ»¤ï¼ˆå¦‚æœæŒ‡å®šäº†insideå‚æ•°ï¼‰
                if inside is not None:
                    tgt = filter_by_time_windows(tgt, EXCLUDE_WINDOWS, inside=inside)
                
                aligned = pd.concat([ref, tgt], axis=1,
                                    join="inner").dropna()
                diff = aligned.iloc[:, 1] - aligned.iloc[:, 0]
                ref_t = aligned.iloc[:, 0]
                
                for ts, e in diff.items():
                    t_val = ref_t.loc[ts]
                    for t_bin, (lo, hi) in TEMP_BINS.items():
                        if lo <= t_val < hi:
                            recs.append({
                                "resolution": res_key,
                                "height"    : h,
                                "temp_bin"  : t_bin,
                                "source"    : src,
                                "error"     : e,
                            })
                            break
    return pd.DataFrame.from_records(recs)

# =============================================================================
# 4. HWS æ¡ä»¶è¯¯å·®æ•°æ®æ„å»º
# =============================================================================
def build_hws_error_df(inside=None):
    """
    é’ˆå¯¹ HWS (TowerAvg å‚è€ƒ)ï¼š
        * è®¡ç®— src âˆ’ TowerAvg
        * æŒ‰ TowerAvg HWS åˆ†å…¥ä½/ä¸­/é«˜æ¡£
        * æ ¹æ®insideå‚æ•°è¿‡æ»¤æ—¶é—´çª—å£
    """
    recs = []
    for res_key, sdict in (("1min",  series_dict_1min),
                           ("60min", series_dict_60min)):
        if sdict is None:
            continue
        src_list = RES_SRC_HWS[res_key]
        
        for h in HEIGHTS:
            if "TowerAvg" not in sdict["HWS"][h]:
                continue
            ref = sdict["HWS"][h]["TowerAvg"].dropna()
            
            # åº”ç”¨æ—¶é—´çª—å£è¿‡æ»¤ï¼ˆå¦‚æœæŒ‡å®šäº†insideå‚æ•°ï¼‰
            if inside is not None:
                ref = filter_by_time_windows(ref, EXCLUDE_WINDOWS, inside=inside)
            
            for src in src_list:
                if src not in sdict["HWS"][h]:
                    continue
                tgt = sdict["HWS"][h][src].dropna()
                
                # åº”ç”¨æ—¶é—´çª—å£è¿‡æ»¤ï¼ˆå¦‚æœæŒ‡å®šäº†insideå‚æ•°ï¼‰
                if inside is not None:
                    tgt = filter_by_time_windows(tgt, EXCLUDE_WINDOWS, inside=inside)
                
                aligned = pd.concat([ref, tgt], axis=1,
                                    join="inner").dropna()
                diff = aligned.iloc[:, 1] - aligned.iloc[:, 0]
                ref_hws = aligned.iloc[:, 0]
                
                for ts, e in diff.items():
                    hws_val = ref_hws.loc[ts]
                    for hws_bin, (lo, hi) in HWS_BINS.items():
                        if lo <= hws_val < hi:
                            recs.append({
                                "resolution": res_key,
                                "height"    : h,
                                "hws_bin"   : hws_bin,
                                "source"    : src,
                                "error"     : e,
                            })
                            break
    return pd.DataFrame.from_records(recs)

# =============================================================================
# 5. ç»˜å›¾å‡½æ•°ï¼ˆRHï¼‰
# =============================================================================
# def make_rh_plot(df: pd.DataFrame, outfile: Path, title_suffix=""):
#     """
#     æ¨ªå‘ 4 é«˜åº¦ Ã— çºµå‘ 2 åˆ†è¾¨ç‡ çš„å­å›¾ç½‘æ ¼ã€‚
#     æ¯ä¸ªå­å›¾é‡Œï¼š
#         * y è½´ = æ•°æ®æºï¼ˆTowerTurb/MWR/ERA5/CRAï¼‰
#         * åŒä¸€æºç”» 3 ä¸ªå¹¶æ’ç®±å›¾ï¼Œå¯¹åº”ä½/ä¸­/é«˜ RH æ¡£
#     """
#     plt.rcParams.update({
#         "font.family":"sans-serif",
#         "font.sans-serif":["Arial","DejaVu Sans"],
#         "font.size":26,
#         "xtick.major.width":2,
#         "ytick.major.width":2,
#     })    
#     RES_LIST = ("1min",  "60min")          
#     ROWS, COLS = len(RES_LIST), len(HEIGHTS)
#     FIGSIZE = (30, 12)
#     fig, axes = plt.subplots(ROWS, COLS, figsize=FIGSIZE,
#                              sharex=False, sharey=False)
#     fig.subplots_adjust(wspace=0.6,hspace=0.8)  # å¢å¤§/å‡å°å­å›¾è¡Œé—´è·

#     # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#     # å¸ƒå±€å‚æ•°
#     box_w   = 0.3                         # å•ç®±å®½åº¦
#     jit_s   = 10                           # jitter ç›´å¾„
#     off     = np.array([-0.6, 0.0, 0.6]) # ä½ä¸­é«˜ RH çš„ y åç§»
#     row_spacing = 1.9                      # æºä¹‹é—´çš„è¡Œè·
    
#     # ä¸ºåŒä¸€åˆ†è¾¨ç‡-é«˜åº¦å­é›†éå†
#     for r, res_key in enumerate(RES_LIST):
#         srcs_this_row = RES_SRC_RH[res_key]
#         y_base = np.arange(len(srcs_this_row)) * row_spacing
#         for c, h in enumerate(HEIGHTS):
#             ax = axes[r, c]
#             ax.axvline(0, color='black', lw=2, linestyle=(0,(5,10)))

#             sub = df.query("resolution == @res_key and height == @h")
#             if sub.empty:
#                 ax.text(0.5, 0.5, "No data", ha="center", va="center",
#                         alpha=0.6)
#                 ax.set_xticks([]); ax.set_yticks([]); ax.set_frame_on(False)
#                 continue
                
#             # â€•â€• é€æº & RH æ¡£ç”»ç®±+æ•£ç‚¹ â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•
#             for i, src in enumerate(srcs_this_row):
#                 for j, rh_bin in enumerate(RH_ORDER):
#                     errs = sub.loc[(sub["source"] == src) &
#                                    (sub["rh_bin"] == rh_bin),
#                                    "error"].values
#                     if errs.size == 0:
#                         continue
                        
#                     # ç®±å›¾
#                     ax.boxplot(errs, vert=False,
#                                positions=[y_base[i] + off[j]],
#                                widths=box_w,
#                                patch_artist=True, manage_ticks=False,
#                                boxprops=dict(facecolor=RH_COLORS[rh_bin],
#                                              alpha=0.75, linewidth=2),
#                                flierprops=dict(marker="x", markersize=6,
#                                                markeredgecolor="black",
#                                                markerfacecolor="none",
#                                                linewidth=0.5),
#                                medianprops=dict(color="lime", linewidth=2),
#                                whiskerprops=dict(color="black", linewidth=1.8),
#                                capprops=dict(color="black", linewidth=1.8))
                               
#                     # jitter
#                     jitter_y = np.random.normal(y_base[i] + off[j], 0.06,
#                                                 size=len(errs))
#                     ax.scatter(errs, jitter_y, s=jit_s,
#                                color=RH_COLORS[rh_bin], alpha=0.8,
#                                linewidths=0)
                               
#             # â€•â€• è½´åˆ»åº¦ & æ ‡ç­¾ â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•
#             ax.set_yticks(y_base)
#             disp_names = [DISPLAY_NAMES.get(s, s) for s in srcs_this_row]
#             ax.set_yticklabels(disp_names)
#             ax.set_ylim(y_base[0] - 1, y_base[-1] + 1)
#             ax.grid(axis="x", linestyle=(0, (5, 8)), alpha=0.6)
#             ax.spines["top"].set_visible(False)
#             ax.spines["right"].set_visible(False)
#             ax.spines["left"].set_linewidth(2)
#             ax.spines["bottom"].set_linewidth(2)
            
#             # X-lim & tick é—´è·æ ¹æ®ç»éªŒç»™å®šï¼Œå¯è‡ªè¡Œè°ƒæ•´
#             ax.set_xlim(-35, 50)
#             ax.xaxis.set_major_locator(mticker.MultipleLocator(20))
#             ax.xaxis.set_minor_locator(mticker.MultipleLocator(10))
            
#             if r == ROWS - 1:
#                 ax.set_xlabel("Bias (%)")          # ä»…åº•æ’æ ‡æ³¨ x-label
#             if r == 0:
#                 ax.set_title(f"{h} m", pad=10, fontsize=26)
                
#     # # è¡Œæ ‡ç­¾ï¼ˆåˆ†è¾¨ç‡ï¼‰
#     # for r, res_key in enumerate(RES_LIST):
#     #     axes[r, 0].annotate(res_key, xy=(-0.80, 0.5),
#     #                         xycoords="axes fraction", rotation=90,
#     #                         va="center", ha="center", fontsize=26)
                            
#     # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#     # å›¾ä¾‹ï¼šRH æ¡£
#     handles_rh = [mlines.Line2D([], [], color=RH_COLORS[b],
#                                 marker="s", linestyle="", markersize=15,
#                                 label=b) for b in RH_ORDER]
#     # å›¾ä¾‹ï¼šæ•°æ®æº
#     all_sources = set([src for src_list in RES_SRC_RH.values() for src in src_list])
#     handles_src = [mlines.Line2D([], [], color="black",
#                              marker="s", linestyle="", markersize=15,
#                              markerfacecolor=COLMAP[s],
#                              label=DISPLAY_NAMES.get(s, s))
#                for s in all_sources]
               
#     fig = plt.gcf()
#     fig.legend(handles_rh,
#                [h.get_label() for h in handles_rh + handles_src],
#                loc="upper center", ncol=7, frameon=False,
#                fontsize=26, bbox_to_anchor=(0.51, 0.98))
               
#     fig.text(0.52, -0.015,
#              "RH Bias = Ground-based remote sensing/Reanalysis âˆ’ AWS",
#              ha="center", fontsize=26)
             
#     # æ·»åŠ æ ‡é¢˜
#     if title_suffix:
#         fig.text(0.52, 0.98, f"RH Conditional Bias {title_suffix}",
#                 ha="center", fontsize=26, fontweight="bold")
                
#     fig.savefig(outfile, dpi=600, format="tif", transparent=True,
#                 bbox_inches="tight",
#                 pil_kwargs={"compression": "tiff_adobe_deflate"})
#     plt.close(fig)          # â† ç«‹å³å…³é—­ï¼Œé‡Šæ”¾å†…å­˜
#     print("Saved â†’", outfile)


######new
def make_rh_plot(df: pd.DataFrame, outfile: Path, title_suffix=""):
    plt.rcParams.update({
        "font.family":"sans-serif",
        "font.sans-serif":["Arial","DejaVu Sans"],
        "font.size":26,
        "xtick.major.width":2,
        "ytick.major.width":2,
    })    
    RES_LIST = ("1min",  "60min")          
    ROWS, COLS = len(RES_LIST), len(HEIGHTS)
    
    # è®¡ç®—æ¯è¡Œæ‰€éœ€çš„é«˜åº¦æ¯”ä¾‹ï¼ˆåŸºäºæ•°æ®æºæ•°é‡ï¼‰
    row_heights = [len(RES_SRC_RH[res]) for res in RES_LIST]
    total_height = sum(row_heights)
    height_ratios = [h/total_height for h in row_heights]
    
    # åˆ›å»ºå›¾å½¢å’ŒGridSpecå¸ƒå±€
    FIGSIZE = (30, 16)  # å¢åŠ å›¾å½¢é«˜åº¦
    fig = plt.figure(figsize=FIGSIZE)
    gs = gridspec.GridSpec(ROWS, COLS, height_ratios=height_ratios, 
                          hspace=0.15, wspace=0.25)
    
    # åˆ›å»ºå­å›¾æ•°ç»„
    axes = [[fig.add_subplot(gs[r, c]) for c in range(COLS)] for r in range(ROWS)]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å¸ƒå±€å‚æ•°
    box_w   = 0.35                         # å•ç®±å®½åº¦ï¼ˆå›ºå®šï¼‰
    jit_s   = 12                           # jitter ç›´å¾„
    off     = np.array([-0.6, 0.0, 0.6])   # ä½ä¸­é«˜ RH çš„ y åç§»ï¼ˆå›ºå®šï¼‰
    UNIT_HEIGHT = 1.8                      # æ¯ä¸ªæ•°æ®æºå ç”¨çš„å‚ç›´ç©ºé—´ï¼ˆå›ºå®šï¼‰
    
    # ä¸ºåŒä¸€åˆ†è¾¨ç‡-é«˜åº¦å­é›†éå†
    for r, res_key in enumerate(RES_LIST):
        srcs_this_row = RES_SRC_RH[res_key]
        # è®¡ç®—è¯¥åˆ†è¾¨ç‡éœ€è¦çš„æ€»é«˜åº¦
        total_height = UNIT_HEIGHT * len(srcs_this_row)
        # è®¡ç®—y_baseä½ç½®
        y_base = np.arange(len(srcs_this_row)) * UNIT_HEIGHT
        for c, h in enumerate(HEIGHTS):
            ax = axes[r][c]
            ax.axvline(0, color='black', lw=2, linestyle=(0,(5,10)))

            sub = df.query("resolution == @res_key and height == @h")
            if sub.empty:
                ax.text(0.5, 0.5, "No data", ha="center", va="center",
                        alpha=0.6)
                ax.set_xticks([]); ax.set_yticks([]); ax.set_frame_on(False)
                continue
                
            # â€•â€• é€æº & RH æ¡£ç”»ç®±+æ•£ç‚¹ â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•
            for i, src in enumerate(srcs_this_row):
                for j, rh_bin in enumerate(RH_ORDER):
                    errs = sub.loc[(sub["source"] == src) &
                                   (sub["rh_bin"] == rh_bin),
                                   "error"].values
                    if errs.size == 0:
                        continue
                        
                    # ç®±å›¾
                    ax.boxplot(errs, vert=False,
                               positions=[y_base[i] + off[j]],
                               widths=box_w,
                               patch_artist=True, manage_ticks=False,
                               boxprops=dict(facecolor=RH_COLORS[rh_bin],
                                             alpha=0.75, linewidth=2),
                               flierprops=dict(marker="x", markersize=6,
                                               markeredgecolor="black",
                                               markerfacecolor="none",
                                               linewidth=0.5),
                               medianprops=dict(color="lime", linewidth=2),
                               whiskerprops=dict(color="black", linewidth=1.8),
                               capprops=dict(color="black", linewidth=1.8))
                               
                    # jitter
                    jitter_y = np.random.normal(y_base[i] + off[j], 0.06,
                                                size=len(errs))
                    ax.scatter(errs, jitter_y, s=jit_s,
                               color=RH_COLORS[rh_bin], alpha=0.8,
                               linewidths=0)
                               
            # â€•â€• è½´åˆ»åº¦ & æ ‡ç­¾ â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•
            ax.set_yticks(y_base)
            disp_names = [DISPLAY_NAMES.get(s, s) for s in srcs_this_row]
            ax.set_yticklabels(disp_names)
            # è®¾ç½®ylimï¼Œä¸Šä¸‹å„ç•™0.5çš„è¾¹è·
            ax.set_ylim(-1, total_height - 1)
            ax.grid(axis="x", linestyle=(0, (5, 8)), alpha=0.6)
            ax.spines["top"].set_visible(False)
            ax.spines["right"].set_visible(False)
            ax.spines["left"].set_linewidth(2)
            ax.spines["bottom"].set_linewidth(2)
            
            # X-lim & tick é—´è·æ ¹æ®ç»éªŒç»™å®šï¼Œå¯è‡ªè¡Œè°ƒæ•´
            ax.set_xlim(-35, 50)
            ax.xaxis.set_major_locator(mticker.MultipleLocator(20))
            ax.xaxis.set_minor_locator(mticker.MultipleLocator(10))
            
            if r == ROWS - 1:
                ax.set_xlabel("Bias (%)")          # ä»…åº•æ’æ ‡æ³¨ x-label
            if r == 0:
                ax.set_title(f"{h} m", pad=10, fontsize=26)
                
    # # è¡Œæ ‡ç­¾ï¼ˆåˆ†è¾¨ç‡ï¼‰
    # for r, res_key in enumerate(RES_LIST):
    #     axes[r][0].annotate(res_key, xy=(-0.40, 0.5),
    #                         xycoords="axes fraction", rotation=90,
    #                         va="center", ha="center", fontsize=26)
                            
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å›¾ä¾‹ï¼šRH æ¡£
    handles_rh = [mlines.Line2D([], [], color=RH_COLORS[b],
                                marker="s", linestyle="", markersize=15,
                                label=b) for b in RH_ORDER]
    # å›¾ä¾‹ï¼šæ•°æ®æº
    all_sources = set([src for src_list in RES_SRC_RH.values() for src in src_list])
    handles_src = [mlines.Line2D([], [], color="black",
                             marker="s", linestyle="", markersize=15,
                             markerfacecolor=COLMAP[s],
                             label=DISPLAY_NAMES.get(s, s))
               for s in all_sources]
               
    fig = plt.gcf()
    fig.legend(handles_rh,
               [h.get_label() for h in handles_rh + handles_src],
               loc="upper center", ncol=7, frameon=False,
               fontsize=26, bbox_to_anchor=(0.51, 0.98))
               
    fig.text(0.52, -0.015,
             "RH Bias = Ground-based remote sensing/Reanalysis âˆ’ AWS",
             ha="center", fontsize=26)
             
    # æ·»åŠ æ ‡é¢˜
    if title_suffix:
        fig.text(0.52, 0.98, f"RH Conditional Bias {title_suffix}",
                ha="center", fontsize=26, fontweight="bold")
                
    fig.savefig(outfile, dpi=600, format="tif", transparent=True,
                bbox_inches="tight",
                pil_kwargs={"compression": "tiff_adobe_deflate"})
    plt.close(fig)          # â† ç«‹å³å…³é—­ï¼Œé‡Šæ”¾å†…å­˜
    print("Saved â†’", outfile)




# =============================================================================
# 6. ç»˜å›¾å‡½æ•°ï¼ˆTempï¼‰
# =============================================================================
# def make_temp_plot(df: pd.DataFrame, outfile: Path, title_suffix=""):
#     """
#     æ¨ªå‘ 4 é«˜åº¦ Ã— çºµå‘ 2 åˆ†è¾¨ç‡ çš„å­å›¾ç½‘æ ¼ã€‚
#     æ¯ä¸ªå­å›¾é‡Œï¼š
#         * y è½´ = æ•°æ®æºï¼ˆTowerTurb/MWR/ERA5/CRAï¼‰
#         * åŒä¸€æºç”» 3 ä¸ªå¹¶æ’ç®±å›¾ï¼Œå¯¹åº”ä½/ä¸­/é«˜ Temp æ¡£
#     """
#     RES_LIST = ("1min",  "60min")          
#     ROWS, COLS = len(RES_LIST), len(HEIGHTS)
#     FIGSIZE = (30, 12)
#     fig, axes = plt.subplots(ROWS, COLS, figsize=FIGSIZE,
#                              sharex=False, sharey=False)
#     fig.subplots_adjust(wspace=0.6,hspace=0.8)  # å¢å¤§/å‡å°å­å›¾è¡Œé—´è·
#     plt.rcParams.update({
#         "font.family":"sans-serif",
#         "font.sans-serif":["Arial","DejaVu Sans"],
#         "font.size":26,
#         "xtick.major.width":2,
#         "ytick.major.width":2,
#     })
#     # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#     # å¸ƒå±€å‚æ•°
#     box_w   = 0.3                         # å•ç®±å®½åº¦
#     jit_s   = 10                           # jitter ç›´å¾„
#     off     = np.array([-0.6, 0.0, 0.6]) # ä½ä¸­é«˜ Temp çš„ y åç§»
#     row_spacing = 1.9                      # æºä¹‹é—´çš„è¡Œè·
    
#     # ä¸ºåŒä¸€åˆ†è¾¨ç‡-é«˜åº¦å­é›†éå†
#     for r, res_key in enumerate(RES_LIST):
#         srcs_this_row = RES_SRC_TEMP[res_key]
#         y_base = np.arange(len(srcs_this_row)) * row_spacing
#         for c, h in enumerate(HEIGHTS):
#             ax = axes[r, c]
#             ax.axvline(0, color='black', lw=2, linestyle=(0,(5,10)))

#             sub = df.query("resolution == @res_key and height == @h")
#             if sub.empty:
#                 ax.text(0.5, 0.5, "No data", ha="center", va="center",
#                         alpha=0.6)
#                 ax.set_xticks([]); ax.set_yticks([]); ax.set_frame_on(False)
#                 continue
                
#             # â€•â€• é€æº & Temp æ¡£ç”»ç®±+æ•£ç‚¹ â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•
#             for i, src in enumerate(srcs_this_row):
#                 for j, t_bin in enumerate(TEMP_ORDER):
#                     errs = sub.loc[(sub["source"] == src) &
#                                    (sub["temp_bin"] == t_bin),
#                                    "error"].values
#                     if errs.size == 0:
#                         continue
                        
#                     # ç®±å›¾
#                     ax.boxplot(errs, vert=False,
#                                positions=[y_base[i] + off[j]],
#                                widths=box_w,
#                                patch_artist=True, manage_ticks=False,
#                                boxprops=dict(facecolor=TEMP_COLORS[t_bin],
#                                              alpha=0.75, linewidth=2),
#                                flierprops=dict(marker="x", markersize=6,
#                                                markeredgecolor="black",
#                                                markerfacecolor="none",
#                                                linewidth=0.5),
#                                medianprops=dict(color="lime", linewidth=2),
#                                whiskerprops=dict(color="black", linewidth=1.8),
#                                capprops=dict(color="black", linewidth=1.8))
                               
#                     # jitter
#                     jitter_y = np.random.normal(y_base[i] + off[j], 0.06,
#                                                 size=len(errs))
#                     ax.scatter(errs, jitter_y, s=jit_s,
#                                color=TEMP_COLORS[t_bin], alpha=0.8,
#                                linewidths=0)
                               
#             # â€•â€• è½´åˆ»åº¦ & æ ‡ç­¾ â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•
#             ax.set_yticks(y_base)
#             disp_names = [DISPLAY_NAMES.get(s, s) for s in srcs_this_row]
#             ax.set_yticklabels(disp_names)
#             ax.set_ylim(y_base[0] - 1, y_base[-1] + 1)
#             ax.grid(axis="x", linestyle=(0, (5, 8)), alpha=0.6)
#             ax.spines["top"].set_visible(False)
#             ax.spines["right"].set_visible(False)
#             ax.spines["left"].set_linewidth(2)
#             ax.spines["bottom"].set_linewidth(2)
            
#             # X-lim & tick é—´è·æ ¹æ®ç»éªŒç»™å®šï¼Œå¯è‡ªè¡Œè°ƒæ•´
#             ax.set_xlim(-8, 8)
#             ax.xaxis.set_major_locator(mticker.MultipleLocator(2))
#             ax.xaxis.set_minor_locator(mticker.MultipleLocator(1))
            
#             if r == ROWS - 1:
#                 ax.set_xlabel("Bias (K)")          # ä»…åº•æ’æ ‡æ³¨ x-label
#             if r == 0:
#                 ax.set_title(f"{h} m", pad=10, fontsize=26)
                
#     # # è¡Œæ ‡ç­¾ï¼ˆåˆ†è¾¨ç‡ï¼‰
#     # for r, res_key in enumerate(RES_LIST):
#     #     axes[r, 0].annotate(res_key, xy=(-2.40, 0.5),
#     #                         xycoords="axes fraction", rotation=90,
#     #                         va="center", ha="center", fontsize=26)
                            
#     # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#     # å›¾ä¾‹ï¼šTemp æ¡£
#     handles_temp = [mlines.Line2D([], [], color=TEMP_COLORS[b],
#                                 marker="s", linestyle="", markersize=15,
#                                 label=b) for b in TEMP_ORDER]
#     # å›¾ä¾‹ï¼šæ•°æ®æº
#     all_sources = set([src for src_list in RES_SRC_TEMP.values() for src in src_list])
#     handles_src = [mlines.Line2D([], [], color="black",
#                              marker="s", linestyle="", markersize=15,
#                              markerfacecolor=COLMAP[s],
#                              label=DISPLAY_NAMES.get(s, s))
#                for s in all_sources]
               
#     fig = plt.gcf()
#     fig.legend(handles_temp,
#                [h.get_label() for h in handles_temp + handles_src],
#                loc="upper center", ncol=7, frameon=False,
#                fontsize=26, bbox_to_anchor=(0.51, 0.98))
               
#     fig.text(0.52, -0.015,
#              "Temp Bias = Ground-based remote sensing/Reanalysis âˆ’ AWS",
#              ha="center", fontsize=26)
             
#     # æ·»åŠ æ ‡é¢˜
#     if title_suffix:
#         fig.text(0.52, 0.98, f"Temp Conditional Bias {title_suffix}",
#                 ha="center", fontsize=26, fontweight="bold")
                
#     fig.savefig(outfile, dpi=600, format="tif", transparent=True,
#                 bbox_inches="tight",
#                 pil_kwargs={"compression": "tiff_adobe_deflate"})
#     plt.close(fig)          # â† ç«‹å³å…³é—­ï¼Œé‡Šæ”¾å†…å­˜
#     print("Saved â†’", outfile)
####new
def make_temp_plot(df: pd.DataFrame, outfile: Path, title_suffix=""):
    plt.rcParams.update({
        "font.family":"sans-serif",
        "font.sans-serif":["Arial","DejaVu Sans"],
        "font.size":26,
        "xtick.major.width":2,
        "ytick.major.width":2,
    })
    RES_LIST = ("1min",  "60min")          
    ROWS, COLS = len(RES_LIST), len(HEIGHTS)
    
    # è®¡ç®—æ¯è¡Œæ‰€éœ€çš„é«˜åº¦æ¯”ä¾‹ï¼ˆåŸºäºæ•°æ®æºæ•°é‡ï¼‰
    row_heights = [len(RES_SRC_TEMP[res]) for res in RES_LIST]
    total_height = sum(row_heights)
    height_ratios = [h/total_height for h in row_heights]
    
    # åˆ›å»ºå›¾å½¢å’ŒGridSpecå¸ƒå±€
    FIGSIZE = (30, 16)  # å¢åŠ å›¾å½¢é«˜åº¦
    fig = plt.figure(figsize=FIGSIZE)
    gs = gridspec.GridSpec(ROWS, COLS, height_ratios=height_ratios, 
                          hspace=0.15, wspace=0.25)
    
    # åˆ›å»ºå­å›¾æ•°ç»„
    axes = [[fig.add_subplot(gs[r, c]) for c in range(COLS)] for r in range(ROWS)]
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å¸ƒå±€å‚æ•°
    box_w   = 0.35                         # å•ç®±å®½åº¦ï¼ˆå›ºå®šï¼‰
    jit_s   = 12                           # jitter ç›´å¾„
    off     = np.array([-0.6, 0.0, 0.6])   # ä½ä¸­é«˜ Temp çš„ y åç§»ï¼ˆå›ºå®šï¼‰
    UNIT_HEIGHT = 1.8                      # æ¯ä¸ªæ•°æ®æºå ç”¨çš„å‚ç›´ç©ºé—´ï¼ˆå›ºå®šï¼‰
    
    # ä¸ºåŒä¸€åˆ†è¾¨ç‡-é«˜åº¦å­é›†éå†
    for r, res_key in enumerate(RES_LIST):
        srcs_this_row = RES_SRC_TEMP[res_key]
        # è®¡ç®—è¯¥åˆ†è¾¨ç‡éœ€è¦çš„æ€»é«˜åº¦
        total_height = UNIT_HEIGHT * len(srcs_this_row)
        # è®¡ç®—y_baseä½ç½®
        y_base = np.arange(len(srcs_this_row)) * UNIT_HEIGHT
        for c, h in enumerate(HEIGHTS):
            ax = axes[r][c]
            ax.axvline(0, color='black', lw=2, linestyle=(0,(5,10)))

            sub = df.query("resolution == @res_key and height == @h")
            if sub.empty:
                ax.text(0.5, 0.5, "No data", ha="center", va="center",
                        alpha=0.6)
                ax.set_xticks([]); ax.set_yticks([]); ax.set_frame_on(False)
                continue
                
            # â€•â€• é€æº & Temp æ¡£ç”»ç®±+æ•£ç‚¹ â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•
            for i, src in enumerate(srcs_this_row):
                for j, t_bin in enumerate(TEMP_ORDER):
                    errs = sub.loc[(sub["source"] == src) &
                                   (sub["temp_bin"] == t_bin),
                                   "error"].values
                    if errs.size == 0:
                        continue
                        
                    # ç®±å›¾
                    ax.boxplot(errs, vert=False,
                               positions=[y_base[i] + off[j]],
                               widths=box_w,
                               patch_artist=True, manage_ticks=False,
                               boxprops=dict(facecolor=TEMP_COLORS[t_bin],
                                             alpha=0.75, linewidth=2),
                               flierprops=dict(marker="x", markersize=6,
                                               markeredgecolor="black",
                                               markerfacecolor="none",
                                               linewidth=0.5),
                               medianprops=dict(color="lime", linewidth=2),
                               whiskerprops=dict(color="black", linewidth=1.8),
                               capprops=dict(color="black", linewidth=1.8))
                               
                    # jitter
                    jitter_y = np.random.normal(y_base[i] + off[j], 0.06,
                                                size=len(errs))
                    ax.scatter(errs, jitter_y, s=jit_s,
                               color=TEMP_COLORS[t_bin], alpha=0.8,
                               linewidths=0)
                               
            # â€•â€• è½´åˆ»åº¦ & æ ‡ç­¾ â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•
            ax.set_yticks(y_base)
            disp_names = [DISPLAY_NAMES.get(s, s) for s in srcs_this_row]
            ax.set_yticklabels(disp_names)
            # è®¾ç½®ylimï¼Œä¸Šä¸‹å„ç•™0.5çš„è¾¹è·
            ax.set_ylim(-1, total_height - 1)
            ax.grid(axis="x", linestyle=(0, (5, 8)), alpha=0.6)
            ax.spines["top"].set_visible(False)
            ax.spines["right"].set_visible(False)
            ax.spines["left"].set_linewidth(2)
            ax.spines["bottom"].set_linewidth(2)
            
            # X-lim & tick é—´è·æ ¹æ®ç»éªŒç»™å®šï¼Œå¯è‡ªè¡Œè°ƒæ•´
            ax.set_xlim(-8, 8)
            ax.xaxis.set_major_locator(mticker.MultipleLocator(2))
            ax.xaxis.set_minor_locator(mticker.MultipleLocator(1))
            
            if r == ROWS - 1:
                ax.set_xlabel("Bias (K)")          # ä»…åº•æ’æ ‡æ³¨ x-label
            if r == 0:
                ax.set_title(f"{h} m", pad=10, fontsize=26)
                
    # # è¡Œæ ‡ç­¾ï¼ˆåˆ†è¾¨ç‡ï¼‰
    # for r, res_key in enumerate(RES_LIST):
    #     axes[r][0].annotate(res_key, xy=(-0.40, 0.5),
    #                         xycoords="axes fraction", rotation=90,
    #                         va="center", ha="center", fontsize=26)
                            
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å›¾ä¾‹ï¼šTemp æ¡£
    handles_temp = [mlines.Line2D([], [], color=TEMP_COLORS[b],
                                marker="s", linestyle="", markersize=15,
                                label=b) for b in TEMP_ORDER]
    # å›¾ä¾‹ï¼šæ•°æ®æº
    all_sources = set([src for src_list in RES_SRC_TEMP.values() for src in src_list])
    handles_src = [mlines.Line2D([], [], color="black",
                             marker="s", linestyle="", markersize=15,
                             markerfacecolor=COLMAP[s],
                             label=DISPLAY_NAMES.get(s, s))
               for s in all_sources]
               
    fig = plt.gcf()
    fig.legend(handles_temp,
               [h.get_label() for h in handles_temp + handles_src],
               loc="upper center", ncol=7, frameon=False,
               fontsize=26, bbox_to_anchor=(0.51, 0.98))
               
    fig.text(0.52, 0.015,
             "Temp Bias = Ground-based remote sensing/Reanalysis âˆ’ AWS",
             ha="center", fontsize=26)
             
    # æ·»åŠ æ ‡é¢˜
    if title_suffix:
        fig.text(0.52, 0.98, f"Temp Conditional Bias {title_suffix}",
                ha="center", fontsize=26, fontweight="bold")
                
    fig.savefig(outfile, dpi=600, format="tif", transparent=True,
                bbox_inches="tight",
                pil_kwargs={"compression": "tiff_adobe_deflate"})
    plt.close(fig)          # â† ç«‹å³å…³é—­ï¼Œé‡Šæ”¾å†…å­˜
    print("Saved â†’", outfile)



# =============================================================================
# 7. ç»˜å›¾å‡½æ•°ï¼ˆHWSï¼‰
# =============================================================================
# def make_hws_plot(df: pd.DataFrame, outfile: Path, title_suffix=""):
#     """
#     æ¨ªå‘ 4 é«˜åº¦ Ã— çºµå‘ 2 åˆ†è¾¨ç‡ çš„å­å›¾ç½‘æ ¼ã€‚
#     æ¯ä¸ªå­å›¾é‡Œï¼š
#         * y è½´ = æ•°æ®æºï¼ˆLiDAR/TowerTurb/ERA5/CRAï¼‰
#         * åŒä¸€æºç”» 3 ä¸ªå¹¶æ’ç®±å›¾ï¼Œå¯¹åº”ä½/ä¸­/é«˜ HWS æ¡£
#     """
#     RES_LIST = ("1min",  "60min")          
#     ROWS, COLS = len(RES_LIST), len(HEIGHTS)
#     FIGSIZE = (30, 12)
#     fig, axes = plt.subplots(ROWS, COLS, figsize=FIGSIZE,
#                              sharex=False, sharey=False)
#     fig.subplots_adjust(wspace=0.6,hspace=0.8)  # å¢å¤§/å‡å°å­å›¾è¡Œé—´è·
#     plt.rcParams.update({
#         "font.family":"sans-serif",
#         "font.sans-serif":["Arial","DejaVu Sans"],
#         "font.size":26,
#         "xtick.major.width":2,
#         "ytick.major.width":2,
#     })
#     # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#     # å¸ƒå±€å‚æ•°
#     box_w   = 0.3                         # å•ç®±å®½åº¦
#     jit_s   = 10                           # jitter ç›´å¾„
#     off     = np.array([-0.6, 0.0, 0.6]) # ä½ä¸­é«˜ HWS çš„ y åç§»
#     row_spacing = 1.9                      # æºä¹‹é—´çš„è¡Œè·
    
#     # ä¸ºåŒä¸€åˆ†è¾¨ç‡-é«˜åº¦å­é›†éå†
#     for r, res_key in enumerate(RES_LIST):
#         srcs_this_row = RES_SRC_HWS[res_key]
#         y_base = np.arange(len(srcs_this_row)) * row_spacing
#         for c, h in enumerate(HEIGHTS):
#             ax = axes[r, c]
#             ax.axvline(0, color='black', lw=2, linestyle=(0,(5,10)))

#             sub = df.query("resolution == @res_key and height == @h")
#             if sub.empty:
#                 ax.text(0.5, 0.5, "No data", ha="center", va="center",
#                         alpha=0.6)
#                 ax.set_xticks([]); ax.set_yticks([]); ax.set_frame_on(False)
#                 continue
                
#             # â€•â€• é€æº & HWS æ¡£ç”»ç®±+æ•£ç‚¹ â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•
#             for i, src in enumerate(srcs_this_row):
#                 for j, hws_bin in enumerate(HWS_ORDER):
#                     errs = sub.loc[(sub["source"] == src) &
#                                    (sub["hws_bin"] == hws_bin),
#                                    "error"].values
#                     if errs.size == 0:
#                         continue
                        
#                     # ç®±å›¾
#                     ax.boxplot(errs, vert=False,
#                                positions=[y_base[i] + off[j]],
#                                widths=box_w,
#                                patch_artist=True, manage_ticks=False,
#                                boxprops=dict(facecolor=HWS_COLORS[hws_bin],
#                                              alpha=0.75, linewidth=2),
#                                flierprops=dict(marker="x", markersize=6,
#                                                markeredgecolor="black",
#                                                markerfacecolor="none",
#                                                linewidth=0.5),
#                                medianprops=dict(color="lime", linewidth=2),
#                                whiskerprops=dict(color="black", linewidth=1.8),
#                                capprops=dict(color="black", linewidth=1.8))
                               
#                     # jitter
#                     jitter_y = np.random.normal(y_base[i] + off[j], 0.06,
#                                                 size=len(errs))
#                     ax.scatter(errs, jitter_y, s=jit_s,
#                                color=HWS_COLORS[hws_bin], alpha=0.8,
#                                linewidths=0)
                               
#             # â€•â€• è½´åˆ»åº¦ & æ ‡ç­¾ â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•
#             ax.set_yticks(y_base)
#             disp_names = [DISPLAY_NAMES.get(s, s) for s in srcs_this_row]
#             ax.set_yticklabels(disp_names)
#             ax.set_ylim(y_base[0] - 1, y_base[-1] + 1)
#             ax.grid(axis="x", linestyle=(0, (5, 8)), alpha=0.6)
#             ax.spines["top"].set_visible(False)
#             ax.spines["right"].set_visible(False)
#             ax.spines["left"].set_linewidth(2)
#             ax.spines["bottom"].set_linewidth(2)
            
#             # X-lim & tick é—´è·æ ¹æ®ç»éªŒç»™å®šï¼Œå¯è‡ªè¡Œè°ƒæ•´
#             ax.set_xlim(-8, 8)
#             ax.xaxis.set_major_locator(mticker.MultipleLocator(2))
#             ax.xaxis.set_minor_locator(mticker.MultipleLocator(1))
            
#             if r == ROWS - 1:
#                 ax.set_xlabel("Bias (m/s)")          # ä»…åº•æ’æ ‡æ³¨ x-label
#             if r == 0:
#                 ax.set_title(f"{h} m", pad=10, fontsize=26)
                
#     # è¡Œæ ‡ç­¾ï¼ˆåˆ†è¾¨ç‡ï¼‰
#     # for r, res_key in enumerate(RES_LIST):
#     #     axes[r, 0].annotate(res_key, xy=(-0.40, 0.5),
#     #                         xycoords="axes fraction", rotation=90,
#     #                         va="center", ha="center", fontsize=26)
                            
#     # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#     # å›¾ä¾‹ï¼šHWS æ¡£
#     handles_hws = [mlines.Line2D([], [], color=HWS_COLORS[b],
#                                 marker="s", linestyle="", markersize=15,
#                                 label=b) for b in HWS_ORDER]
#     # å›¾ä¾‹ï¼šæ•°æ®æº
#     all_sources = set([src for src_list in RES_SRC_HWS.values() for src in src_list])
#     handles_src = [mlines.Line2D([], [], color="black",
#                              marker="s", linestyle="", markersize=15,
#                              markerfacecolor=COLMAP[s],
#                              label=DISPLAY_NAMES.get(s, s))
#                for s in all_sources]
               
#     fig = plt.gcf()
#     fig.legend(handles_hws,
#                [h.get_label() for h in handles_hws + handles_src],
#                loc="upper center", ncol=7, frameon=False,
#                fontsize=26, bbox_to_anchor=(0.51, 0.98))
               
#     fig.text(0.52, -0.015,
#              "HWS Bias = Ground-based remote sensing/Reanalysis âˆ’ AWS",
#              ha="center", fontsize=26)
             
#     # æ·»åŠ æ ‡é¢˜
#     if title_suffix:
#         fig.text(0.52, 0.98, f"HWS Conditional Bias {title_suffix}",
#                 ha="center", fontsize=26, fontweight="bold")
                
#     fig.savefig(outfile, dpi=600, format="tif", transparent=True,
#                 bbox_inches="tight",
#                 pil_kwargs={"compression": "tiff_adobe_deflate"})
#     plt.close(fig)          # â† ç«‹å³å…³é—­ï¼Œé‡Šæ”¾å†…å­˜
#     print("Saved â†’", outfile)
######new
def make_hws_plot(df: pd.DataFrame, outfile: Path, title_suffix=""):
    plt.rcParams.update({
        "font.family":"sans-serif",
        "font.sans-serif":["Arial","DejaVu Sans"],
        "font.size":26,
        "xtick.major.width":2,
        "ytick.major.width":2,
    })
    RES_LIST = ("1min",  "60min")          
    ROWS, COLS = len(RES_LIST), len(HEIGHTS)
    
    # è®¡ç®—æ¯è¡Œæ‰€éœ€çš„é«˜åº¦æ¯”ä¾‹ï¼ˆåŸºäºæ•°æ®æºæ•°é‡ï¼‰
    row_heights = [len(RES_SRC_HWS[res]) for res in RES_LIST]
    total_height = sum(row_heights)
    height_ratios = [h/total_height for h in row_heights]
    
    # åˆ›å»ºå›¾å½¢å’ŒGridSpecå¸ƒå±€
    FIGSIZE = (30, 16)  # å¢åŠ å›¾å½¢é«˜åº¦
    fig = plt.figure(figsize=FIGSIZE)
    gs = gridspec.GridSpec(ROWS, COLS, height_ratios=height_ratios, 
                          hspace=0.15, wspace=0.25)
    
    # åˆ›å»ºå­å›¾æ•°ç»„
    axes = [[fig.add_subplot(gs[r, c]) for c in range(COLS)] for r in range(ROWS)]
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å¸ƒå±€å‚æ•°
    box_w   = 0.35                         # å•ç®±å®½åº¦ï¼ˆå›ºå®šï¼‰
    jit_s   = 12                           # jitter ç›´å¾„
    off     = np.array([-0.6, 0.0, 0.6])   # ä½ä¸­é«˜ HWS çš„ y åç§»ï¼ˆå›ºå®šï¼‰
    UNIT_HEIGHT = 1.8                      # æ¯ä¸ªæ•°æ®æºå ç”¨çš„å‚ç›´ç©ºé—´ï¼ˆå›ºå®šï¼‰
    
    # ä¸ºåŒä¸€åˆ†è¾¨ç‡-é«˜åº¦å­é›†éå†
    for r, res_key in enumerate(RES_LIST):
        srcs_this_row = RES_SRC_HWS[res_key]
        # è®¡ç®—è¯¥åˆ†è¾¨ç‡éœ€è¦çš„æ€»é«˜åº¦
        total_height = UNIT_HEIGHT * len(srcs_this_row)
        # è®¡ç®—y_baseä½ç½®
        y_base = np.arange(len(srcs_this_row)) * UNIT_HEIGHT
        for c, h in enumerate(HEIGHTS):
            ax = axes[r][c]
            ax.axvline(0, color='black', lw=2, linestyle=(0,(5,10)))

            sub = df.query("resolution == @res_key and height == @h")
            if sub.empty:
                ax.text(0.5, 0.5, "No data", ha="center", va="center",
                        alpha=0.6)
                ax.set_xticks([]); ax.set_yticks([]); ax.set_frame_on(False)
                continue
                
            # â€•â€• é€æº & HWS æ¡£ç”»ç®±+æ•£ç‚¹ â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•
            for i, src in enumerate(srcs_this_row):
                for j, hws_bin in enumerate(HWS_ORDER):
                    errs = sub.loc[(sub["source"] == src) &
                                   (sub["hws_bin"] == hws_bin),
                                   "error"].values
                    if errs.size == 0:
                        continue
                        
                    # ç®±å›¾
                    ax.boxplot(errs, vert=False,
                               positions=[y_base[i] + off[j]],
                               widths=box_w,
                               patch_artist=True, manage_ticks=False,
                               boxprops=dict(facecolor=HWS_COLORS[hws_bin],
                                             alpha=0.75, linewidth=2),
                               flierprops=dict(marker="x", markersize=6,
                                               markeredgecolor="black",
                                               markerfacecolor="none",
                                               linewidth=0.5),
                               medianprops=dict(color="lime", linewidth=2),
                               whiskerprops=dict(color="black", linewidth=1.8),
                               capprops=dict(color="black", linewidth=1.8))
                               
                    # jitter
                    jitter_y = np.random.normal(y_base[i] + off[j], 0.06,
                                                size=len(errs))
                    ax.scatter(errs, jitter_y, s=jit_s,
                               color=HWS_COLORS[hws_bin], alpha=0.8,
                               linewidths=0)
                               
            # â€•â€• è½´åˆ»åº¦ & æ ‡ç­¾ â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•
            ax.set_yticks(y_base)
            disp_names = [DISPLAY_NAMES.get(s, s) for s in srcs_this_row]
            ax.set_yticklabels(disp_names)
            # è®¾ç½®ylimï¼Œä¸Šä¸‹å„ç•™0.5çš„è¾¹è·
            ax.set_ylim(-1, total_height - 1)
            ax.grid(axis="x", linestyle=(0, (5, 8)), alpha=0.6)
            ax.spines["top"].set_visible(False)
            ax.spines["right"].set_visible(False)
            ax.spines["left"].set_linewidth(2)
            ax.spines["bottom"].set_linewidth(2)
            
            # X-lim & tick é—´è·æ ¹æ®ç»éªŒç»™å®šï¼Œå¯è‡ªè¡Œè°ƒæ•´
            ax.set_xlim(-8, 8)
            ax.xaxis.set_major_locator(mticker.MultipleLocator(2))
            ax.xaxis.set_minor_locator(mticker.MultipleLocator(1))
            
            if r == ROWS - 1:
                ax.set_xlabel("Bias (m/s)")          # ä»…åº•æ’æ ‡æ³¨ x-label
            if r == 0:
                ax.set_title(f"{h} m", pad=10, fontsize=26)
                
    # # è¡Œæ ‡ç­¾ï¼ˆåˆ†è¾¨ç‡ï¼‰
    # for r, res_key in enumerate(RES_LIST):
    #     axes[r][0].annotate(res_key, xy=(-0.40, 0.5),
    #                         xycoords="axes fraction", rotation=90,
    #                         va="center", ha="center", fontsize=26)
                            
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # å›¾ä¾‹ï¼šHWS æ¡£
    handles_hws = [mlines.Line2D([], [], color=HWS_COLORS[b],
                                marker="s", linestyle="", markersize=15,
                                label=b) for b in HWS_ORDER]
    # å›¾ä¾‹ï¼šæ•°æ®æº
    all_sources = set([src for src_list in RES_SRC_HWS.values() for src in src_list])
    handles_src = [mlines.Line2D([], [], color="black",
                             marker="s", linestyle="", markersize=15,
                             markerfacecolor=COLMAP[s],
                             label=DISPLAY_NAMES.get(s, s))
               for s in all_sources]
               
    fig = plt.gcf()
    fig.legend(handles_hws,
               [h.get_label() for h in handles_hws + handles_src],
               loc="upper center", ncol=7, frameon=False,
               fontsize=26, bbox_to_anchor=(0.51, 0.98))
               
    fig.text(0.52, -0.015,
             "HWS Bias = Ground-based remote sensing/Reanalysis âˆ’ AWS",
             ha="center", fontsize=26)
             
    # æ·»åŠ æ ‡é¢˜
    if title_suffix:
        fig.text(0.52, 0.98, f"HWS Conditional Bias {title_suffix}",
                ha="center", fontsize=26, fontweight="bold")
                
    fig.savefig(outfile, dpi=600, format="tif", transparent=True,
                bbox_inches="tight",
                pil_kwargs={"compression": "tiff_adobe_deflate"})
    plt.close(fig)          # â† ç«‹å³å…³é—­ï¼Œé‡Šæ”¾å†…å­˜
    print("Saved â†’", outfile)
# =============================================================================
# 8. ç»Ÿè®¡å‡½æ•°
# =============================================================================
def summarize_rh_errors(df: pd.DataFrame) -> pd.DataFrame:
    """
    æŒ‰ (resolution, height, rh_bin, source) åˆ†ç»„ç»Ÿè®¡ï¼š
    count / mean / median / q25 / q75 / IQR / whisker_low / whisker_high / min / max
    """
    grp = df.groupby(["resolution", "height", "rh_bin", "source"])["error"]
    summary = grp.agg(
        count  = "size",
        mean   = "mean",
        median = "median",
        q25    = lambda x: x.quantile(0.25),
        q75    = lambda x: x.quantile(0.75),
        min    = "min",
        max    = "max",
    )
    summary["iqr"] = summary.q75 - summary.q25
    summary["whisker_low"]  = (summary.q25 - 1.5 * summary.iqr).clip(lower=summary["min"])
    summary["whisker_high"] = (summary.q75 + 1.5 * summary.iqr).clip(upper=summary["max"])
    # æ›´æ˜“è¯»çš„åˆ—é¡ºåº
    return summary[[
        "count", "mean", "median", "q25", "q75",
        "iqr", "whisker_low", "whisker_high", "min", "max"
    ]]

def summarize_temp_errors(df: pd.DataFrame) -> pd.DataFrame:
    """
    æŒ‰ (resolution, height, temp_bin, source) åˆ†ç»„ç»Ÿè®¡ï¼š
    count / mean / median / q25 / q75 / IQR / whisker_low / whisker_high / min / max
    """
    grp = df.groupby(["resolution", "height", "temp_bin", "source"])["error"]
    summary = grp.agg(
        count  = "size",
        mean   = "mean",
        median = "median",
        q25    = lambda x: x.quantile(0.25),
        q75    = lambda x: x.quantile(0.75),
        min    = "min",
        max    = "max",
    )
    summary["iqr"] = summary.q75 - summary.q25
    summary["whisker_low"]  = (summary.q25 - 1.5 * summary.iqr).clip(lower=summary["min"])
    summary["whisker_high"] = (summary.q75 + 1.5 * summary.iqr).clip(upper=summary["max"])
    return summary[[
        "count", "mean", "median", "q25", "q75",
        "iqr", "whisker_low", "whisker_high", "min", "max"
    ]]

def summarize_hws_errors(df: pd.DataFrame) -> pd.DataFrame:
    """
    æŒ‰ (resolution, height, hws_bin, source) åˆ†ç»„ç»Ÿè®¡ï¼š
    count / mean / median / q25 / q75 / IQR / whisker_low / whisker_high / min / max
    """
    grp = df.groupby(["resolution", "height", "hws_bin", "source"])["error"]
    summary = grp.agg(
        count  = "size",
        mean   = "mean",
        median = "median",
        q25    = lambda x: x.quantile(0.25),
        q75    = lambda x: x.quantile(0.75),
        min    = "min",
        max    = "max",
    )
    summary["iqr"] = summary.q75 - summary.q25
    summary["whisker_low"]  = (summary.q25 - 1.5 * summary.iqr).clip(lower=summary["min"])
    summary["whisker_high"] = (summary.q75 + 1.5 * summary.iqr).clip(upper=summary["max"])
    return summary[[
        "count", "mean", "median", "q25", "q75",
        "iqr", "whisker_low", "whisker_high", "min", "max"
    ]]

# =============================================================================
# 9. ä¸»æ‰§è¡Œæµç¨‹
# =============================================================================
# åˆ›å»ºè¾“å‡ºç›®å½•
OUT_DIR = Path(r"E:\Beijing2024\å‡ºå›¾TIF")
OUT_DIR.mkdir(parents=True, exist_ok=True)

# æ—¶é—´çª—å£æ ¼å¼åŒ–å­—ç¬¦ä¸²
time_window_str = f"{EXCLUDE_WINDOWS[0][0].strftime('%Y-%m-%d %H:%M')} to {EXCLUDE_WINDOWS[-1][1].strftime('%Y-%m-%d %H:%M')}"

# ==================== RH åˆ†æ ====================
print("Building RH conditional error dataframes...")

# 1. åŒ…å«æ—¶é—´çª—å£çš„æ•°æ®
print("  - Inside time windows...")
df_rh_inside = build_rh_error_df(inside=True)
make_rh_plot(
    df_rh_inside,
    OUT_DIR / "RH_Conditional_Bias_BoxJitter_Inside.tif",
    title_suffix=f"(Inside {time_window_str})"
)
rh_stats_inside = summarize_rh_errors(df_rh_inside)
with pd.ExcelWriter(OUT_DIR / "RH_error_stats_inside.xlsx", engine="openpyxl") as writer:
    for (rh_bin, h), sub in rh_stats_inside.groupby(level=["rh_bin", "height"]):
        sheet_name = f"{rh_bin.split(' ')[0]}_{h}m"           
        sub.droplevel(["rh_bin", "height"]).to_excel(writer, sheet_name=sheet_name)
print(f"  - RH inside statistics saved to {OUT_DIR / 'RH_error_stats_inside.xlsx'}")

# 2. ä¸åŒ…å«æ—¶é—´çª—å£çš„æ•°æ®
print("  - Outside time windows...")
df_rh_outside = build_rh_error_df(inside=False)
make_rh_plot(
    df_rh_outside,
    OUT_DIR / "RH_Conditional_Bias_BoxJitter_Outside.tif",
    title_suffix="(Exclude Rainstorm)"
)
rh_stats_outside = summarize_rh_errors(df_rh_outside)
with pd.ExcelWriter(OUT_DIR / "RH_error_stats_outside.xlsx", engine="openpyxl") as writer:
    for (rh_bin, h), sub in rh_stats_outside.groupby(level=["rh_bin", "height"]):
        sheet_name = f"{rh_bin.split(' ')[0]}_{h}m"           
        sub.droplevel(["rh_bin", "height"]).to_excel(writer, sheet_name=sheet_name)
print(f"  - RH outside statistics saved to {OUT_DIR / 'RH_error_stats_outside.xlsx'}")

# 3. å…¨éƒ¨æ•°æ®
print("  - All data...")
df_rh_all = build_rh_error_df()  # ä¸ä¼ é€’insideå‚æ•°
make_rh_plot(
    df_rh_all,
    OUT_DIR / "RH_Conditional_Bias_BoxJitter_All.tif",
    title_suffix="(All Data)"
)
rh_stats_all = summarize_rh_errors(df_rh_all)
with pd.ExcelWriter(OUT_DIR / "RH_error_stats_all.xlsx", engine="openpyxl") as writer:
    for (rh_bin, h), sub in rh_stats_all.groupby(level=["rh_bin", "height"]):
        sheet_name = f"{rh_bin.split(' ')[0]}_{h}m"           
        sub.droplevel(["rh_bin", "height"]).to_excel(writer, sheet_name=sheet_name)
print(f"  - RH all statistics saved to {OUT_DIR / 'RH_error_stats_all.xlsx'}")

# ==================== Temp åˆ†æ ====================
print("\nBuilding Temp conditional error dataframes...")

# 1. åŒ…å«æ—¶é—´çª—å£çš„æ•°æ®
print("  - Inside time windows...")
df_temp_inside = build_temp_error_df(inside=True)
make_temp_plot(
    df_temp_inside,
    OUT_DIR / "Temp_Conditional_Bias_BoxJitter_Inside.tif",
    title_suffix=f"(Include {time_window_str})"
)
temp_stats_inside = summarize_temp_errors(df_temp_inside)
with pd.ExcelWriter(OUT_DIR / "Temp_error_stats_inside.xlsx", engine="openpyxl") as writer:
    for (t_bin, h), sub in temp_stats_inside.groupby(level=["temp_bin", "height"]):
        sheet_name = f"{t_bin.split(' ')[0]}_{h}m"    
        sub.droplevel(["temp_bin", "height"]).to_excel(writer, sheet_name=sheet_name)
print(f"  - Temp inside statistics saved to {OUT_DIR / 'Temp_error_stats_inside.xlsx'}")

# 2. ä¸åŒ…å«æ—¶é—´çª—å£çš„æ•°æ®
print("  - Outside time windows...")
df_temp_outside = build_temp_error_df(inside=False)
make_temp_plot(
    df_temp_outside,
    OUT_DIR / "Temp_Conditional_Bias_BoxJitter_Outside.tif",
    title_suffix="(Exlude Rainstorm)"
)
temp_stats_outside = summarize_temp_errors(df_temp_outside)
with pd.ExcelWriter(OUT_DIR / "Temp_error_stats_outside.xlsx", engine="openpyxl") as writer:
    for (t_bin, h), sub in temp_stats_outside.groupby(level=["temp_bin", "height"]):
        sheet_name = f"{t_bin.split(' ')[0]}_{h}m"    
        sub.droplevel(["temp_bin", "height"]).to_excel(writer, sheet_name=sheet_name)
print(f"  - Temp outside statistics saved to {OUT_DIR / 'Temp_error_stats_outside.xlsx'}")

# 3. å…¨éƒ¨æ•°æ®
print("  - All data...")
df_temp_all = build_temp_error_df()  # ä¸ä¼ é€’insideå‚æ•°
make_temp_plot(
    df_temp_all,
    OUT_DIR / "Temp_Conditional_Bias_BoxJitter_All.tif",
    title_suffix="(All Data)"
)
temp_stats_all = summarize_temp_errors(df_temp_all)
with pd.ExcelWriter(OUT_DIR / "Temp_error_stats_all.xlsx", engine="openpyxl") as writer:
    for (t_bin, h), sub in temp_stats_all.groupby(level=["temp_bin", "height"]):
        sheet_name = f"{t_bin.split(' ')[0]}_{h}m"    
        sub.droplevel(["temp_bin", "height"]).to_excel(writer, sheet_name=sheet_name)
print(f"  - Temp all statistics saved to {OUT_DIR / 'Temp_error_stats_all.xlsx'}")

# ==================== HWS åˆ†æ ====================
print("\nBuilding HWS conditional error dataframes...")

# 1. åŒ…å«æ—¶é—´çª—å£çš„æ•°æ®
print("  - Inside time windows...")
df_hws_inside = build_hws_error_df(inside=True)
make_hws_plot(
    df_hws_inside,
    OUT_DIR / "HWS_Conditional_Bias_BoxJitter_Inside.tif",
    title_suffix=f"(Include {time_window_str})"
)
hws_stats_inside = summarize_hws_errors(df_hws_inside)
with pd.ExcelWriter(OUT_DIR / "HWS_error_stats_inside.xlsx", engine="openpyxl") as writer:
    for (hws_bin, h), sub in hws_stats_inside.groupby(level=["hws_bin", "height"]):
        sheet_name = f"{hws_bin.split(' ')[0]}_{h}m"    
        sub.droplevel(["hws_bin", "height"]).to_excel(writer, sheet_name=sheet_name)
print(f"  - HWS inside statistics saved to {OUT_DIR / 'HWS_error_stats_inside.xlsx'}")

# 2. ä¸åŒ…å«æ—¶é—´çª—å£çš„æ•°æ®
print("  - Outside time windows...")
df_hws_outside = build_hws_error_df(inside=False)
make_hws_plot(
    df_hws_outside,
    OUT_DIR / "HWS_Conditional_Bias_BoxJitter_Outside.tif",
    title_suffix="(Exclude Rainstorm)"
)
hws_stats_outside = summarize_hws_errors(df_hws_outside)
with pd.ExcelWriter(OUT_DIR / "HWS_error_stats_outside.xlsx", engine="openpyxl") as writer:
    for (hws_bin, h), sub in hws_stats_outside.groupby(level=["hws_bin", "height"]):
        sheet_name = f"{hws_bin.split(' ')[0]}_{h}m"    
        sub.droplevel(["hws_bin", "height"]).to_excel(writer, sheet_name=sheet_name)
print(f"  - HWS outside statistics saved to {OUT_DIR / 'HWS_error_stats_outside.xlsx'}")

# 3. å…¨éƒ¨æ•°æ®
print("  - All data...")
df_hws_all = build_hws_error_df()  # ä¸ä¼ é€’insideå‚æ•°
make_hws_plot(
    df_hws_all,
    OUT_DIR / "HWS_Conditional_Bias_BoxJitter_All.tif",
    title_suffix="(All Data)"
)
hws_stats_all = summarize_hws_errors(df_hws_all)
with pd.ExcelWriter(OUT_DIR / "HWS_error_stats_all.xlsx", engine="openpyxl") as writer:
    for (hws_bin, h), sub in hws_stats_all.groupby(level=["hws_bin", "height"]):
        sheet_name = f"{hws_bin.split(' ')[0]}_{h}m"    
        sub.droplevel(["hws_bin", "height"]).to_excel(writer, sheet_name=sheet_name)
print(f"  - HWS all statistics saved to {OUT_DIR / 'HWS_error_stats_all.xlsx'}")

print("\nAll analysis completed successfully!")








import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import matplotlib.ticker as mticker
import matplotlib.lines as mlines
from pathlib import Path

# =============================================================================
# 0. å…¨å±€å¸¸é‡ï¼ˆä¿®æ”¹DISPLAY_NAMESï¼‰
# =============================================================================
HEIGHTS = [80, 140, 200, 280]
COLMAP = {"MWR":"red", "TowerTurb":"slategray",
          "CRA":"magenta", "ERA5":"blue", "LiDAR":"darkorange"}
# ä¿®æ”¹ï¼šå°†Turb.æ”¹ä¸ºECFMS
DISPLAY_NAMES = {"TowerTurb":"ECM", "LiDAR":"DWL"}

# ---- RH æ¡£åˆ’åˆ† & é¢œè‰² ----
RH_BINS = {
    "Low RH (<50%)"      : (-np.inf, 50),
    "Middle RH (50â€“80%)"    : (50, 80),
    "High RH (>80%)"     : (80,  np.inf),
}
RH_ORDER  = list(RH_BINS.keys())
RH_COLORS = {
    "Low RH (<50%)"   : "#1f77b4",
    "Middle RH (50â€“80%)" : "#2ca02c",
    "High RH (>80%)"  : "#d62728",
}

# ---- Temp æ¡£åˆ’åˆ† & é¢œè‰² ----
TEMP_BINS = {
    "Low T (<300 K)"  : (-np.inf, 27+273),
    "Middle T (300â€“303 K)": (27+273 , 30+273),
    "High T (â‰¥303 K)" : (30+273 , np.inf),
}
TEMP_ORDER  = list(TEMP_BINS.keys())
TEMP_COLORS = {
    "Low T (<300 K)"  : "#1f77b4",
    "Middle T (300â€“303 K)": "#2ca02c",
    "High T (â‰¥303 K)" : "#d62728",
}

# ---- HWS æ¡£åˆ’åˆ† & é¢œè‰² ----
HWS_BINS = {
    "Low HWS (<3 m/s)": (-np.inf, 3),
    "Middle HWS (3â€“7 m/s)": (3, 7),
    "High HWS (â‰¥7 m/s)": (7, np.inf),
}
HWS_ORDER = list(HWS_BINS.keys())
HWS_COLORS = {
    "Low HWS (<3 m/s)": "#1f77b4",
    "Middle HWS (3â€“7 m/s)": "#2ca02c",
    "High HWS (â‰¥7 m/s)": "#d62728",
}

# ---- æ—¶é—´çª—å£å®šä¹‰ ----
EXCLUDE_WINDOWS = [
    (pd.Timestamp("2024-08-09 12:46"), pd.Timestamp("2024-08-10 00:03")),
    (pd.Timestamp("2024-06-07 09:15"), pd.Timestamp("2024-06-07 15:00")),
    (pd.Timestamp("2024-08-10 16:20"), pd.Timestamp("2024-08-10 17:30"))
]

# ---- 60åˆ†é’Ÿåˆ†è¾¨ç‡çš„æ•°æ®æº ----
RES_SRC_RH_60min = RES_SRC_TEMP_60min = ["TowerTurb", "MWR", "ERA5", "CRA"]
RES_SRC_HWS_60min = ["LiDAR", "TowerTurb", "ERA5", "CRA"]

# =============================================================================
# 1. é€šç”¨å‡½æ•°ï¼šæ—¶é—´çª—å£è¿‡æ»¤ï¼ˆä¸åŸä»£ç ç›¸åŒï¼‰
# =============================================================================
def filter_by_time_windows(series, windows, inside=True):
    if not windows:
        return series
    
    mask = pd.Series(False, index=series.index)
    
    for start, end in windows:
        window_mask = (series.index >= start) & (series.index <= end)
        if inside:
            mask = mask | window_mask
        else:
            pass
    
    if inside:
        return series[mask]
    else:
        inside_mask = pd.Series(False, index=series.index)
        for start, end in windows:
            inside_mask = inside_mask | ((series.index >= start) & (series.index <= end))
        return series[~inside_mask]

# =============================================================================
# 2. æ•°æ®æ„å»ºå‡½æ•°ï¼ˆåªå¤„ç†60åˆ†é’Ÿæ•°æ®ï¼‰
# =============================================================================
def build_rh_error_df_60min(inside=None):
    """æ„å»º60åˆ†é’ŸRHè¯¯å·®æ•°æ®"""
    recs = []
    sdict = series_dict_60min  # å‡è®¾è¿™ä¸ªå˜é‡å·²å®šä¹‰
    if sdict is None:
        return pd.DataFrame()
        
    for h in HEIGHTS:
        if "TowerAvg" not in sdict["RH"][h]:
            continue
        ref = sdict["RH"][h]["TowerAvg"].dropna()
        
        if inside is not None:
            ref = filter_by_time_windows(ref, EXCLUDE_WINDOWS, inside=inside)
        
        for src in RES_SRC_RH_60min:
            if src not in sdict["RH"][h]:
                continue
            tgt = sdict["RH"][h][src].dropna()
            
            if inside is not None:
                tgt = filter_by_time_windows(tgt, EXCLUDE_WINDOWS, inside=inside)
            
            aligned = pd.concat([ref, tgt], axis=1, join="inner").dropna()
            diff = aligned.iloc[:, 1] - aligned.iloc[:, 0]
            ref_rh = aligned.iloc[:, 0]
            
            for ts, e in diff.items():
                rh_val = ref_rh.loc[ts]
                for rh_bin, (lo, hi) in RH_BINS.items():
                    if lo <= rh_val < hi:
                        recs.append({
                            "height"    : h,
                            "rh_bin"    : rh_bin,
                            "source"    : src,
                            "error"     : e,
                        })
                        break
    return pd.DataFrame.from_records(recs)

def build_temp_error_df_60min(inside=None):
    """æ„å»º60åˆ†é’Ÿæ¸©åº¦è¯¯å·®æ•°æ®"""
    recs = []
    sdict = series_dict_60min  # å‡è®¾è¿™ä¸ªå˜é‡å·²å®šä¹‰
    if sdict is None:
        return pd.DataFrame()
        
    for h in HEIGHTS:
        if "TowerAvg" not in sdict["Temp"][h]:
            continue
        ref = sdict["Temp"][h]["TowerAvg"].dropna()
        
        if inside is not None:
            ref = filter_by_time_windows(ref, EXCLUDE_WINDOWS, inside=inside)
        
        for src in RES_SRC_TEMP_60min:
            if src not in sdict["Temp"][h]:
                continue
            tgt = sdict["Temp"][h][src].dropna()
            
            if inside is not None:
                tgt = filter_by_time_windows(tgt, EXCLUDE_WINDOWS, inside=inside)
            
            aligned = pd.concat([ref, tgt], axis=1, join="inner").dropna()
            diff = aligned.iloc[:, 1] - aligned.iloc[:, 0]
            ref_t = aligned.iloc[:, 0]
            
            for ts, e in diff.items():
                t_val = ref_t.loc[ts]
                for t_bin, (lo, hi) in TEMP_BINS.items():
                    if lo <= t_val < hi:
                        recs.append({
                            "height"    : h,
                            "temp_bin"  : t_bin,
                            "source"    : src,
                            "error"     : e,
                        })
                        break
    return pd.DataFrame.from_records(recs)

def build_hws_error_df_60min(inside=None):
    """æ„å»º60åˆ†é’Ÿé£é€Ÿè¯¯å·®æ•°æ®"""
    recs = []
    sdict = series_dict_60min  # å‡è®¾è¿™ä¸ªå˜é‡å·²å®šä¹‰
    if sdict is None:
        return pd.DataFrame()
        
    for h in HEIGHTS:
        if "TowerAvg" not in sdict["HWS"][h]:
            continue
        ref = sdict["HWS"][h]["TowerAvg"].dropna()
        
        if inside is not None:
            ref = filter_by_time_windows(ref, EXCLUDE_WINDOWS, inside=inside)
        
        for src in RES_SRC_HWS_60min:
            if src not in sdict["HWS"][h]:
                continue
            tgt = sdict["HWS"][h][src].dropna()
            
            if inside is not None:
                tgt = filter_by_time_windows(tgt, EXCLUDE_WINDOWS, inside=inside)
            
            aligned = pd.concat([ref, tgt], axis=1, join="inner").dropna()
            diff = aligned.iloc[:, 1] - aligned.iloc[:, 0]
            ref_hws = aligned.iloc[:, 0]
            
            for ts, e in diff.items():
                hws_val = ref_hws.loc[ts]
                for hws_bin, (lo, hi) in HWS_BINS.items():
                    if lo <= hws_val < hi:
                        recs.append({
                            "height"    : h,
                            "hws_bin"   : hws_bin,
                            "source"    : src,
                            "error"     : e,
                        })
                        break
    return pd.DataFrame.from_records(recs)

# =============================================================================
# 3. ç»˜å›¾å‡½æ•°ï¼šç»„åˆæ¸©åº¦ã€æ¹¿åº¦å’Œé£é€Ÿè¯¯å·®
# =============================================================================
plt.rcParams.update(plt.rcParamsDefault)
panel_labels = ["(a)", "(b)", "(c)", "(d)", "(e)", "(f)"]
def make_combined_plot(outfile: Path):
    """åˆ›å»ºåŒ…å«æ¸©åº¦ã€æ¹¿åº¦å’Œé£é€Ÿè¯¯å·®çš„ç»„åˆå›¾"""
    # è®¾ç½®å…¨å±€å­—ä½“ä¸ºArialï¼Œå­—å·ä¸º22
    plt.rcParams.update({
        'font.size': 22,
        'font.family': 'sans-serif',                
        'font.sans-serif': ['Arial', 'DejaVu Sans'],     
        'axes.titlepad': 10,
        'legend.fontsize': 22,
        'axes.labelsize': 22,
        'xtick.labelsize': 22,
        'ytick.labelsize': 22,
        'xtick.major.size': 12,
        'xtick.minor.size': 7,
        'ytick.major.size': 12,
        'ytick.minor.size': 7,
        'xtick.direction': 'out',
        'ytick.direction': 'out',
        'xtick.major.width': 2,
        'xtick.minor.width': 2,
        'ytick.major.width': 2,
        'ytick.minor.width': 2,
    })
    
    # åˆ›å»º6è¡Œ4åˆ—çš„å›¾å½¢ï¼Œä½¿ç”¨GridSpecä»¥ä¾¿æ›´ç²¾ç¡®æ§åˆ¶é—´è·
    ROWS, COLS = 6, len(HEIGHTS)
    FIGSIZE = (20, 40)  # å¢åŠ é«˜åº¦ä»¥å®¹çº³å›¾ä¾‹
    fig = plt.figure(figsize=FIGSIZE)
    
    # ä½¿ç”¨GridSpecå¹¶è®¾ç½®é«˜åº¦æ¯”ä¾‹ï¼Œä»¥ä¾¿æ§åˆ¶å˜é‡å†…éƒ¨åˆ†ç»„é—´è·
    # æ¯ä¸ªå˜é‡ç»„å 2è¡Œï¼Œå˜é‡ç»„ä¹‹é—´é—´è·ä¸º0.5ï¼Œå˜é‡å†…éƒ¨åˆ†ç»„é—´è·ä¸º0.2
    height_ratios = [1, 1, 0.1, 1, 1, 0.1, 1, 1, 0.1, 1, 1]  # 6ä¸ªå­å›¾+5ä¸ªé—´è·
    gs = gridspec.GridSpec(11, COLS, height_ratios=height_ratios, 
                          hspace=0.35, wspace=0.5)
    
    # åˆ›å»ºå­å›¾æ•°ç»„ï¼Œè·³è¿‡é—´è·è¡Œ
    axes = []
    row_indices = [0, 1, 3, 4, 6, 7]  # å®é™…å­å›¾æ‰€åœ¨çš„è¡Œç´¢å¼•
    for r in row_indices:
        row_axes = []
        for c in range(COLS):
            row_axes.append(fig.add_subplot(gs[r, c]))
        axes.append(row_axes)
    
    # å¸ƒå±€å‚æ•°
    box_w = 0.4
    jit_s = 12
    off = np.array([-0.8, 0.0, 0.8])
    row_spacing = 2.2
    
    # è¡Œæ ‡ç­¾å’Œå˜é‡è®¾ç½® - ä¿®æ”¹é¡ºåºï¼šincludeåœ¨ä¸Šï¼Œexcludeåœ¨ä¸‹
    row_settings = [
        # (å˜é‡ç±»å‹, åˆ†ç»„, æ•°æ®æºåˆ—è¡¨, é¢œè‰²å­—å…¸, æ¡£é¡ºåº, xè½´æ ‡ç­¾, xè½´èŒƒå›´, xè½´åˆ»åº¦)
        ("temp", "exclude", RES_SRC_TEMP_60min, TEMP_COLORS, TEMP_ORDER, "Bias (K)", (-9, 9.5), 3),
        ("temp", "include", RES_SRC_TEMP_60min, TEMP_COLORS, TEMP_ORDER, "Bias (K)", (-9, 9.5), 3),
        
        ("rh", "exclude", RES_SRC_RH_60min, RH_COLORS, RH_ORDER, "Bias (%)", (-54, 50), 20),
        ("rh", "include", RES_SRC_RH_60min, RH_COLORS, RH_ORDER, "Bias (%)", (-54, 50), 20),

        ("hws", "exclude", RES_SRC_HWS_60min, HWS_COLORS, HWS_ORDER, "Bias (m/s)", (-9.5, 9), 3),
        ("hws", "include", RES_SRC_HWS_60min, HWS_COLORS, HWS_ORDER, "Bias (m/s)", (-9.5, 9), 3),
    ]
    
    # æ„å»ºæ•°æ®
    df_temp_exclude = build_temp_error_df_60min(inside=False)
    df_temp_include = build_temp_error_df_60min(inside=True)
    df_rh_exclude = build_rh_error_df_60min(inside=False)
    df_rh_include = build_rh_error_df_60min(inside=True)
    df_hws_exclude = build_hws_error_df_60min(inside=False)
    df_hws_include = build_hws_error_df_60min(inside=True)
    
    # æ•°æ®æ˜ å°„
    data_map = {
        ("temp", "exclude"): df_temp_exclude,
        ("temp", "include"): df_temp_include,
        ("rh", "exclude"): df_rh_exclude,
        ("rh", "include"): df_rh_include,
        ("hws", "exclude"): df_hws_exclude,
        ("hws", "include"): df_hws_include,
    }
    
    # å˜é‡åç¼©å†™æ˜ å°„
    VAR_ABBR = {"temp": "Temp", "rh": "RH", "hws": "HWS"}
    #VAR_ABBR1 = {"temp": "Temp", "rh": "RH", "hws": "HWS"}
    # ç»˜åˆ¶æ¯ä¸ªå­å›¾
    for r, (var, group, src_list, colors, bin_order, xlabel, xlim, xtick) in enumerate(row_settings):
        y_base = np.arange(len(src_list)) * row_spacing
        df = data_map[(var, group)]
        
        for c, h in enumerate(HEIGHTS):
            ax = axes[r][c]
            ax.axvline(0, color='black', lw=1.5, linestyle=(0,(5,10)))
            
            sub = df.query("height == @h")
            if sub.empty:
                ax.text(0.5, 0.5, "No data", ha="center", va="center", alpha=0.6)
                ax.set_xticks([]); ax.set_yticks([]); ax.set_frame_on(False)
                continue
            
            # ç»˜åˆ¶ç®±çº¿å›¾å’Œæ•£ç‚¹
            for i, src in enumerate(src_list):
                for j, bin_name in enumerate(bin_order):
                    if var == "temp":
                        errs = sub.loc[(sub["source"] == src) & (sub["temp_bin"] == bin_name), "error"].values
                    elif var == "rh":
                        errs = sub.loc[(sub["source"] == src) & (sub["rh_bin"] == bin_name), "error"].values
                    else:  # hws
                        errs = sub.loc[(sub["source"] == src) & (sub["hws_bin"] == bin_name), "error"].values
                    
                    if errs.size == 0:
                        continue
                    
                    # ç®±çº¿å›¾
                    ax.boxplot(errs, vert=False,
                               positions=[y_base[i] + off[j]],
                               widths=box_w,
                               patch_artist=True, manage_ticks=False,
                               boxprops=dict(facecolor=colors[bin_name], alpha=0.75, linewidth=1.5),
                               flierprops=dict(marker="x", markersize=5, markeredgecolor="black", 
                                               markerfacecolor="none", linewidth=0.5),
                               medianprops=dict(color="lime", linewidth=1.5),
                               whiskerprops=dict(color="black", linewidth=1.5),
                               capprops=dict(color="black", linewidth=1.5))
                    
                    # æ•£ç‚¹
                    jitter_y = np.random.normal(y_base[i] + off[j], 0.06, size=len(errs))
                    ax.scatter(errs, jitter_y, s=jit_s, color=colors[bin_name], alpha=0.8, linewidths=0)
            
            # è®¾ç½®è½´æ ‡ç­¾å’Œåˆ»åº¦
            ax.set_yticks(y_base)
            disp_names = [DISPLAY_NAMES.get(s, s) for s in src_list]
            ax.set_yticklabels(disp_names)
            ax.set_ylim(y_base[0] - 1.5, y_base[-1] + 1.5)
            ax.grid(axis="x", linestyle=(0, (5, 8)), alpha=0.6)
            ax.spines["top"].set_visible(False)
            ax.spines["right"].set_visible(False)
            ax.spines["left"].set_linewidth(1.5)
            ax.spines["bottom"].set_linewidth(1.5)
            
            ax.set_xlim(xlim)
            ax.xaxis.set_major_locator(mticker.MultipleLocator(xtick))
            ax.xaxis.set_minor_locator(mticker.MultipleLocator(xtick/2))
            
            # åªåœ¨æœ€å·¦ä¾§æ·»åŠ å˜é‡æ ‡ç­¾ï¼Œåœ¨æœ€åº•éƒ¨æ·»åŠ xè½´æ ‡ç­¾
            if c == 0:
               var_abbr = VAR_ABBR[var]
               if group == "exclude":
                   label_text = f"{var_abbr}\nExclude Rainstorm"
               else:
                   label_text = f"{var_abbr}\nInclude Rainstorm"
               ax.set_ylabel(label_text, fontsize=22)
            else:
               ax.set_ylabel("")
            
            # åœ¨é¡¶éƒ¨æ·»åŠ é«˜åº¦æ ‡ç­¾
            if r == 0:
                ax.set_title(f"{h} m", fontsize=22, pad=10,fontweight="bold")
            if c == 0:
                ax.text(-0.25, 1.02, panel_labels[r],transform=ax.transAxes,fontsize=26,fontweight="bold", va="bottom", ha="right")
    # æ·»åŠ å˜é‡ç»„å›¾ä¾‹ - è°ƒæ•´ä½ç½®ä»¥é€‚åº”æ–°çš„å¸ƒå±€
    # æ¸©åº¦ç»„å›¾ä¾‹ï¼ˆæ”¾åœ¨ç¬¬0è¡Œä¸Šæ–¹ï¼‰
    handles_temp = [mlines.Line2D([], [], color=TEMP_COLORS[b], marker="s", linestyle="", 
                                 markersize=12, label=b) for b in TEMP_ORDER]
    temp_legend = fig.legend(handles_temp, [h.get_label() for h in handles_temp],
                            loc='center', bbox_to_anchor=(0.5, 0.90), ncol=3, frameon=False,
                           title_fontsize=22)
    
    # æ¹¿åº¦ç»„å›¾ä¾‹ï¼ˆæ”¾åœ¨ç¬¬2è¡Œä¸Šæ–¹ï¼‰
    handles_rh = [mlines.Line2D([], [], color=RH_COLORS[b], marker="s", linestyle="", 
                              markersize=12, label=b) for b in RH_ORDER]
    rh_legend = fig.legend(handles_rh, [h.get_label() for h in handles_rh],
                          loc='center', bbox_to_anchor=(0.5, 0.695), ncol=3, frameon=False,
                          title="Temperature bias(K)\n", title_fontsize=22)
    
    # é£é€Ÿç»„å›¾ä¾‹ï¼ˆæ”¾åœ¨ç¬¬4è¡Œä¸Šæ–¹ï¼‰
    handles_hws = [mlines.Line2D([], [], color=HWS_COLORS[b], marker="s", linestyle="", 
                               markersize=12, label=b) for b in HWS_ORDER]
    hws_legend = fig.legend(handles_hws, [h.get_label() for h in handles_hws],
                           loc='center', bbox_to_anchor=(0.5, 0.49), ncol=3, frameon=False,
                           title="Relative Humidity bias(%)\n", title_fontsize=22)
    fig.text(
        0.5, 0.295,                  # 0.04 å¯ä»¥æ ¹æ®æ•ˆæœå¾®è°ƒé«˜ä½
        "Horizontal Wind Speed bias(m/s)",
        ha="center", va="center",
        fontsize=22
    )
    # ä¿å­˜å›¾å½¢
    fig.savefig(outfile, dpi=600, format="tif", transparent=True, bbox_inches="tight",
                pil_kwargs={"compression": "tiff_adobe_deflate"})
    plt.close(fig)
    print(f"Saved â†’ {outfile}")

# =============================================================================
# 4. ä¸»æ‰§è¡Œæµç¨‹
# =============================================================================
# å‡è®¾ series_dict_60min å·²å®šä¹‰ï¼ˆåŒ…å«60åˆ†é’Ÿåˆ†è¾¨ç‡çš„æ•°æ®ï¼‰

# åˆ›å»ºè¾“å‡ºç›®å½•
OUT_DIR = Path(r"E:\Beijing2024\å‡ºå›¾TIF")
OUT_DIR.mkdir(parents=True, exist_ok=True)

# ç”Ÿæˆç»„åˆå›¾
make_combined_plot(OUT_DIR / "Combined_Conditional_Bias_60min.tif")

print("Combined plot generation completed successfully!")

gc.collect()















################### ç»˜åˆ¶æ¸©åº¦(æ¢ç©ºæ—¶åˆ»Â±30minå¹³å‡ç‰ˆ) â€“ å¸¦ Inset ###################
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import metpy.calc as mpcalc
from metpy.units import units
from matplotlib.ticker import MultipleLocator
from mpl_toolkits.axes_grid1.inset_locator import inset_axes  # â† æ–°å¢ï¼šinset å·¥å…·

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ç”¨æˆ·é…ç½® â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
excel_path   = r"E:\Beijing2024\æ¢ç©ºæ•°æ®-54511\original combined2.xlsx"
sheet_names  = pd.ExcelFile(excel_path).sheet_names           # å…¨éƒ¨æ—¶æ¬¡
out_dir      = r"E:\Beijing2024\å‡ºå›¾TIF"
out_fname    = "Temperature_Profile_1hå¹³å‡_with_inset.tif"  # â† æ–‡ä»¶åæ›´æ–°
os.makedirs(out_dir, exist_ok=True)
site_elev = 49

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ç»Ÿä¸€çš„ç»˜å›¾é£æ ¼ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
plt.rcParams.update({
    'font.family': 'sans-serif',                # å…ˆæŒ‡å®šå®¶æ—
    'font.sans-serif': ['Arial', 'DejaVu Sans'],     # æŠŠ Arial è®¾ä¸ºé¦–é€‰
    'font.size'      : 36,
    'axes.linewidth' : 3,
    'axes.labelsize' : 36,
    'xtick.labelsize': 36,
    'ytick.labelsize': 36
})

# æ ‡å‡†é«˜åº¦/æ°”å‹åˆ»åº¦
alt_ticks = np.array([0, 500, 1000, 1500, 2000, 2500, 3000, 4000, 6000, 8000, 10000])   # m
p_ticks   = np.array([1000, 925, 850, 700, 500, 275])                         # hPa
p2alt = lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å»ºç«‹ 4Ã—3 ç”»å¸ƒ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
n_rows, n_cols = 4, 3
fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 40), sharex=False, sharey=False)
axes = axes.ravel()             # æ–¹ä¾¿ç”¨ 1-D ç´¢å¼•
### â† æ–°å¢ï¼šå…ˆå‡†å¤‡å›¾ä¾‹ç”¨åˆ°çš„å¥æŸ„ä¸æ ‡ç­¾ ###
legend_handles = [
    plt.Line2D([], [], color='blue',    lw=6, label='ERA5'),
    plt.Line2D([], [], color='magenta', lw=6, label='CRA'),
    plt.Line2D([], [], color='red',     lw=6, label='MWR'),
    plt.Line2D([], [], color='black',   lw=6, label='Radiosonde')
]

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å¾ªç¯æ‰€æœ‰æ—¶æ¬¡ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
for idx, sheet in enumerate(sheet_names):
    if idx >= n_rows * n_cols:            # è¶…å‡º 12 å¼ å­å›¾å°±è·³è¿‡
        break

    ax = axes[idx]
    ax.spines['bottom'].set_color('red')
    ax.spines['bottom'].set_linewidth(ax.spines['left'].get_linewidth())
    ax.spines['left'].set_color('red')
    # 1) è¯»å–æ¢ç©ºè¡¨
    snd = pd.read_excel(excel_path, sheet_name=sheet)

    # 2) å½“å‰ target_timeï¼ˆç”±å·¥ä½œè¡¨åè§£æï¼‰
    target_time = pd.to_datetime(sheet, format='%Y%m%d%H')

    # 3) æŒ‰åŸé€»è¾‘è¿‡æ»¤/å¤„ç† ERA5ã€CRAã€MWR
    era5_profile = ERA5_interp_BJ[ERA5_interp_BJ['valid_time'] == target_time].copy()
    cra_regular['timestamps'] = pd.to_datetime(cra_regular['timestamps'])
    cra_profile = cra_regular[cra_regular['timestamps'] == target_time].copy()
    # å¤„ç†MWRæ•°æ®ï¼šå–æ¢ç©ºæ—¶åˆ»å‰ååŠå°æ—¶å¹³å‡
    start_time = target_time - pd.Timedelta(minutes=30)
    end_time = target_time + pd.Timedelta(minutes=30)
    mwr_filtered = t_mwr_long.reset_index()  # å°†åŒé‡ç´¢å¼•è½¬æ¢ä¸ºåˆ—
    mask = (mwr_filtered['timestamps'] >= start_time) & (mwr_filtered['timestamps'] <= end_time)
    mwr_filtered = mwr_filtered.loc[mask]
    if not mwr_filtered.empty:
        mwr_avg = mwr_filtered.groupby('height', as_index=False)['T(K)'].mean()
        mwr_profile = mwr_avg.sort_values('height')
    else:
        print(f"âš ï¸ å½“å‰æ—¶æ¬¡ {target_time.strftime('%Y-%m-%d %H:%M')} çš„ MWR æ•°æ®ä¸å­˜åœ¨")
        mwr_profile = pd.DataFrame(columns=['height', 'T(K)'])  # ç©ºDataFrameé¿å…æŠ¥é”™
    
    # â€” å•ä½è½¬æ¢ â€”
    era5_profile['height'] = mpcalc.pressure_to_height_std(
        era5_profile['pressure_level'].to_list() * units.hPa
    ).to('m').magnitude - site_elev
    cra_profile['height'] = mpcalc.pressure_to_height_std(
        cra_profile['Level (hPa)'].to_list() * units.hPa
    ).to('m').magnitude - site_elev
    snd['temperature_K'] = snd['temperature_C'] + 273.15
    snd['height'] = mpcalc.pressure_to_height_std(
        snd['pressure_hPa'].to_list() * units.hPa
    ).to('m').magnitude - site_elev

    # â€” æ’åº â€”
    era5_profile = era5_profile.sort_values('height')
    cra_profile  = cra_profile.sort_values('height').iloc[:37]
    snd          = snd.sort_values('height')

    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ç»˜å›¾ï¼ˆä¸»å›¾ï¼š0â€“3000 mï¼‰ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    ax.plot(era5_profile['t'],       era5_profile['height'],color='blue',    lw=5)
    ax.plot(cra_profile['Temp (K)'], cra_profile['height'], color='magenta', lw=5)
    ax.plot(mwr_profile['T(K)'],     mwr_profile['height'], color='red',     lw=5)
    ax.plot(snd['temperature_K'],    snd['height'],         color='black',   lw=5)
    
    # ä¸»å›¾ y èŒƒå›´ï¼š0â€“3000 m
    ax.set_ylim(0, 3500)  # â† ä¿®æ”¹ï¼šé™å®šä¸»å›¾é«˜åº¦
    ax.set_xlim(275, 310)
    # â€” è™šçº¿å‚è€ƒé«˜åº¦/æ°”å‹ â€”
    for y in alt_ticks:
        ax.axhline(y, color='red',   lw=2, ls=(0, (5, 10)), zorder=0)
    for p in p_ticks:
        ax.axhline(p2alt(p), color='blue', lw=2, ls=(0, (5, 10)), zorder=0)
    # â€” å·¦å³åŒè½´ â€”
    secax = ax.secondary_yaxis(
        'right',
        functions=(
            lambda h: mpcalc.height_to_pressure_std(h * units.m).to('hPa').magnitude,
            lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude
        )
    )
    secax.set_ylim(1000, 700)  # å¯¹åº” 0â€“3000 m çš„å‹å¼ºèŒƒå›´è¿‘ä¼¼

    # y-ticksï¼ˆä¸»ï¼‰
    ax.set_yticks([0, 500, 1000, 1500, 2000, 2500, 3000, 3500])
    secax.set_yticks([1000, 925, 900, 850, 700])

    # x è½´ç»†èŠ‚
    ax.xaxis.set_major_locator(MultipleLocator(10))
    ax.xaxis.set_minor_locator(MultipleLocator(5))    
    ax.tick_params(axis='x', colors='red', length=12, width=2)
    ax.tick_params(axis='x', which='minor', length=6, width=2, colors='red')
    if row == 3 and col == 0:
        ax.set_xlabel('Temperature (K)', color='red', fontsize=50, weight='bold')

    # y è½´åˆ»åº¦é¢œè‰²
    ax.tick_params(axis='y', colors='red', length=12, width=2)
    secax.tick_params(axis='y', colors='blue', length=12, width=2)

    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” Insetï¼š3000â€“10000 m â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    axins = inset_axes(ax, width="31%", height="48%", loc='upper right', borderpad=0.8)  # â† æ–°å¢
       # â˜…â˜…â˜… å…³é”®ï¼šç»™ inset è½´åŠ ä¸€å—ä¸é€æ˜èƒŒæ™¯å¹¶æŠ¬é«˜ z-order â˜…â˜…â˜…
    axins.set_facecolor('white')         # ç”¨ç™½è‰²æŠŠä¸»å›¾çº¿æ¡é®æ‰
    axins.patch.set_alpha(1)             # ä¿è¯ä¸é€æ˜
    axins.patch.set_zorder(2)            # z-order è¦é«˜äºä¸»å›¾é‡Œ axhline çš„ 0
    # ç”»åŒä¸€æ¡æ›²çº¿
    axins.plot(era5_profile['t'],      era5_profile['height'], color='blue',    lw=3)
    axins.plot(cra_profile['Temp (K)'], cra_profile['height'], color='magenta', lw=3)
    axins.plot(mwr_profile['T(K)'],     mwr_profile['height'], color='red',     lw=3)
    axins.plot(snd['temperature_K'],    snd['height'],         color='black',   lw=3)

    axins.set_xlim(230, 290)
    axins.set_ylim(3500, 10000)  # åªçœ‹é«˜ç©º
    axins.set_facecolor('white')
    # Inset è½´åˆ»åº¦æ›´å°å³å¯ï¼ˆå…³é—­ minorï¼‰
    axins.xaxis.set_major_locator(MultipleLocator(20))
    axins.yaxis.set_major_locator(MultipleLocator(2000))
    # â€”â€” ç»Ÿä¸€è®¾ç½® x è½´å…ƒç´ ä¸ºçº¢è‰² â€”â€”
    axins.tick_params(axis='x', which='both', colors='red', labelsize=30,
                      width=ax.spines['left'].get_linewidth(), length=8)
    axins.tick_params(axis='y', which='both', labelsize=30,
                      width=ax.spines['left'].get_linewidth(), length=8)
    # â€”â€” Inset spines è®¾ç½® â€”â€”
    axins.spines['top'  ].set_visible(False)   # â† é¡¶éƒ¨ä¸å¯è§
    axins.spines['right'].set_visible(False)   # â† å³ä¾§ä¸å¯è§
    axins.spines['bottom'].set_color('red')
    # åº• / å·¦ä¿æŒåŒç­‰çº¿å®½
    for spine in ['left', 'bottom']:
        axins.spines[spine].set_linewidth(ax.spines['left'].get_linewidth())

    # ä¸éœ€è¦æ¬¡è½´ã€æ ‡ç­¾
    axins.set_xlabel('', color='red')
    axins.set_ylabel('')

    # â€”â€”â€”â€”â€”â€”â€”â€” è½´åˆ»åº¦ã€æ ‡ç­¾ç®¡ç†ï¼ˆä¸»å›¾ï¼‰ â€”â€”â€”â€”â€”â€”â€”â€”
    col = idx % n_cols
    row = idx // n_cols

    # ä»…ä¿ç•™å·¦/å³è¾¹ & æœ€åº•è¡Œçš„è½´æ ‡ç­¾
    if col == 0:                # æœ€å·¦åˆ— â†’ é«˜åº¦æ ‡ç­¾
        ax.set_ylabel(' ', color='black')
    else:
        ax.set_ylabel('')
        ax.tick_params(axis='y', labelleft=False)

    if col == n_cols - 1:       # æœ€å³åˆ— â†’ Pressure æ ‡ç­¾
        secax.set_ylabel(' ', color='black', rotation=270, labelpad=20)
    else:
        secax.set_ylabel('')
        secax.tick_params(axis='y', labelright=False)

    if row == n_rows - 1:       # æœ€åº•è¡Œ â†’ Temperature æ ‡ç­¾
        ax.xaxis.set_major_locator(MultipleLocator(10))
        ax.xaxis.set_minor_locator(MultipleLocator(5))
        ax.tick_params(axis='x', which='major', length=12, width=2, colors='red')
        ax.tick_params(axis='x', which='minor', length=6, width=2, colors='red')
    else:
        ax.set_xlabel('', color='red')
        ax.tick_params(axis='x', labelbottom=False, colors='red')
    if row == 3 and col == 1:
        ax.set_xlabel('Temperature (K)', color='red', weight='bold')
    
    
    # ä»…åœ¨ Inset ä¸Šç»˜åˆ¶é«˜å±‚è™šçº¿é«˜åº¦
    for y in alt_ticks[(alt_ticks >= 3500) & (alt_ticks <= 10000)]:
        axins.axhline(y, color='black', lw=2, ls=(0, (5, 5)), zorder=0)
    # â€” å­å›¾æ ‡é¢˜ â€”
    ax.set_title(target_time.strftime('%Y-%m-%d %H:%M (BJT)'), pad=12, fontsize=36, weight='bold')
    axins.set_ylim(3500, 10100)
    axins.set_xlim(230,  290)
    axins.spines['left'].set_color('red')
    axins.tick_params(axis='y', colors='red')
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” éšè—ç©ºç™½å­å›¾ï¼ˆå¦‚æœæœ‰ï¼‰ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
for j in range(idx + 1, n_rows * n_cols):
    fig.delaxes(axes[j])

fig.text(0.01, 0.5, 'Height (m a.g.l.)', rotation=90, va='center', ha='left',
         color='black', weight='bold', fontsize=50)
fig.text(0.995, 0.5, 'Pressure (hPa)', rotation=270, va='center', ha='right',
         color='black', weight='bold', fontsize=50)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ä¿å­˜é«˜åˆ†è¾¨ç‡ TIF â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
fig.legend(handles=legend_handles,
           loc='upper center',
           bbox_to_anchor=(0.5, 0.995),
           ncol=4,
           frameon=False,
           fontsize=32)

fig.text(0.5, 0.993,
         'Temperature Radiosonde Comparison â€“ 1h Temporal Resolution',
         ha='center', va='bottom',
         fontsize=40, weight='bold')

fig.tight_layout(rect=[0, 0, 1, 0.98])
save_path = os.path.join(out_dir, out_fname)
fig.savefig(save_path, dpi=300, #transparent=True,
            pil_kwargs={"compression": "tiff_adobe_deflate"},
            format='tif', bbox_inches='tight')
print(f"âœ… å·²ä¿å­˜åˆ°ï¼š{save_path}")






################### ç»˜åˆ¶æ¸©åº¦(æ¢ç©ºåŒ¹é…ç‰ˆ) â€” å¸¦ Inset ###################
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import metpy.calc as mpcalc
from metpy.units import units
from matplotlib.ticker import MultipleLocator
from scipy.interpolate import interpn
from mpl_toolkits.axes_grid1.inset_locator import inset_axes   # â† æ–°å¢ï¼šinset å·¥å…·

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ç”¨æˆ·é…ç½® â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
excel_path   = r"E:\\Beijing2024\\æ¢ç©ºæ•°æ®-54511\\original combined2.xlsx"
sheet_names  = pd.ExcelFile(excel_path).sheet_names           # å…¨éƒ¨æ—¶æ¬¡
out_dir      = r"E:\Beijing2024\å‡ºå›¾TIF"
out_fname    = "Temperature_Profile_MWRåŒ¹é…æ¢ç©º-1min_with_inset2.tif"
os.makedirs(out_dir, exist_ok=True)
site_elev = Altitude   # â† è¯·æ›¿æ¢ä¸ºå®é™…æµ·æ‹”é«˜åº¦ (m)

# æå– t_mwr_long çš„ç½‘æ ¼ç‚¹ï¼ˆæ—¶é—´æˆ³å’Œé«˜åº¦ï¼‰
time_points   = t_mwr_long.index.get_level_values('timestamps').unique().sort_values()
height_points = t_mwr_long.index.get_level_values('height').unique().sort_values()

# å°†æ—¶é—´è½¬æ¢ä¸º UNIX ç§’
time_numeric = (time_points - pd.Timestamp("1970-01-01")) // pd.Timedelta('1s')

# æå– t_mwr_long çš„æ¸©åº¦æ•°æ®å¹¶é‡å¡‘ä¸ºäºŒç»´ç½‘æ ¼
values_grid = t_mwr_long.unstack().values  # å½¢çŠ¶ = (len(time_points), len(height_points))

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ç»Ÿä¸€çš„ç»˜å›¾é£æ ¼ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
plt.rcParams.update({
    'font.family'      : 'sans-serif',
    'font.sans-serif'  : ['Arial', 'DejaVu Sans'],
    'font.size'        : 36,
    'axes.linewidth'   : 3,
    'axes.labelsize'   : 36,
    'xtick.labelsize'  : 36,
    'ytick.labelsize'  : 36
})


alt_ticks = np.array([0, 500, 1000, 1500, 2000, 2500, 3000, 4000, 6000, 8000, 10000])   # m
p_ticks   = np.array([1000, 925, 850, 700, 500, 275])     
p2alt = lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å»ºç«‹ 4Ã—3 ç”»å¸ƒ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
n_rows, n_cols = 4, 3
fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 40), sharex=False, sharey=False)
axes = axes.ravel()  # æ–¹ä¾¿ç”¨ 1â€‘D ç´¢å¼•

# å›¾ä¾‹ç”¨åˆ°çš„å¥æŸ„ä¸æ ‡ç­¾ (ä¸»å›¾ & inset å…±ç”¨)
legend_handles = [
    #plt.Line2D([], [], color='blue',    lw=6, label='ERA5'),
    #plt.Line2D([], [], color='magenta', lw=6, label='CRA'),
    plt.Line2D([], [], color='red',     lw=6, label='MWR'),
    plt.Line2D([], [], color='black',   lw=6, label='Radiosonde')
]

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å¾ªç¯æ‰€æœ‰æ—¶æ¬¡ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
for idx, sheet in enumerate(sheet_names):
    if idx >= n_rows * n_cols:   # è¶…å‡º 12 å¼ å­å›¾å°±è·³è¿‡
        break

    ax = axes[idx]

    # 1) è¯»å–æ¢ç©ºè¡¨
    snd = pd.read_excel(excel_path, sheet_name=sheet)

    # 2) å½“å‰ target_timeï¼ˆç”±å·¥ä½œè¡¨åè§£æï¼‰
    target_time = pd.to_datetime(sheet, format='%Y%m%d%H')

    # 3) æŒ‰åŸé€»è¾‘è¿‡æ»¤ / å¤„ç† ERA5ã€CRAã€MWR
    era5_profile = ERA5_interp_BJ[ERA5_interp_BJ['valid_time'] == target_time].copy()
    cra_regular['timestamps'] = pd.to_datetime(cra_regular['timestamps'])
    cra_profile = cra_regular[cra_regular['timestamps'] == target_time].copy()

    # è‹¥ç›®æ ‡æ—¶åˆ»ä¸åœ¨ MWR ç½‘æ ¼æ—¶åºä¸­ â†’ å¡«å…… NaN
    if target_time not in time_points:
        interpolated_T = np.full(snd.shape[0], np.nan)
    else:
        snd['time'] = pd.to_datetime(snd['time'])
        snd_time_numeric = (snd['time'] - pd.Timestamp("1970-01-01")) // pd.Timedelta('1s')
        snd_height = snd['pressure_hPa'].apply(
            lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude - site_elev
        )
        xi = np.array([snd_time_numeric, snd_height]).T
        interpolated_T = interpn(
            points=(time_numeric, height_points),
            values=values_grid,
            xi=xi,
            method='linear',
            bounds_error=False,
            fill_value=np.nan
        )
    snd['T_mwr_interpolated'] = interpolated_T

    # â€” å•ä½è½¬æ¢ â€”
    era5_profile['height'] = mpcalc.pressure_to_height_std(
        era5_profile['pressure_level'].to_list() * units.hPa).to('m').magnitude - site_elev
    cra_profile['height'] = mpcalc.pressure_to_height_std(
        cra_profile['Level (hPa)'].to_list() * units.hPa).to('m').magnitude - site_elev
    snd['temperature_K'] = snd['temperature_C'] + 273.15
    snd['height'] = mpcalc.pressure_to_height_std(
        snd['pressure_hPa'].to_list() * units.hPa).to('m').magnitude - site_elev

    # â€” æ’åº â€”
    era5_profile = era5_profile.sort_values('height')
    cra_profile  = cra_profile.sort_values('height').iloc[:37]
    snd          = snd.sort_values('height')

    # =========================== ä¸»å›¾ ===========================
    # åªæ˜¾ç¤ºä½å±‚ (0â€“3500 m)
    ax.set_ylim(0, 3500)

    #ax.plot(era5_profile['t'],         era5_profile['height'],         color='blue',    lw=3)
    #ax.plot(cra_profile['Temp (K)'],   cra_profile['height'],         color='magenta', lw=3)
    ax.plot(snd['T_mwr_interpolated'], snd['height'],                 color='red',     lw=3)
    ax.plot(snd['temperature_K'],      snd['height'],                 color='black',   lw=3)

    # â€” å·¦å³åŒè½´ â€”
    secax = ax.secondary_yaxis(
        'right',
        functions=(
            lambda h: mpcalc.height_to_pressure_std(h * units.m).to('hPa').magnitude,
            lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude)
    )
    secax.set_ylim(1000, 275)   # æ°”å‹èŒƒå›´å¯¹åº” 0â€“3500 m (è¿‘ä¼¼å€¼å³å¯)

    # â€” å½©è‰²ç»†èŠ‚
    ax.set_xlim(275, 310)
    ax.spines['bottom'].set_color('red')
    ax.spines['left'  ].set_color('black')
    ax.spines['left'].set_color('red')
    
    # ä¸»åˆ»åº¦ / æ¬¡åˆ»åº¦
    ax.xaxis.set_major_locator(MultipleLocator(10))
    ax.xaxis.set_minor_locator(MultipleLocator(5))

    # yâ€‘tick / xâ€‘tick é…è‰² & æ ·å¼
    ax.tick_params(axis='y', colors='red',   length=12, width=2)
    ax.tick_params(axis='x', colors='red',   length=12, width=2)
    ax.tick_params(axis='x', which='minor',  colors='red', length=6, width=2)
    secax.tick_params(axis='y', colors='blue', length=12, width=2)

    # â€” è™šçº¿å‚è€ƒé«˜åº¦ / æ°”å‹ (ä»…ä½å±‚)
    for y in alt_ticks:
        ax.axhline(y, color='red',   lw=2, ls=(0, (5, 10)), zorder=0)
    for p in p_ticks:
        ax.axhline(p2alt(p), color='blue', lw=2, ls=(0, (5, 10)), zorder=0)

    # â€”â€”â€”â€”â€”â€”â€”â€” è½´åˆ»åº¦ã€æ ‡ç­¾ç®¡ç† â€”â€”â€”â€”â€”â€”â€”â€”
    col = idx % n_cols
    row = idx // n_cols

    # ä»…æœ€å·¦åˆ—æ˜¾ç¤ºé«˜åº¦åˆ»åº¦
    if col == 0:
        ax.set_ylabel(' ', color='black')
    else:
        ax.set_ylabel('')
        ax.tick_params(axis='y', labelleft=False)

    # ä»…æœ€å³åˆ—æ˜¾ç¤ºæ°”å‹åˆ»åº¦
    if col == n_cols - 1:
        secax.set_ylabel(' ', color='black', rotation=270, labelpad=20)
    else:
        secax.set_ylabel('')
        secax.tick_params(axis='y', labelright=False)

    # ä»…æœ€åº•è¡Œæ˜¾ç¤ºæ¸©åº¦æ ‡ç­¾
    if row == n_rows - 1:
        ax.xaxis.set_major_locator(MultipleLocator(10))
        ax.xaxis.set_minor_locator(MultipleLocator(5))
    else:
        ax.set_xlabel('')
        ax.tick_params(axis='x', labelbottom=False)
    if row == 3 and col == 1:
        ax.set_xlabel('Temperature (K)', color='red', fontsize=50, weight='bold')

    # â€” å­å›¾æ ‡é¢˜ â€”
    ax.set_title(target_time.strftime('%Y-%m-%d %H:%M (BJT)'), pad=12, fontsize=36, weight='bold')

    # =========================== Inset Plot (3500â€“10000 m) ===========================
    ax_inset = inset_axes(
        ax,
        width="31%", height="48%",   # å ä¸»å›¾é¢ç§¯çš„æ¯”ä¾‹
        loc='upper right',
        borderpad=0.6
    )

       # â˜…â˜…â˜… å…³é”®ï¼šç»™ inset è½´åŠ ä¸€å—ä¸é€æ˜èƒŒæ™¯å¹¶æŠ¬é«˜ z-order â˜…â˜…â˜…
    ax_inset.set_facecolor('white')         # ç”¨ç™½è‰²æŠŠä¸»å›¾çº¿æ¡é®æ‰
    ax_inset.patch.set_alpha(1)             # ä¿è¯ä¸é€æ˜
    ax_inset.patch.set_zorder(2)            # z-order è¦é«˜äºä¸»å›¾é‡Œ axhline çš„ 0

    # ï¼ˆå¦‚æœæƒ³è®© inset çš„å¤–æ¡†ä¹Ÿå‹åœ¨æœ€ä¸Šé¢ï¼Œå¯ä»¥å†æŠ¬é«˜ä¸€ä¸‹è„Šçº¿ï¼‰
    for spine in ax_inset.spines.values():
        spine.set_zorder(3)
    
    # é€‰å– 3500â€“10000 m çš„æ•°æ®
    era5_high = era5_profile[(era5_profile['height'] >= 3500) & (era5_profile['height'] <= 10000)]
    cra_high  = cra_profile [(cra_profile ['height'] >= 3500) & (cra_profile ['height'] <= 10000)]
    snd_high  = snd         [(snd['height']          >= 3500) & (snd['height']          <= 10000)]

    #ax_inset.plot(era5_high['t'],         era5_high['height'],         color='blue',    lw=3)
    #ax_inset.plot(cra_high['Temp (K)'],   cra_high['height'],          color='magenta', lw=3)
    ax_inset.plot(snd_high['T_mwr_interpolated'], snd_high['height'],  color='red',     lw=3)
    ax_inset.plot(snd_high['temperature_K'],      snd_high['height'],  color='black',   lw=3)
    
    # Inset åæ ‡è½´è®¾ç½®
    ax_inset.set_xlim(ax.get_xlim())
    ax_inset.set_ylim(3500, 10100)
    ax_inset.set_xlim(230,  290)
    # Inset è½´åˆ»åº¦æ›´å°å³å¯ï¼ˆå…³é—­ minorï¼‰
    ax_inset.xaxis.set_major_locator(MultipleLocator(20))
    #ax_inset.yaxis.set_major_locator(MultipleLocator(2000))
    # éšè—é¡¶éƒ¨å’Œå³ä¾§è¾¹æ¡†
    ax_inset.spines['top' ].set_visible(False)
    ax_inset.spines['right'].set_visible(False)

    # å·¦ / åº•è¾¹æ¡†é¢œè‰² & tick é¢œè‰²ä¸ä¸»å›¾ä¿æŒä¸€è‡´
    ax_inset.spines['left' ].set_color(ax.spines['left' ].get_edgecolor())
    ax_inset.spines['bottom'].set_color(ax.spines['bottom'].get_edgecolor())

    base_color = 'red'            # ä¸ä¸»å›¾ä¸€è‡´
    ax_inset.tick_params(axis='x', which='major',
                         length=8, width=2, labelsize=30,
                         colors=base_color)
    ax_inset.tick_params(axis='y', which='major',
                         length=8, width=2, labelsize=30,
                         colors='black')
    
    # ä»…åœ¨ Inset ä¸Šç»˜åˆ¶é«˜å±‚è™šçº¿é«˜åº¦
    for y in alt_ticks[(alt_ticks >= 3500) & (alt_ticks <= 10000)]:
        ax_inset.axhline(y, color='black', lw=2, ls=(0, (5, 5)), zorder=0)

    # Inset ä¸éœ€è¦è½´æ ‡ç­¾
    ax_inset.set_xlabel('')
    ax_inset.set_ylabel('')
    ax_inset.spines['left'].set_color('red')
    ax_inset.tick_params(axis='y', colors='red')
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” éšè—ç©ºç™½å­å›¾ï¼ˆå¦‚æœæœ‰ï¼‰ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
for j in range(idx + 1, n_rows * n_cols):
    fig.delaxes(axes[j])

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ç»Ÿä¸€çš„å…¨å±€æ ‡ç­¾ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
fig.text(0.01, 0.5, 'Height (m a.g.l.)', rotation=90, va='center', ha='left',
         color='black', weight='bold', fontsize=50)
fig.text(0.995, 0.5, 'Pressure (hPa)',   rotation=270, va='center', ha='right',
         color='black', weight='bold', fontsize=50)

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å…¨å±€å›¾ä¾‹ & æ ‡é¢˜ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
fig.legend(handles=legend_handles,
           loc='upper center', bbox_to_anchor=(0.5, 0.995), ncol=4,
           frameon=False, fontsize=32)
fig.text(0.5, 0.993, 'Temperature Radiosonde Comparison â€“ 1â€¯min Temporal Resolution',
         ha='center', va='bottom', fontsize=40, weight='bold')

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ä¿å­˜é«˜åˆ†è¾¨ç‡ TIF â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
fig.tight_layout(rect=[0, 0, 1, 0.98])   # ç•™å‡ºé¡¶éƒ¨ç©ºé—´
save_path = os.path.join(out_dir, out_fname)
fig.savefig(save_path, dpi=300, format='tif', #transparent=True,
            bbox_inches='tight', pil_kwargs={"compression": "tiff_adobe_deflate"})
print(f"âœ… å·²ä¿å­˜åˆ°ï¼š{save_path}")



###################ç»˜åˆ¶æ¹¿åº¦(æ¢ç©ºæ—¶åˆ»Â±30minå¹³å‡ç‰ˆ-1håˆ†è¾¨ç‡)###################
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import metpy.calc as mpcalc
from metpy.units import units
from matplotlib.ticker import MultipleLocator

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ç”¨æˆ·é…ç½® â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
excel_path   = r"E:\\Beijing2024\\æ¢ç©ºæ•°æ®-54511\\original combined2.xlsx"
sheet_names  = pd.ExcelFile(excel_path).sheet_names           # å…¨éƒ¨æ—¶æ¬¡
out_dir      = r"E:\Beijing2024\å‡ºå›¾TIF"
out_fname    = "RH_Profile_å¹³å‡.tif"
os.makedirs(out_dir, exist_ok=True)
site_elev = 49

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ç»Ÿä¸€çš„ç»˜å›¾é£æ ¼ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
plt.rcParams.update({
    'font.family': 'sans-serif',                # å…ˆæŒ‡å®šå®¶æ—
    'font.sans-serif': ['Arial', 'DejaVu Sans'],     # æŠŠ Arial è®¾ä¸ºé¦–é€‰
    'font.size'      : 36,
    'axes.linewidth' : 3,
    'axes.labelsize' : 36,
    'xtick.labelsize': 36,
    'ytick.labelsize': 36
})

# æ ‡å‡†é«˜åº¦/æ°”å‹åˆ»åº¦
alt_ticks = np.array([0, 500, 1500, 3000, 5000, 8000, 10000, 12500, 15000])   # m
p_ticks   = np.array([1000, 925, 850, 700, 500, 275])                         # hPa
p2alt = lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å»ºç«‹ 4Ã—3 ç”»å¸ƒ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
n_rows, n_cols = 4, 3
fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 40), sharex=False, sharey=False)
axes = axes.ravel()             # æ–¹ä¾¿ç”¨ 1-D ç´¢å¼•
# å›¾ä¾‹ç”¨åˆ°çš„å¥æŸ„ä¸æ ‡ç­¾ (ä¸»å›¾ & inset å…±ç”¨)
legend_handles = [
    plt.Line2D([], [], color='blue',    lw=6, label='ERA5'),
    plt.Line2D([], [], color='magenta', lw=6, label='CRA'),
    plt.Line2D([], [], color='green',   lw=6, label='MWR'),
    plt.Line2D([], [], color='black',   lw=6, label='Radiosonde')
]

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å¾ªç¯æ‰€æœ‰æ—¶æ¬¡ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
for idx, sheet in enumerate(sheet_names):
    if idx >= n_rows * n_cols:            # è¶…å‡º 12 å¼ å­å›¾å°±è·³è¿‡
        break

    ax = axes[idx]

    # 1) è¯»å–æ¢ç©ºè¡¨
    snd = pd.read_excel(excel_path, sheet_name=sheet)

    # 2) å½“å‰ target_timeï¼ˆç”±å·¥ä½œè¡¨åè§£æï¼‰
    target_time = pd.to_datetime(sheet, format='%Y%m%d%H')

    # 3) æŒ‰åŸé€»è¾‘è¿‡æ»¤/å¤„ç† ERA5ã€CRAã€MWR
    era5_profile = ERA5_interp_BJ[ERA5_interp_BJ['valid_time'] == target_time].copy()
    cra_regular['timestamps'] = pd.to_datetime(cra_regular['timestamps'])
    cra_profile = cra_regular[cra_regular['timestamps'] == target_time].copy()
    # å¤„ç†MWRæ•°æ®ï¼šå–æ¢ç©ºæ—¶åˆ»å‰ååŠå°æ—¶å¹³å‡
    start_time = target_time - pd.Timedelta(minutes=30)
    end_time = target_time + pd.Timedelta(minutes=30)
    mwr_filtered = rh_mwr_long.reset_index()  # å°†åŒé‡ç´¢å¼•è½¬æ¢ä¸ºåˆ—
    mask = (mwr_filtered['timestamps'] >= start_time) & (mwr_filtered['timestamps'] <= end_time)
    mwr_filtered = mwr_filtered.loc[mask]
    if not mwr_filtered.empty:
        mwr_avg = mwr_filtered.groupby('height', as_index=False)['RH(%)'].mean()
        mwr_profile = mwr_avg.sort_values('height')
    else:
        print(f"âš ï¸ å½“å‰æ—¶æ¬¡ {target_time.strftime('%Y-%m-%d %H:%M')} çš„ MWR æ•°æ®ä¸å­˜åœ¨")
        mwr_profile = pd.DataFrame(columns=['height', 'RH(%)'])  # ç©ºDataFrameé¿å…æŠ¥é”™
    
    # â€” å•ä½è½¬æ¢ â€”
    era5_profile['height'] = mpcalc.pressure_to_height_std(
        era5_profile['pressure_level'].to_list() * units.hPa
    ).to('m').magnitude - site_elev
    cra_profile['height'] = mpcalc.pressure_to_height_std(
        cra_profile['Level (hPa)'].to_list() * units.hPa
    ).to('m').magnitude - site_elev
    snd['temperature_K'] = snd['temperature_C'] + 273.15
    snd['height'] = mpcalc.pressure_to_height_std(
        snd['pressure_hPa'].to_list() * units.hPa
    ).to('m').magnitude - site_elev

    # â€” æ’åº â€”
    era5_profile = era5_profile.sort_values('height')
    cra_profile  = cra_profile.sort_values('height').iloc[:37]
    snd          = snd.sort_values('height')

    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ç»˜å›¾ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    ax.plot(era5_profile['r'],             era5_profile['height'], color='blue',    lw=3)
    ax.plot(cra_profile['rh (%)'],         cra_profile['height'],  color='magenta', lw=3)
    ax.plot(mwr_profile['RH(%)'],          mwr_profile['height'],  color='green',   lw=3)
    ax.plot(snd['relative humidity_%'],    snd['height'],          color='black',   lw=3)
    
    # â€” å·¦å³åŒè½´ â€”
    secax = ax.secondary_yaxis(
        'right',
        functions=(
            lambda h: mpcalc.height_to_pressure_std(h * units.m).to('hPa').magnitude,
            lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude
        )
    )
    secax.set_ylim(1000, 275)
    ax.set_ylim(0, 10000)
    ax.set_xlim(-2, 103)
    ax.xaxis.set_major_locator(MultipleLocator(10))
    ax.xaxis.set_minor_locator(MultipleLocator(5))
    ax.tick_params(axis='x', colors='green', length=12,width=2) 
    ax.tick_params(axis='x', which='minor', length=6, width=2,color='green')
    ax.set_yticks(alt_ticks)  # è®¾ç½®å·¦ä¾§ä¸»åˆ»åº¦
    secax.tick_params(axis='y', colors='blue', length=12, width=2,labelcolor='blue')
    secax.set_yticks(p_ticks)   # è®¾ç½®å³ä¾§ä¸»åˆ»åº¦
    ax.set_ylim(0, 10000) 
    # ax.xaxis.set_major_locator(MultipleLocator(10))
    # ax.xaxis.set_minor_locator(MultipleLocator(5))
    # ax.tick_params(axis='x',which='minor',length=6,width=2,color='black')
    #plt.tick_params(axis='x', length=12, width=2)
    #ax.set_xlim(240, 310)
    

    # â€” è™šçº¿å‚è€ƒé«˜åº¦/æ°”å‹ â€”
    for y in alt_ticks:
        ax.axhline(y, color='red',   lw=2, ls=(0, (5, 10)), zorder=0)
    for p in p_ticks:
        ax.axhline(p2alt(p), color='blue', lw=2, ls=(0, (5, 10)), zorder=0)

    # â€”â€”â€”â€”â€”â€”â€”â€” è½´åˆ»åº¦ã€æ ‡ç­¾ç®¡ç† â€”â€”â€”â€”â€”â€”â€”â€”
    col = idx % n_cols
    row = idx // n_cols

    # y-è½´ & sec-y é¢œè‰²
    ax.spines['left' ].set_color('red')
    ax.spines['right'].set_color('black')
    ax.spines['bottom'].set_color('green')
    ax.tick_params(axis='y', colors='red', length=12, width=2)
    #secax.tick_params(axis='y', colors='black', length=12, width=2)

    # ä»…ä¿ç•™å·¦/å³è¾¹ & æœ€åº•è¡Œçš„è½´æ ‡ç­¾
    if col == 0:                # æœ€å·¦åˆ— â†’ é«˜åº¦æ ‡ç­¾
        ax.set_ylabel(' ', color='red')
    else:
        ax.set_ylabel('')
        ax.tick_params(axis='y', labelleft=False)

    if col == n_cols - 1:       # æœ€å³åˆ— â†’ Pressure æ ‡ç­¾
        secax.set_ylabel(' ', color='blue', rotation=270, labelpad=20)
    else:
        secax.set_ylabel('')
        secax.tick_params(axis='y', labelright=False)

    if row == n_rows - 1:       # æœ€åº•è¡Œ â†’ Temperature æ ‡ç­¾
        #ax.set_xlabel('Temperature (K)')
        ax.xaxis.set_major_locator(MultipleLocator(10))
        ax.xaxis.set_minor_locator(MultipleLocator(5))
        ax.tick_params(axis='x', which='major', length=12, width=2)
        ax.tick_params(axis='x', which='minor', length=6, width=2,color='green')
    else:
        ax.set_xlabel('')
        ax.tick_params(axis='x', labelbottom=False)
    if row == 3 and col == 1:
        ax.set_xlabel('Relative Humidity(%)',fontsize=50,weight='bold',color='green')
    # â€” å­å›¾æ ‡é¢˜ â€”
    ax.set_title(target_time.strftime('%Y-%m-%d %H:%M (BJT)'), pad=12, fontsize=36,weight='bold')

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” éšè—ç©ºç™½å­å›¾ï¼ˆå¦‚æœæœ‰ï¼‰ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

for j in range(idx + 1, n_rows * n_cols):
    fig.delaxes(axes[j])
fig.text(0.01, 0.5, 'Height (m a.g.l.)', 
        rotation=90, va='center', ha='left',
        color='black', weight='bold',fontsize=50)
fig.text(0.995, 0.5, 'Pressure (hPa)', 
        rotation=270, va='center', ha='right',
        color='black', weight='bold',fontsize=50)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ä¿å­˜é«˜åˆ†è¾¨ç‡ TIF â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
### â† æ–°å¢ï¼šå…¨å±€å›¾ä¾‹ï¼ˆæ”¾åœ¨é¡¶éƒ¨ï¼‰ ###
fig.legend(handles=legend_handles,
           loc='upper center', bbox_to_anchor=(0.5, 0.995), ncol=4,
           frameon=False, fontsize=32)
fig.text(0.5, 0.993, 'Relative Humidity Radiosonde Comparison â€“ 1h Temporal Resolution',
         ha='center', va='bottom', fontsize=40, weight='bold')

fig.tight_layout(rect=[0, 0, 1, 0.98])   # ç•™å‡ºé¡¶éƒ¨ç©ºé—´
save_path = os.path.join(out_dir, out_fname)
fig.savefig(save_path, dpi=300, transparent=True,pil_kwargs={"compression": "tiff_adobe_deflate"},
            format='tif', bbox_inches='tight')
print(f"âœ… å·²ä¿å­˜åˆ°ï¼š{save_path}")


###################ç»˜åˆ¶æ¹¿åº¦(æ¢ç©ºåŒ¹é…ç‰ˆ)-1min###################
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import metpy.calc as mpcalc
from metpy.units import units
from matplotlib.ticker import MultipleLocator
from scipy.interpolate import interpn

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ç”¨æˆ·é…ç½® â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
excel_path   = r"E:\\Beijing2024\\æ¢ç©ºæ•°æ®-54511\\original combined2.xlsx"
sheet_names  = pd.ExcelFile(excel_path).sheet_names           # å…¨éƒ¨æ—¶æ¬¡
out_dir      = r"E:\Beijing2024\å‡ºå›¾TIF"
out_fname    = "RH_Profile_MWRåŒ¹é…æ¢ç©º.tif"
os.makedirs(out_dir, exist_ok=True)
site_elev = Altitude

# æå– rh_mwr_long çš„ç½‘æ ¼ç‚¹ï¼ˆæ—¶é—´æˆ³å’Œé«˜åº¦ï¼‰
time_points = rh_mwr_long.index.get_level_values('timestamps').unique().sort_values()
height_points = rh_mwr_long.index.get_level_values('height').unique().sort_values()

# å°†æ—¶é—´è½¬æ¢ä¸ºæ•°å€¼ï¼ˆä¾‹å¦‚ç›¸å¯¹äºæŸä¸ªåŸºå‡†æ—¶é—´çš„ç§’æ•°ï¼‰
time_numeric = (time_points - pd.Timestamp("1970-01-01")) // pd.Timedelta('1s')

# æå– rh_mwr_long çš„æ¸©åº¦æ•°æ®å¹¶é‡å¡‘ä¸ºäºŒç»´ç½‘æ ¼
values_grid = rh_mwr_long.unstack().values  # å½¢çŠ¶ä¸º (len(time_points), len(height_points))

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ç»Ÿä¸€çš„ç»˜å›¾é£æ ¼ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
plt.rcParams.update({
    'font.family': 'sans-serif',                # å…ˆæŒ‡å®šå®¶æ—
    'font.sans-serif': ['Arial', 'DejaVu Sans'],     # æŠŠ Arial è®¾ä¸ºé¦–é€‰
    'font.size'      : 36,
    'axes.linewidth' : 3,
    'axes.labelsize' : 36,
    'xtick.labelsize': 36,
    'ytick.labelsize': 36
})

# æ ‡å‡†é«˜åº¦/æ°”å‹åˆ»åº¦
alt_ticks = np.array([0, 500, 2000, 3000, 5000, 8000, 10000, 12500, 15000])   # m
p_ticks   = np.array([1000, 925, 850, 700, 500, 275])                         # hPa
p2alt = lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude
legend_handles = [
    #plt.Line2D([], [], color='blue',    lw=6, label='ERA5'),
    #plt.Line2D([], [], color='magenta', lw=6, label='CRA'),
    plt.Line2D([], [], color='green',     lw=6, label='MWR'),
    plt.Line2D([], [], color='black',   lw=6, label='Radiosonde')
]

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å»ºç«‹ 4Ã—3 ç”»å¸ƒ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
n_rows, n_cols = 4, 3
fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 40), sharex=False, sharey=False)
axes = axes.ravel()             # æ–¹ä¾¿ç”¨ 1-D ç´¢å¼•

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” å¾ªç¯æ‰€æœ‰æ—¶æ¬¡ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
for idx, sheet in enumerate(sheet_names):
    if idx >= n_rows * n_cols:            # è¶…å‡º 12 å¼ å­å›¾å°±è·³è¿‡
        break

    ax = axes[idx]

    # 1) è¯»å–æ¢ç©ºè¡¨
    snd = pd.read_excel(excel_path, sheet_name=sheet)

    # 2) å½“å‰ target_timeï¼ˆç”±å·¥ä½œè¡¨åè§£æï¼‰
    target_time = pd.to_datetime(sheet, format='%Y%m%d%H')

    # 3) æŒ‰åŸé€»è¾‘è¿‡æ»¤/å¤„ç† ERA5ã€CRAã€MWR
    era5_profile = ERA5_interp_BJ[ERA5_interp_BJ['valid_time'] == target_time].copy()
    cra_regular['timestamps'] = pd.to_datetime(cra_regular['timestamps'])
    cra_profile = cra_regular[cra_regular['timestamps'] == target_time].copy()
    # åˆ¤æ–­å½“å‰æ—¶æ¬¡æ˜¯å¦å­˜åœ¨MWRæ•°æ®
    if target_time not in time_points:
        # è‹¥ä¸å­˜åœ¨ï¼Œå¡«å……NaNå¹¶è·³è¿‡æ’å€¼
        interpolated_rh = np.full(snd.shape[0], np.nan)
    else:
    # ä» snd ä¸­æå–ç›®æ ‡æ’å€¼ç‚¹çš„æ—¶é—´å’Œé«˜åº¦
        snd['time'] = pd.to_datetime(snd['time'])
    
        snd_time_numeric = (snd['time'] - pd.Timestamp("1970-01-01")) // pd.Timedelta('1s')
        snd_height = snd['pressure_hPa'].apply(
            lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude - site_elev
        )
    
        # æ„å»ºæ’å€¼ç›®æ ‡ç‚¹åæ ‡ (æ—¶é—´, é«˜åº¦)
        xi = np.array([snd_time_numeric, snd_height]).T
    
        # æ‰§è¡Œçº¿æ€§æ’å€¼ï¼ˆæ—¶é—´å’Œé«˜åº¦ç»´åº¦ï¼‰
        interpolated_rh = interpn(
            points=(time_numeric, height_points),
            values=values_grid,
            xi=xi,
            method='linear',
            bounds_error=False,  # å…è®¸å¤–æ¨
            fill_value=np.nan     # è¶…å‡ºèŒƒå›´å¡«å……ä¸ºNaN
        )
    
        # å°†æ’å€¼ç»“æœæ·»åŠ åˆ° snd æ•°æ®ä¸­
    snd['rh_mwr_interpolated'] = interpolated_rh

    # ç”Ÿæˆæ’å€¼åæ•°æ®æ¡†
    mwr_profile = snd['rh_mwr_interpolated']

    # â€” å•ä½è½¬æ¢ â€”
    era5_profile['height'] = mpcalc.pressure_to_height_std(
        era5_profile['pressure_level'].to_list() * units.hPa
    ).to('m').magnitude - site_elev
    cra_profile['height'] = mpcalc.pressure_to_height_std(
        cra_profile['Level (hPa)'].to_list() * units.hPa
    ).to('m').magnitude - site_elev
    snd['temperature_K'] = snd['temperature_C'] + 273.15
    snd['height'] = mpcalc.pressure_to_height_std(
        snd['pressure_hPa'].to_list() * units.hPa
    ).to('m').magnitude - site_elev

    # â€” æ’åº â€”
    era5_profile = era5_profile.sort_values('height')
    cra_profile  = cra_profile.sort_values('height').iloc[:37]
    snd          = snd.sort_values('height')

    # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ç»˜å›¾ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    #ax.plot(era5_profile['r'],         era5_profile['height'],color='blue',    lw=3)
    #ax.plot(cra_profile['rh (%)'],   cra_profile['height'], color='magenta',     lw=3)
    ax.plot(snd['rh_mwr_interpolated'], snd['height'],         color='green', lw=3)
    ax.plot(snd['relative humidity_%'],      snd['height'],         color='black',   lw=3)
    
    # â€” å·¦å³åŒè½´ â€”
    secax = ax.secondary_yaxis(
        'right',
        functions=(
            lambda h: mpcalc.height_to_pressure_std(h * units.m).to('hPa').magnitude,
            lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude
        )
    )
    secax.set_ylim(1000, 275)
    ax.set_ylim(0, 10000)
    ax.set_xlim(-2, 103)
    ax.xaxis.set_major_locator(MultipleLocator(10))
    ax.xaxis.set_minor_locator(MultipleLocator(5))
    ax.tick_params(axis='x', colors='green', length=12,width=2) 
    ax.tick_params(axis='x', which='minor', length=6, width=2,color='green')
    ax.set_yticks(alt_ticks)  # è®¾ç½®å·¦ä¾§ä¸»åˆ»åº¦
    secax.tick_params(axis='y', colors='blue', length=12, width=2,labelcolor='blue')
    secax.set_yticks(p_ticks)   # è®¾ç½®å³ä¾§ä¸»åˆ»åº¦
    ax.set_ylim(0, 10000) 

    # â€” è™šçº¿å‚è€ƒé«˜åº¦/æ°”å‹ â€”
    for y in alt_ticks:
        ax.axhline(y, color='red',   lw=2, ls=(0, (5, 10)), zorder=0)
    for p in p_ticks:
        ax.axhline(p2alt(p), color='blue', lw=2, ls=(0, (5, 10)), zorder=0)

    # â€”â€”â€”â€”â€”â€”â€”â€” è½´åˆ»åº¦ã€æ ‡ç­¾ç®¡ç† â€”â€”â€”â€”â€”â€”â€”â€”
    col = idx % n_cols
    row = idx // n_cols

    # y-è½´ & sec-y é¢œè‰²
    ax.spines['left' ].set_color('red')
    ax.spines['right'].set_color('black')
    ax.spines['bottom'].set_color('green')
    ax.tick_params(axis='y', colors='red', length=12, width=2)

    # ä»…ä¿ç•™å·¦/å³è¾¹ & æœ€åº•è¡Œçš„è½´æ ‡ç­¾
    if col == 0:                # æœ€å·¦åˆ— â†’ é«˜åº¦æ ‡ç­¾
        ax.set_ylabel(' ', color='red')
    else:
        ax.set_ylabel('')
        ax.tick_params(axis='y', labelleft=False)

    if col == n_cols - 1:       # æœ€å³åˆ— â†’ Pressure æ ‡ç­¾
        secax.set_ylabel(' ', color='blue', rotation=270, labelpad=20)
    else:
        secax.set_ylabel('')
        secax.tick_params(axis='y', labelright=False)

    if row == n_rows - 1:       # æœ€åº•è¡Œ â†’ Temperature æ ‡ç­¾
        ax.xaxis.set_major_locator(MultipleLocator(10))
        ax.xaxis.set_minor_locator(MultipleLocator(5))
        ax.tick_params(axis='x', which='major', length=12, width=2)
        ax.tick_params(axis='x', which='minor', length=6, width=2,color='green')
    else:
        ax.set_xlabel('')
        ax.tick_params(axis='x', labelbottom=False)
    if row == 3 and col == 1:
        ax.set_xlabel('Relative Humidity(%)',fontsize=50,weight='bold',color='green')
    # â€” å­å›¾æ ‡é¢˜ â€”
    ax.set_title(target_time.strftime('%Y-%m-%d %H:%M (BJT)'), pad=12, fontsize=36,weight='bold')

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” éšè—ç©ºç™½å­å›¾ï¼ˆå¦‚æœæœ‰ï¼‰ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

for j in range(idx + 1, n_rows * n_cols):
    fig.delaxes(axes[j])
fig.text(0.01, 0.5, 'Height (m a.g.l.)', 
        rotation=90, va='center', ha='left',
        color='black', weight='bold',fontsize=50)
fig.text(0.995, 0.5, 'Pressure (hPa)', 
        rotation=270, va='center', ha='right',
        color='black', weight='bold',fontsize=50)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” ä¿å­˜é«˜åˆ†è¾¨ç‡ TIF â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
### â† æ–°å¢ï¼šå…¨å±€å›¾ä¾‹ï¼ˆæ”¾åœ¨é¡¶éƒ¨ï¼‰ ###
fig.legend(handles=legend_handles,
           loc='upper center', bbox_to_anchor=(0.5, 0.995), ncol=4,
           frameon=False, fontsize=32)
fig.text(0.5, 0.993, 'Relative Humidity Radiosonde Comparison â€“ 1min Temporal Resolution',
         ha='center', va='bottom', fontsize=40, weight='bold')

fig.tight_layout(rect=[0, 0, 1, 0.98])   # ç•™å‡ºé¡¶éƒ¨ç©ºé—´
save_path = os.path.join(out_dir, out_fname)
fig.savefig(save_path, dpi=300, transparent=True,pil_kwargs={"compression": "tiff_adobe_deflate"},
            format='tif', bbox_inches='tight')
print(f"âœ… å·²ä¿å­˜åˆ°ï¼š{save_path}")



############################# Horizontal Wind Speed Profiles â€“ 1â€¯h #############################
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import metpy.calc as mpcalc
from metpy.units import units
from matplotlib.ticker import MultipleLocator
from mpl_toolkits.axes_grid1.inset_locator import inset_axes

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ USER CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
excel_path   = r"E:\\Beijing2024\\æ¢ç©ºæ•°æ®-54511\\original combined2.xlsx"
out_dir      = r"E:\\Beijing2024\\å‡ºå›¾TIF"
out_fname    = "wind_Profile-1h_with_inset.tif"
os.makedirs(out_dir, exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PLOT STYLE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
plt.rcParams.update({
    'font.family'   : 'sans-serif',
    'font.sans-serif': ['Arial', 'DejaVu Sans'],
    'font.size'      : 36,
    'axes.linewidth' : 3,
    'axes.labelsize' : 36,
    'xtick.labelsize': 36,
    'ytick.labelsize': 36
})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Standard altitude / pressure ticks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
alt_ticks = np.array([0, 500, 1000, 1500, 2000, 2500, 3000, 4000, 6000, 8000, 10000])  #Â m
p_ticks   = np.array([1000, 925, 850, 800, 750, 700, 500, 275])                                  #Â hPa
p2alt = lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helper: extract DWL profile â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _get_profile_from_series_dict(dic, timestamp):
    """Return a DataFrame of Dopplerâ€‘Lidar HWS for the given *timestamp*.
    The user must ensure the dictionary structure matches the assumed format.
    Expected layout: dic['HWS'][height]['Doppler'] (or similar) is a Series
    indexed by timestamps. Adjust if necessary.
    """
    # Build list of (height, value) pairs
    data = []
    for h, sources in dic['HWS'].items():
        #Â ---- adapt key name 'Doppler' to match your actual inner key ----
        s = sources.get('Doppler', None)  # replace 'Doppler' if needed
        if s is None or timestamp not in s.index:
            continue
        data.append((h, s.loc[timestamp]))
    prof = pd.DataFrame(data, columns=['height', 'hws']).sort_values('height')
    return prof

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Figure grid â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from pandas import ExcelFile
sheet_names = ExcelFile(excel_path).sheet_names         #Â 12 timeâ€‘stamps max
n_rows, n_cols = 4, 3
fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 40), sharex=False, sharey=False)
axes = axes.ravel()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ—¶é—´åˆ—å…ˆæ ‡å‡†åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€
cleaned_h['BJT'] = pd.to_datetime(cleaned_h['BJT'])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 60 min é‡é‡‡æ ·ï¼ˆæŒ‰ height åˆ†ç»„ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€
cleaned_h_60min = (
    cleaned_h
    .groupby(
        ['height',                     # â† åˆ†é«˜åº¦
         pd.Grouper(key='BJT', freq='60min')]   # â† å¯¹æ—¶é—´åˆ—åš 60 min åˆ†ç®±
    , as_index=False)                 # ä¿æŒåˆ—å½¢å¼ï¼Œé¿å…æˆä¸ºç´¢å¼•
    .mean(numeric_only=True)          # ä½ åªå…³å¿ƒæ•°å€¼åˆ—ï¼Œè¿™æ ·æ›´å¿«
    
)

Subplot_yaxis=2500

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Main loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for idx, sheet in enumerate(sheet_names):
    if idx >= n_rows * n_cols:  # safety guard
        break
    ax = axes[idx]

    # ----â€†1)Â Read radiosonde table (sheetâ€‘wise) --------------------------------
    snd = pd.read_excel(excel_path, sheet_name=sheet)

    # ----â€†2) current timestamp -------------------------------------------------
    target_time = pd.to_datetime(sheet, format='%Y%m%d%H')

    # ----â€†3)Â ERA5, CRA profiles (prepared upstream) ---------------------------
    era5_profile = ERA5_interp_BJ.loc[ERA5_interp_BJ['valid_time'] == target_time].copy()
    cra_profile  = cra_regular.loc[pd.to_datetime(cra_regular['timestamps']) == target_time].copy()

    # ----â€†4)Â Doppler Windâ€‘Lidar profile from series_dict_60min -----------------
    dwl_profile = (
            cleaned_h_60min[cleaned_h_60min['BJT'] == target_time]   # å–å½“å‰æ•´ç‚¹
            .loc[:, ['height', 'hws']]
            .sort_values('height')
        )

    # ----â€†5)Â Unit conversion ---------------------------------------------------
    era5_profile['height'] = mpcalc.pressure_to_height_std(
        era5_profile['pressure_level'].to_numpy() * units.hPa).to('m').magnitude
    cra_profile['height'] = mpcalc.pressure_to_height_std(
        cra_profile['Level (hPa)'].to_numpy() * units.hPa).to('m').magnitude
    snd['height'] = mpcalc.pressure_to_height_std(
        snd['pressure_hPa'].to_numpy() * units.hPa).to('m').magnitude

    # rename radiosonde windâ€‘speed column if needed
    if 'wind speed_m/s' in snd.columns:
        snd.rename(columns={'wind speed_m/s': 'hws'}, inplace=True)
    else:
        snd.rename(columns={snd.filter(like='wind').columns[0]: 'hws'}, inplace=True)

    # ERA5 / CRA windâ€‘speed columns may differ; harmonise to 'hws'
    era5_profile.rename(columns={era5_profile.filter(like='hws').columns[0]: 'hws'}, inplace=True)
    cra_profile.rename(columns={cra_profile.filter(like='hws').columns[0]: 'hws'}, inplace=True)

    # Keep only needed columns; sort by height
    era5_profile = era5_profile[['height', 'hws']].sort_values('height')
    cra_profile  = cra_profile[['height', 'hws']].sort_values('height').iloc[:37]
    snd          = snd[['height', 'hws']].sort_values('height')
    dwl_profile  = dwl_profile.sort_values('height')

    # ---------------------------- PLOT MAIN AXIS -----------------------------
    ax.plot(era5_profile['hws'], era5_profile['height'], color='blue',    lw=3)
    ax.plot(cra_profile['hws'],  cra_profile['height'],  color='magenta', lw=3)
    ax.plot(dwl_profile['hws'], dwl_profile['height'], color='darkorange',      lw=3)
    ax.plot(snd['hws'],         snd['height'],         color='black',    lw=3)

    # ---- dual yâ€‘axis (height â†” pressure) -------------------------------------
    secax = ax.secondary_yaxis(
        'right',
        functions=(
            lambda h: mpcalc.height_to_pressure_std(h * units.m).to('hPa').magnitude,
            lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude
        )
    )

    ax.set_xlim(0, 40)
    alt_ticks_plot = alt_ticks[alt_ticks >= Subplot_yaxis]
    ax.set_yticks(alt_ticks)
    p_ticks_plot = [p for p in p_ticks if p2alt(p) >= Subplot_yaxis]
    secax.set_yticks(p_ticks)
    # main & secondary limits
    ax.set_ylim(0, Subplot_yaxis)
    # xâ€‘ticks formatting (orange)
    ax.xaxis.set_major_locator(MultipleLocator(5))
    ax.tick_params(axis='x', which='major', length=12, width=2, colors='darkorange')
    ax.tick_params(axis='x', which='minor', length=6, width=2, colors='darkorange')

    # spine colours
    ax.spines['left' ].set_color('red')
    ax.spines['bottom'].set_color('darkorange')
    ax.spines['right'].set_color('black')
    ax.tick_params(axis='y', colors='red', length=12, width=2)
    secax.tick_params(axis='y', colors='blue', length=12, width=2)

    # ---- dashed reference lines (unchanged) ----------------------------------
    for y in alt_ticks:
        ax.axhline(y, color='red',   lw=2, ls=(0, (5, 10)), zorder=0)
    for p in p_ticks:
        ax.axhline(p2alt(p), color='blue',  lw=2, ls=(0, (5, 10)), zorder=0)

    # --------------------------- INSET AXIS ----------------------------------
    ax_in = inset_axes(ax, width="31%", height="48%", loc='upper right',
                       borderpad=1)
    ax_inset.set_facecolor('white')         # ç”¨ç™½è‰²æŠŠä¸»å›¾çº¿æ¡é®æ‰
    ax_inset.patch.set_alpha(1)             # ä¿è¯ä¸é€æ˜
    ax_inset.patch.set_zorder(2) 

    # plot same datasets, restricted to <Â 500â€¯m
    ax_in.plot(era5_profile.loc[era5_profile['height'] >= Subplot_yaxis, 'hws'],
               era5_profile.loc[era5_profile['height'] >= Subplot_yaxis, 'height'],
               color='blue',   lw=3)
    ax_in.plot(cra_profile.loc[cra_profile['height'] >= Subplot_yaxis, 'hws'],
               cra_profile.loc[cra_profile['height'] >= Subplot_yaxis, 'height'],
               color='magenta', lw=3)
    ax_in.plot(dwl_profile.loc[dwl_profile['height'] >= Subplot_yaxis, 'hws'],
               dwl_profile.loc[dwl_profile['height'] >= Subplot_yaxis, 'height'],
               color='red',    lw=3)
    ax_in.plot(snd.loc[snd['height'] >= Subplot_yaxis, 'hws'],
               snd.loc[snd['height'] >= Subplot_yaxis, 'height'],
               color='black',  lw=3)

    # inset axis limits & ticks
    ax_in.set_ylim(Subplot_yaxis, 10010)
    ax_in.set_xlim(0, 45)
    # >>> å¼ºåˆ¶åœ¨ y è½´æœ€åº•éƒ¨æ˜¾ç¤º Subplot_yaxis è¿™ä¸€ä¸ªåˆ»åº¦ <<<
    y_ticks_inset = np.concatenate([[Subplot_yaxis],
                                    alt_ticks[(alt_ticks > Subplot_yaxis) &
                                              (alt_ticks >= 4000)]])
    ax_in.set_yticks(y_ticks_inset)
    ax_in.tick_params(axis='both', which='major', length=8, width=2, labelsize=30)
    ax_in.tick_params(axis='both', which='minor', length=4, width=2)

    # inset spines styling
    ax_in.spines['top'   ].set_visible(False)
    ax_in.spines['right' ].set_visible(False)
    ax_in.spines['left'  ].set_color('red')
    ax_in.spines['bottom'].set_color('darkorange')
    ax_in.tick_params(axis='y', colors='red')
    ax_in.tick_params(axis='x', colors='darkorange')
    ax_in.xaxis.set_major_locator(MultipleLocator(10))

    # -------------------- subplotâ€‘specific labels / title --------------------
    col = idx % n_cols
    row = idx // n_cols
    center_col = n_cols // 2 
    if col == 0:
        ax.set_ylabel('')  # we move global yâ€‘label outside fig
    else:
        ax.tick_params(axis='y', labelleft=False)
    if col == n_cols - 1:
        secax.set_ylabel('')  # rightâ€‘side label moved to global text
    else:
        secax.tick_params(axis='y', labelright=False)

    if row == n_rows - 1:                       # åº•è¡Œ
        ax.tick_params(axis='x', labelbottom=True)   # åˆ»åº¦æ•°å­—ä¿ç•™
        
        if col == center_col:                   # åªæœ‰ä¸­é—´é‚£æ ¼è¦ xlabel
            ax.set_xlabel('Horizontal Wind Speed (m/s)',
                      fontsize=50, weight='bold', color='darkorange',
                      labelpad=20)
    else:                                       # å…¶ä½™è¡Œ
        ax.tick_params(axis='x', labelbottom=False)  # åˆ»åº¦æ•°å­—éšè—

    # panel title
    ax.set_title(target_time.strftime('%Y-%m-%d %H:%M (BJT)'), pad=12, fontsize=36,weight='bold')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Hide any empty subâ€‘axes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for j in range(idx + 1, n_rows * n_cols):
    fig.delaxes(axes[j])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Global axesâ€‘level annotations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fig.text(-0.01, 0.5, 'Height (m a.g.l.)', rotation=90, va='center', ha='left',
         color='black', weight='bold', fontsize=50)
fig.text(1.01, 0.5, 'Pressure (hPa)', rotation=270, va='center', ha='right',
         color='black', weight='bold', fontsize=50)

# Legend & title (top)
legend_handles = [
    plt.Line2D([], [], color='blue',      lw=6, label='ERA5'),
    plt.Line2D([], [], color='magenta',   lw=6, label='CRA'),
    plt.Line2D([], [], color='darkorange',lw=6, label='Doppler Wind Lidar'),
    plt.Line2D([], [], color='black',     lw=6, label='Radiosonde')
]
fig.legend(handles=legend_handles, loc='upper center', bbox_to_anchor=(0.5, 0.995),
           ncol=4, frameon=False, fontsize=32)
fig.text(0.5, 0.993, 'Horizontal Wind Speed Radiosonde Comparison â€“ 1h Temporal Resolution',
         ha='center', va='bottom', fontsize=40, weight='bold')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Save figure (no transparency) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fig.tight_layout(rect=[0, 0, 1, 0.985])
save_path = os.path.join(out_dir, out_fname)
fig.savefig(save_path, dpi=300, pil_kwargs={"compression": "tiff_adobe_deflate"},
            format='tif', bbox_inches='tight')
print(f"âœ… Figure saved to: {save_path}")




import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import metpy.calc as mpcalc
from metpy.units import units
from matplotlib.ticker import MultipleLocator
from mpl_toolkits.axes_grid1.inset_locator import inset_axes

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ USER CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
excel_path   = r"E:\\Beijing2024\\æ¢ç©ºæ•°æ®-54511\\original combined2.xlsx"
out_dir      = r"E:\\Beijing2024\\å‡ºå›¾TIF"
out_fname    = "wind_Profile-5min_with_inset.tif"
os.makedirs(out_dir, exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PLOT STYLE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
plt.rcParams.update({
    'font.family'   : 'sans-serif',
    'font.sans-serif': ['Arial', 'DejaVu Sans'],
    'font.size'      : 36,
    'axes.linewidth' : 3,
    'axes.labelsize' : 36,
    'xtick.labelsize': 36,
    'ytick.labelsize': 36
})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Standard altitude / pressure ticks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
alt_ticks = np.array([0, 500, 1000, 1500, 2000, 2500, 3000, 4000, 6000, 8000, 10000])  #Â m
p_ticks   = np.array([1000, 925, 850, 800, 750, 700, 500, 275])                                    #Â hPa
p2alt = lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude




# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Figure grid â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from pandas import ExcelFile
sheet_names = ExcelFile(excel_path).sheet_names         #Â 12 timeâ€‘stamps max
n_rows, n_cols = 4, 3
fig, axes = plt.subplots(n_rows, n_cols, figsize=(30, 40), sharex=False, sharey=False)
axes = axes.ravel()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ—¶é—´åˆ—å…ˆæ ‡å‡†åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€
cleaned_h['BJT'] = pd.to_datetime(cleaned_h['BJT'])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 60 min é‡é‡‡æ ·ï¼ˆæŒ‰ height åˆ†ç»„ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€
cleaned_h_5min = (
    cleaned_h
    .groupby(
        ['height',                     # â† åˆ†é«˜åº¦
         pd.Grouper(key='BJT', freq='5min')]   # â† å¯¹æ—¶é—´åˆ—åš 60 min åˆ†ç®±
    , as_index=False)                 # ä¿æŒåˆ—å½¢å¼ï¼Œé¿å…æˆä¸ºç´¢å¼•
    .mean(numeric_only=True)          # ä½ åªå…³å¿ƒæ•°å€¼åˆ—ï¼Œè¿™æ ·æ›´å¿«
    #.dropna(subset=['hws'])           # å¯é€‰ï¼šå»æ‰ hws ç¼ºæµ‹è¡Œ
)

Subplot_yaxis=2500

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Main loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for idx, sheet in enumerate(sheet_names):
    if idx >= n_rows * n_cols:  # safety guard
        break
    ax = axes[idx]

    # ----â€†1)Â Read radiosonde table (sheetâ€‘wise) --------------------------------
    snd = pd.read_excel(excel_path, sheet_name=sheet)

    # ----â€†2) current timestamp -------------------------------------------------
    target_time = pd.to_datetime(sheet, format='%Y%m%d%H')

    # ----â€†3)Â ERA5, CRA profiles (peared upstream) ---------------------------
    era5_profile = ERA5_interp_BJ.loc[ERA5_interp_BJ['valid_time'] == target_time].copy()
    cra_profile  = cra_regular.loc[pd.to_datetime(cra_regular['timestamps']) == target_time].copy()

    # ----â€†4)Â Doppler Windâ€‘Lidar profile from series_dict_60min -----------------
    dwl_profile = (
            cleaned_h_5min[cleaned_h_5min['BJT'] == target_time]   # å–å½“å‰æ•´ç‚¹
            .loc[:, ['height', 'hws']]
            .sort_values('height')
        )

    # ----â€†5)Â Unit conversion ---------------------------------------------------
    era5_profile['height'] = mpcalc.pressure_to_height_std(
        era5_profile['pressure_level'].to_numpy() * units.hPa).to('m').magnitude
    cra_profile['height'] = mpcalc.pressure_to_height_std(
        cra_profile['Level (hPa)'].to_numpy() * units.hPa).to('m').magnitude
    snd['height'] = mpcalc.pressure_to_height_std(
        snd['pressure_hPa'].to_numpy() * units.hPa).to('m').magnitude

    # rename radiosonde windâ€‘speed column if needed
    if 'wind speed_m/s' in snd.columns:
        snd.rename(columns={'wind speed_m/s': 'hws'}, inplace=True)
    else:
        snd.rename(columns={snd.filter(like='wind').columns[0]: 'hws'}, inplace=True)

    # ERA5 / CRA windâ€‘speed columns may differ; harmonise to 'hws'
    era5_profile.rename(columns={era5_profile.filter(like='hws').columns[0]: 'hws'}, inplace=True)
    cra_profile.rename(columns={cra_profile.filter(like='hws').columns[0]: 'hws'}, inplace=True)

    # Keep only needed columns; sort by height
    era5_profile = era5_profile[['height', 'hws']].sort_values('height')
    cra_profile  = cra_profile[['height', 'hws']].sort_values('height').iloc[:37]
    snd          = snd[['height', 'hws']].sort_values('height')
    dwl_profile  = dwl_profile.sort_values('height')

    # ---------------------------- PLOT MAIN AXIS -----------------------------
    #ax.plot(era5_profile['hws'], era5_profile['height'], color='blue',    lw=3)
    #ax.plot(cra_profile['hws'],  cra_profile['height'],  color='magenta', lw=3)
    ax.plot(dwl_profile['hws'], dwl_profile['height'], color='darkorange',      lw=3)
    ax.plot(snd['hws'],         snd['height'],         color='black',    lw=3)

    # ---- dual yâ€‘axis (height â†” pressure) -------------------------------------
    secax = ax.secondary_yaxis(
        'right',
        functions=(
            lambda h: mpcalc.height_to_pressure_std(h * units.m).to('hPa').magnitude,
            lambda p: mpcalc.pressure_to_height_std(p * units.hPa).to('m').magnitude
        )
    )

    ax.set_xlim(0, 40)
    
    alt_ticks_plot = alt_ticks[alt_ticks >= Subplot_yaxis]
    ax.set_yticks(alt_ticks)
    
    p_ticks_plot = [p for p in p_ticks if p2alt(p) >= Subplot_yaxis]
    secax.set_yticks(p_ticks)
    
    ax.set_ylim(0, Subplot_yaxis)
    ax.xaxis.set_major_locator(MultipleLocator(5))
    ax.tick_params(axis='x', which='major', length=12, width=2, colors='darkorange')
    ax.tick_params(axis='x', which='minor', length=6, width=2, colors='darkorange')

    # spine colours
    ax.spines['left' ].set_color('red')
    ax.spines['bottom'].set_color('darkorange')
    ax.spines['right'].set_color('black')
    ax.tick_params(axis='y', colors='red', length=12, width=2)
    secax.tick_params(axis='y', colors='blue', length=12, width=2)

    # ---- dashed reference lines (unchanged) ----------------------------------
    for y in alt_ticks:
        ax.axhline(y, color='red',   lw=2, ls=(0, (5, 10)), zorder=0)
    for p in p_ticks:
        ax.axhline(p2alt(p), color='blue',  lw=2, ls=(0, (5, 10)), zorder=0)

    # # --------------------------- INSET AXIS ----------------------------------
    # ax_in = inset_axes(ax, width="31%", height="48%", loc='upper right',
    #                    borderpad=1)
    # ax_inset.set_facecolor('white')         # ç”¨ç™½è‰²æŠŠä¸»å›¾çº¿æ¡é®æ‰
    # ax_inset.patch.set_alpha(1)             # ä¿è¯ä¸é€æ˜
    # ax_inset.patch.set_zorder(2) 

    # # plot same datasets, restricted to <Â 500â€¯m
    # # ax_in.plot(era5_profile.loc[era5_profile['height'] >= Subplot_yaxis, 'hws'],
    # #            era5_profile.loc[era5_profile['height'] >= Subplot_yaxis, 'height'],
    # #            color='blue',   lw=3)
    # # ax_in.plot(cra_profile.loc[cra_profile['height'] >= Subplot_yaxis, 'hws'],
    # #            cra_profile.loc[cra_profile['height'] >= Subplot_yaxis, 'height'],
    # #            color='magenta', lw=3)
    # ax_in.plot(dwl_profile.loc[dwl_profile['height'] >= Subplot_yaxis, 'hws'],
    #            dwl_profile.loc[dwl_profile['height'] >= Subplot_yaxis, 'height'],
    #            color='red',    lw=3)
    # ax_in.plot(snd.loc[snd['height'] >= Subplot_yaxis, 'hws'],
    #            snd.loc[snd['height'] >= Subplot_yaxis, 'height'],
    #            color='black',  lw=3)

    # # inset axis limits & ticks
    # ax_in.set_ylim(Subplot_yaxis, 10010)
    # ax_in.set_xlim(0, 45)
    
    # # >>> å¼ºåˆ¶åœ¨ y è½´æœ€åº•éƒ¨æ˜¾ç¤º Subplot_yaxis è¿™ä¸€ä¸ªåˆ»åº¦ <<<
    # y_ticks_inset = np.concatenate([[Subplot_yaxis],
    #                                 alt_ticks[(alt_ticks > Subplot_yaxis) &
    #                                           (alt_ticks >= 4000)]])
    # ax_in.set_yticks(y_ticks_inset)
    
    
    # ax_in.tick_params(axis='both', which='major', length=8, width=2, labelsize=30)
    # ax_in.tick_params(axis='both', which='minor', length=4, width=2)

    # # inset spines styling
    # ax_in.spines['top'   ].set_visible(False)
    # ax_in.spines['right' ].set_visible(False)
    # ax_in.spines['left'  ].set_color('red')
    # ax_in.spines['bottom'].set_color('darkorange')
    # ax_in.tick_params(axis='y', colors='red')
    # ax_in.tick_params(axis='x', colors='darkorange')
    # ax_in.xaxis.set_major_locator(MultipleLocator(10))

    # -------------------- subplotâ€‘specific labels / title --------------------
    col = idx % n_cols
    row = idx // n_cols
    center_col = n_cols // 2 
    if col == 0:
        ax.set_ylabel('')  # we move global yâ€‘label outside fig
    else:
        ax.tick_params(axis='y', labelleft=False)
    if col == n_cols - 1:
        secax.set_ylabel('')  # rightâ€‘side label moved to global text
    else:
        secax.tick_params(axis='y', labelright=False)

    if row == n_rows - 1:                       # åº•è¡Œ
        ax.tick_params(axis='x', labelbottom=True)   # åˆ»åº¦æ•°å­—ä¿ç•™
        if col == center_col:                   # åªæœ‰ä¸­é—´é‚£æ ¼è¦ xlabel
            ax.set_xlabel('Horizontal Wind Speed (m/s)',
                      fontsize=50, weight='bold', color='darkorange',
                      labelpad=20)
    else:                                       # å…¶ä½™è¡Œ
        ax.tick_params(axis='x', labelbottom=False)  # åˆ»åº¦æ•°å­—éšè—

    # panel title
    ax.set_title(target_time.strftime('%Y-%m-%d %H:%M (BJT)'), pad=12, fontsize=36,weight='bold')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Hide any empty subâ€‘axes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for j in range(idx + 1, n_rows * n_cols):
    fig.delaxes(axes[j])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Global axesâ€‘level annotations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fig.text(-0.01, 0.5, 'Height (m a.g.l.)', rotation=90, va='center', ha='left',
         color='black', weight='bold', fontsize=50)
fig.text(1.01, 0.5, 'Pressure (hPa)', rotation=270, va='center', ha='right',
         color='black', weight='bold', fontsize=50)

# Legend & title (top)
legend_handles = [
    #plt.Line2D([], [], color='blue',    lw=6, label='ERA5'),
    #plt.Line2D([], [], color='magenta', lw=6, label='CRA'),
    plt.Line2D([], [], color='darkorange',     lw=6, label='Doppler Wind Lidar'),
    plt.Line2D([], [], color='black',   lw=6, label='Radiosonde')
]
fig.legend(handles=legend_handles, loc='upper center', bbox_to_anchor=(0.5, 0.995),
           ncol=4, frameon=False, fontsize=32)
fig.text(0.5, 0.993, 'Horizontal Wind Speed Radiosonde Comparison â€“ 5min Temporal Resolution',
         ha='center', va='bottom', fontsize=40, weight='bold')

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Save figure (no transparency) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fig.tight_layout(rect=[0, 0, 1, 0.985])
save_path = os.path.join(out_dir, out_fname)
fig.savefig(save_path, dpi=300, pil_kwargs={"compression": "tiff_adobe_deflate"},
            format='tif', bbox_inches='tight')
print(f"âœ… Figure saved to: {save_path}")

##########################ä¸‰ç»´è½¨è¿¹å›¾+åœ°é¢åœ°å›¾##############

##########################éœ€è¦åœ¨Jupyterä¸­è¿è¡Œæ¥å¼€å¯ä¸‰ç»´äº¤äº’##############
# import os
# import requests
# import numpy as np
# import pandas as pd
# import plotly.graph_objects as go
# from PIL import Image
# from metpy.calc import pressure_to_height_std
# from metpy.units import units      # â† æ³¨æ„æ˜¯ from â€¦ import units
# from io import BytesIO


# # è®¾ç½®æ–‡ä»¶è·¯å¾„å’Œè¾“å‡ºç›®å½•
# excel_path = r"E:\Beijing2024\æ¢ç©ºæ•°æ®-54511\original combined2.xlsx"
# out_dir = r"E:\Beijing2024\å‡ºå›¾TIF"
# os.makedirs(out_dir, exist_ok=True)

# # 1. è¯»å–æ‰€æœ‰å·¥ä½œè¡¨å¹¶æ¸…æ´—æ•°æ®
# xls = pd.ExcelFile(excel_path)
# data_sheets = {}
# for sheet in xls.sheet_names:
#     df = pd.read_excel(xls, sheet_name=sheet, header=0)  # é»˜è®¤æ— è¡¨å¤´
#     # æå–ç¬¬2åˆ—ï¼ˆindex1ï¼‰ã€ç¬¬3åˆ—ï¼ˆindex2ï¼‰ã€ç¬¬4åˆ—ï¼ˆindex3ï¼‰
#     df = df.iloc[:, [1, 2, 3]]
#     df.columns = ['lon', 'lat', 'pressure_hPa']
#     df = df.astype(float)                # å¼ºåˆ¶è½¬æ¢ä¸ºæµ®ç‚¹
#     df = df.dropna(how='any')           # åˆ é™¤å« NaN çš„è¡Œ:contentReference[oaicite:6]{index=6}
#     if df.empty:
#         continue
#     data_sheets[sheet] = df

# # 2. å‹åŠ›è½¬æ¢ä¸ºé«˜åº¦ï¼ˆæ ‡å‡†å¤§æ°”ï¼‰:contentReference[oaicite:7]{index=7}
# for sheet, df in data_sheets.items():
#     pressure = df['pressure_hPa'].values * units('hPa')
#     height = pressure_to_height_std(pressure)  # è¿”å›å¸¦å•ä½çš„é«˜åº¦
#     df['height_m'] = height.to('m').magnitude

# # 3. è·å–é«˜å¾·é™æ€åœ°å›¾å›¾åƒï¼ˆç»çº¬èŒƒå›´ 116â€“117E, 39.5â€“40.5Nï¼‰
# api_key = "f53bda1e2e8685bdbb4529a24d03f063"
# center = "116.5,40.0"   # åœ°å›¾ä¸­å¿ƒ
# zoom = 9
# img_size = "6400*1600"
# static_map_url = (
#     f"https://restapi.amap.com/v3/staticmap?"
#     f"location={center}&zoom={zoom}&size={img_size}&key={api_key}"
# )
# resp = requests.get(static_map_url)
# img = Image.open(BytesIO(resp.content))
# # è½¬æ¢ä¸º8ä½è°ƒè‰²æ¿å›¾åƒä»¥è·å–é¢œè‰²æ˜ å°„
# eight_bit_img = img.convert('P', palette=Image.WEB, dither=None)
# palette = np.array(eight_bit_img.getpalette()).reshape((-1, 3))
# colorscale = [[i/255.0, f"rgb({r},{g},{b})"] for i,(r,g,b) in enumerate(palette)]

# # æ„é€ åœ°å›¾é¢ x,y,z
# im = np.array(img)
# H, W = im.shape[:2]
# lon_min, lon_max = 116.0, 117.0
# lat_min, lat_max = 39.5, 40.5
# x = np.linspace(lon_min, lon_max, W)
# y = np.linspace(lat_max, lat_min, H)  # æ³¨æ„çº¬åº¦æ–¹å‘å–åï¼Œä½¿å›¾åƒä¸å€’ç½®
# z = np.zeros((W, H))  # z ä¸ºé›¶å¹³é¢:contentReference[oaicite:8]{index=8}

# # 4. åˆ›å»º 3D å›¾å½¢å¹¶ç»˜åˆ¶è½¨è¿¹å’Œåœ°å›¾åº•é¢
# fig = go.Figure()

# # å„æ—¶æ¬¡è½¨è¿¹ï¼Œæ¯æ¡çº¿ä½¿ç”¨ä¸åŒé¢œè‰²å’Œåç§°
# color_list = ["red", "green", "blue", "orange", "purple", "cyan", "magenta"]
# for i, (sheet, df) in enumerate(data_sheets.items()):
#     fig.add_trace(go.Scatter3d(
#         x=df['lon'], y=df['lat'], z=df['height_m'],
#         mode='lines',
        
#         marker=dict(size=4),
#         line=dict(color=color_list[i % len(color_list)], width=2),
#         name=sheet  # å›¾ä¾‹æ˜¾ç¤ºæ—¶æ¬¡
#     ))
# line=dict(
#     #color='rgba(0, 0, 255, 0.8)',  # åŠé€æ˜è“è‰²
#     width=8
# )
# # æ·»åŠ é«˜å¾·åœ°å›¾å¹³é¢ï¼ˆSurfaceï¼‰:contentReference[oaicite:9]{index=9}
# fig.add_trace(go.Surface(
#     x=x, y=y, z=z,
#     surfacecolor=np.array(eight_bit_img),  # è°ƒè‰²æ¿ç´¢å¼•å›¾
#     colorscale=colorscale,
#     cmin=0, cmax=255,
#     showscale=False,
#     lighting_diffuse=1, lighting_ambient=1,
#     lighting_fresnel=1, lighting_roughness=1, lighting_specular=0.5
# ))

# # 5. è®¾ç½®å¸ƒå±€ï¼šé€æ˜èƒŒæ™¯ã€è½´æ ‡ç­¾ã€è§†è§’ç­‰:contentReference[oaicite:10]{index=10}
# fig.update_layout(
#     title="åŒ—äº¬åœ°åŒºæ¢ç©ºè½¨è¿¹ï¼ˆ3Dï¼‰",
#     scene=dict(
#         xaxis_title='Longitude (Â°E)',
#         yaxis_title='Latitude (Â°N)',
#         zaxis_title='Height (m a.g.l.)',
#         xaxis=dict(range=[lon_min, lon_max],gridcolor='gray',title_font=dict(size=20),
#             tickfont=dict(size=13)),     # Xè½´åˆ»åº¦å­—å·
#         yaxis=dict(range=[lat_min, lat_max],title_font=dict(size=20),  # Xè½´æ ‡é¢˜å­—å·
#             tickfont=dict(size=13),     # Xè½´åˆ»åº¦å­—å·
#                    gridcolor='gray'),
#         zaxis=dict(range=[0, 10000], title_font=dict(size=20),  # Xè½´æ ‡é¢˜å­—å·
#             tickfont=dict(size=13),     # Xè½´åˆ»åº¦å­—å·
#                    tickformat=".0f", 
#                    gridcolor='gray'  # è®¾ç½®zè½´ç½‘æ ¼çº¿é¢œè‰²ä¸ºé»‘è‰²
#         )
#     ),
#     margin=dict(l=0, r=0, b=0, t=50),
#     legend=dict(title="æ—¶æ¬¡"),
#     paper_bgcolor='rgba(0,0,0,0)',  # èƒŒæ™¯é€æ˜:contentReference[oaicite:11]{index=11}
#     plot_bgcolor='rgba(0,0,0,0)'
# )

# # è®¾ç½®åˆå§‹è§†è§’ï¼Œæ–¹ä¾¿è§‚å¯Ÿ
# # åœ¨åŸæœ‰ä»£ç çš„å¸ƒå±€è®¾ç½®éƒ¨åˆ†å¢åŠ ä»¥ä¸‹å‚æ•°
# fig.update_layout(
#     height=1500, 
#     width=1100, 
#     # åŸæœ‰å¸ƒå±€å‚æ•°ä¿æŒä¸å˜...
#     scene=dict(
#         # åŸæœ‰è½´è®¾ç½®ä¿æŒä¸å˜...
#         # æ–°å¢å‚æ•°è°ƒæ•´æ˜¾ç¤ºåŒºåŸŸ
#         aspectmode="manual",  # æ‰‹åŠ¨æ§åˆ¶æ¯”ä¾‹
#         aspectratio=dict(x=1, y=1, z=0.8),  # è°ƒæ•´ä¸‰ç»´ç©ºé—´æ¯”ä¾‹
#         camera=dict(  # è°ƒæ•´ç›¸æœºè§†è§’å‚æ•°
#             up=dict(x=0, y=0, z=1),
#             center=dict(x=0, y=0, z=0),
#             eye=dict(x=1.5, y=1.5, z=1.5)  # è°ƒæ•´è§‚å¯Ÿç‚¹ä½ç½®
#         )
#     )
    
# )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  export_plot_profiles.py  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â”€â”€â”€ precheck_plot_export.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import pandas as pd
import numpy as np
import sys

# â¶ å®šä¹‰â€œå¿…é¡»å­˜åœ¨â€çš„å˜é‡åŠå…¶å…³é”®åˆ—
REQUIRED = {
    "ERA5_interp_BJ" : ["pressure_level", "t"],
    "cra_regular"    : ["Level (hPa)", "rh (%)", "hws(m/s)"],
    "t_mwr_long"     : [],                # å·²æ˜¯å¤šå±‚ç´¢å¼•ï¼Œåˆ—æ£€æŸ¥å¯çœ
    "rh_mwr_long"    : [],
    "cleaned_h"      : ["BJT", "hws"],
    "cleaned_h_60min": ["BJT", "hws"],
    "cleaned_h_5min" : ["BJT", "hws"],
}

SCALARS = ["Altitude", "site_elev"]       # äºŒè€…è‡³å°‘è¦æœ‰ä¸€ä¸ª

errors = []

# â· å˜é‡æ˜¯å¦å­˜åœ¨ã€æ˜¯å¦ DataFrameã€å…³é”®åˆ—æ˜¯å¦åœ¨
for var, cols in REQUIRED.items():
    if var not in globals():
        errors.append(f"âŒ ç¼ºå°‘å˜é‡  {var}")
        continue
    obj = globals()[var]
    if not isinstance(obj, pd.DataFrame):
        errors.append(f"âŒ {var} ä¸æ˜¯ pandas.DataFrame (è€Œæ˜¯ {type(obj)})")
        continue
    for c in cols:
        if c not in obj.columns:
            errors.append(f"âŒ {var} ç¼ºå°‘åˆ— '{c}'")
    if obj.empty:
        errors.append(f"âš ï¸  {var} æ˜¯ç©º DataFrame")

# â¸ æ ‡é«˜ / ç«™ç‚¹æµ·æ‹”æ˜¯å¦æä¾›
if not any(s in globals() for s in SCALARS):
    errors.append("âŒ æœªæ‰¾åˆ° Altitude æˆ– site_elev")

# â¹ æ‰“å°ç»“æœå¹¶è§†éœ€è¦é€€å‡º
if errors:
    print("\n".join(errors))
    sys.exit("â€¼ï¸  æ•°æ®æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·å…ˆå‡†å¤‡å¥½ä»¥ä¸Šå¯¹è±¡å†æ‰§è¡Œå¯¼å‡ºã€‚")
else:
    print("âœ… æ‰€æœ‰å¿…è¦æ•°æ®å·²å°±ç»ªï¼Œå¯å®‰å…¨æ‰§è¡Œå¯¼å‡ºã€‚")
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# =============================================================================
# é¡¹ç›®ï¼šå¤šæºå»“çº¿æ•°æ®èåˆä¸å¯¼å‡ºï¼ˆRadiosonde / MWR / DWL / ERA5 / CRAï¼‰
#
# åŠŸèƒ½æ¦‚è¿°ï¼š
# 1) è¯»å–æ¢ç©º Excelï¼ˆå¤š sheetï¼Œsheet åå½¢å¦‚ YYYYMMDDHHï¼‰ï¼Œå°†â€œæ°”å‹â†’é«˜åº¦â€å¹¶ä½œä¸ºå…¨æµç¨‹çš„é«˜åº¦åŸºå‡†ï¼›
# 2) 1 åˆ†é’Ÿå±‚ï¼ˆtime-height é€ç‚¹é…å‡†ï¼‰ï¼š
#    - é”šç‚¹ï¼šç›´æ¥ä½¿ç”¨â€œæ¢ç©ºçš„åŸå§‹æ—¶é—´ä¸é«˜åº¦â€ä½œä¸º (time, height) å–æ ·ç‚¹ï¼ˆä¸åšæ•´åˆ†é‡é‡‡æ ·ï¼‰ï¼›
#    - MWRï¼ˆæ¸©åº¦/æ¹¿åº¦ï¼‰ï¼šä» (timestamps Ã— height) çš„é•¿è¡¨æ„å»ºè§„åˆ™ç½‘æ ¼ï¼Œä½¿ç”¨ scipy.interpn
#      åœ¨ (time, height) ä¸ŠåŒçº¿æ€§æ’å€¼åˆ°æ¢ç©ºé”šç‚¹ï¼›éšåæŒ‰æ¯æ¬¡å‘å°„ï¼ˆlaunchï¼‰
#      â€œä»é¦–ä¸ªé NaN å‰çš„è¿ç»­ NaN è·³è¿‡ã€ä»ç¬¬ä¸€ä¸ªæœ‰æ•ˆå€¼å¼€å§‹ï¼Œé‡åˆ°é¦–ä¸ª NaN å³åœæ­¢â€çš„ç­–ç•¥è£å‰ªï¼Œ
#      ç¡®ä¿ MWR ä¸æ¢ç©ºåœ¨ 1min å±‚ä¸€ä¸€é…å¯¹ï¼›
#    - DWLï¼ˆé£é€Ÿ 1minï¼‰ï¼šç”± cleaned_h èšåˆå¾—åˆ° cleaned_h_1minï¼ˆæŒ‰é«˜åº¦Ã—1min åˆ†ç®±å–å‡å€¼ï¼‰ï¼Œ
#      æ„å»º (time Ã— height) ç½‘æ ¼å¹¶æ’å€¼åˆ°æ¢ç©ºé”šç‚¹ï¼›**ä¸æˆªæ–­**ï¼Œä»…ä¿ç•™ DWL æ’å€¼åéç©ºç‚¹ï¼Œ
#      ä¸æ¢ç©ºåœ¨ (launch, time, height) ä¸Šå†…è¿æ¥é…å¯¹ï¼Œä¿è¯æ—¶ç©ºåŒ¹é…ï¼›
#    - å°†ä¸Šè¿°é…å¯¹åçš„ Radiosonde/MWR/DWL çš„ 1min æ•°æ®åˆ†åˆ«å†™å…¥ temp_1min / rh_1min / hws_1minã€‚
#
# 3) 1 å°æ—¶å±‚ï¼ˆé«˜åº¦å¯¹é½ï¼‰ï¼š
#    - å¯¹æ¯ä¸ªæ—¶æ¬¡ï¼ˆsheetï¼‰ï¼šä»¥è¯¥æ—¶æ¬¡æ¢ç©ºçš„é«˜åº¦é›†åˆï¼ˆå»é‡å‡åºï¼‰ä¸ºâ€œç›®æ ‡é«˜åº¦ç½‘æ ¼â€ï¼›
#    - å°† ERA5ï¼ˆå‹åŠ›å±‚â†’é«˜åº¦ï¼‰ã€CRAï¼ˆå‹åŠ›å±‚â†’é«˜åº¦ï¼‰ã€MWRï¼ˆÂ±30 min å¹³å‡å‰–é¢ï¼‰ã€
#      DWLï¼ˆæ•´ç‚¹ 60min å‰–é¢ï¼‰æ²¿â€œé«˜åº¦ç»´â€çº¿æ€§æ’å€¼åˆ°è¯¥ç›®æ ‡é«˜åº¦ï¼›
#    - æ¢ç©ºè‡ªèº«çš„æ¸©/æ¹¿/é£åœ¨ç›®æ ‡é«˜åº¦ä¸ŠåšæŒ‰é«˜èšåˆï¼ˆæ— éœ€å†æ’å€¼ï¼‰ï¼›
#    - å°†ä¸Šè¿°ç»“æœå†™å…¥ temp_1h / rh_1h / hws_1hã€‚
#
# 4) ç»Ÿä¸€é™åˆ¶é«˜åº¦ï¼šå…¨æµç¨‹ä»…ä¿ç•™ height â‰¤ MAX_Hï¼ˆå«ï¼‰ï¼Œé»˜è®¤ MAX_H=10000 mã€‚
#
# 5) å¯¼å‡ºåˆ° Excelï¼š
#    - ç»Ÿä¸€åˆ—ï¼štime, launch, source, height, valueï¼›
#    - ç»Ÿä¸€æ’åºï¼štime â†’ height â†’ sourceï¼ˆsource å›ºå®šé¡ºåºï¼šRadiosonde â†’ MWR â†’ DWL â†’ ERA5 â†’ CRAï¼‰ï¼›
#    - å¯¹ hws_1h é¢å¤–ä¸¢å¼ƒ value ä¸º NaN çš„è¡Œï¼›
#    - æ‰€æœ‰å·¥ä½œè¡¨åˆ—å®½ç»Ÿä¸€è®¾ç½®ä¸º 25ï¼›
#    - è¾“å‡ºæ–‡ä»¶è·¯å¾„ç”± OUT_XLSX æŒ‡å®šï¼ˆè¦†ç›–å¼å†™å‡ºï¼‰ã€‚
#
# ä¸»è¦è¾“å…¥ï¼ˆå¤–éƒ¨ä¾èµ–çš„ DataFrameï¼Œéœ€åœ¨è¿è¡Œå‰å‡†å¤‡å¥½ï¼‰ï¼š
# - ERA5_interp_BJï¼šåˆ—å« ['valid_time','pressure_level','t','r','hws(m/s)']ï¼›
# - cra_regular   ï¼šåˆ—å« ['timestamps','Level (hPa)','Temp (K)','rh (%)','hws(m/s)']ï¼›
# - t_mwr_long    ï¼šMultiIndex (timestamps, height) çš„é•¿è¡¨/Seriesï¼ˆåˆ—å/å€¼å 'T(K)'ï¼‰ï¼›
# - rh_mwr_long   ï¼šåŒä¸Šï¼ˆ'RH(%)'ï¼‰ï¼›
# - cleaned_h     ï¼šDWL åŸå§‹é€æ¡æ•°æ®ï¼Œåˆ—å« ['BJT','height','hws']ï¼ˆç”¨äºç”Ÿæˆ 1minï¼‰ï¼›
# - cleaned_h_60minï¼šDWL æ•´ç‚¹ 1 å°æ—¶å‰–é¢ï¼Œåˆ—å« ['BJT','height','hws']ï¼›
# - æ¢ç©º Excelï¼ˆEXCEL_INï¼‰ï¼šæ¯ä¸ª sheet è‡³å°‘å« ['time','pressure_hPa','temperature_C','relative humidity_%',
#   'geopotential height_m','wind speed_m/s'] ä¸­çš„è‹¥å¹²åˆ—ï¼›æ°”å‹å°†è¢«è½¬æ¢ä¸ºé«˜åº¦ä½œä¸ºä¸»è½´ã€‚
#
# å…³é”®ç®—æ³•/å®ç°ç»†èŠ‚ï¼š
# - p2hï¼šä½¿ç”¨ MetPy æ ‡å‡†å¤§æ°”ï¼ˆpressure_to_height_stdï¼‰å°†â€œè£¸ hPaâ€è½¬æ¢ä¸ºå‡ ä½•é«˜åº¦å¹¶å‡å»ç«™ç‚¹æµ·æ‹”ï¼›
# - 2D æ’å€¼ï¼šscipy.interpolate.interpnï¼Œåœ¨ (time, height) è§„åˆ™ç½‘æ ¼ä¸Šå¯¹æ¢ç©ºé”šç‚¹åšåŒçº¿æ€§æ’å€¼ï¼›
# - 1D æ’å€¼ï¼šscipy.interpolate.interp1dï¼Œä»…æ²¿é«˜åº¦ç»´çº¿æ€§æ’å€¼ï¼Œè¶Šç•Œå¡« NaNï¼ˆä¸å¤–æ¨ï¼‰ï¼›
# - 1min æ¸©/æ¹¿è£å‰ªï¼ˆä»… MWRï¼‰ï¼šæŒ‰æ¯ä¸ª launchï¼Œä»é¦–ä¸ªæœ‰æ•ˆå€¼å¼€å§‹ä¿ç•™ï¼Œé‡åˆ°é¦–ä¸ª NaN å³åœæ­¢ï¼›
# - DWL 1min ä¸æˆªæ–­ï¼šä»…ä¿ç•™éç©ºå¹¶ä¸æ¢ç©ºé…å¯¹ï¼›
# - ç»Ÿä¸€ç±»å‹æ¸…æ´—ï¼šå¯¹ç”¨äºè®¡ç®—/æ’å€¼çš„åˆ—å¼ºåˆ¶æ•°å€¼åŒ–ï¼ˆerrors='coerce'ï¼‰ï¼Œå¹¶åœ¨å¿…è¦å¤„å» NaNï¼›
# - å®‰å…¨æ€§ï¼šæ„å»ºç½‘æ ¼æ—¶ä¿è¯æ—¶é—´ä¸é«˜åº¦è½´ä¸¥æ ¼å•è°ƒï¼ˆå»é‡ã€åˆå¹¶é‡å¤é«˜åº¦ã€è¿‘ä¼¼é‡å¤åˆ—æŒ‰ 3 ä½å°æ•°å†åˆå¹¶ï¼‰ã€‚
#
# ä¸»è¦å¯è°ƒå‚æ•°ï¼š
# - EXCEL_IN  ï¼šæ¢ç©ºå¤š sheet Excel è·¯å¾„ï¼›
# - OUT_XLSX  ï¼šè¾“å‡º Excel è·¯å¾„ï¼ˆè¦†ç›–å†™ï¼‰ï¼›
# - SITE_ELEV ï¼šç«™ç‚¹æµ·æ‹”ï¼ˆmï¼‰ï¼Œç”¨äºä»æ ‡å‡†å¤§æ°”é«˜åº¦ä¸­å‡å»ï¼›
# - MAX_H     ï¼šç»Ÿä¸€çš„é«˜åº¦ä¸Šé™ï¼ˆé»˜è®¤ 10000 mï¼Œå«ï¼‰ã€‚
#
# å·²ç§»é™¤/ä¸åŒ…å«ï¼š
# - æ—©å…ˆçš„ DWL 5 åˆ†é’Ÿæ•´ç‚¹å¯¹é½ä¸æ’å€¼é€»è¾‘ï¼ˆprepare_dwl_5min_block åŠç›¸å…³å…¥åº“ï¼‰å·²å…¨é¢åˆ é™¤ã€‚
# =============================================================================

import re
import pandas as pd
import numpy as np
from pathlib import Path
import metpy.calc as mpcalc
from metpy.units import units
from scipy.interpolate import interpn, interp1d
from pandas.api.types import CategoricalDtype

# ================================ é…ç½®åŒº ================================ #
EXCEL_IN   = r"E:\Beijing2024\æ¢ç©ºæ•°æ®-54511\original combined2.xlsx"   # æ¢ç©ºåŸå§‹è¡¨ï¼ˆå¤š sheetï¼‰
OUT_XLSX   = Path(r"E:\Beijing2024\å‡ºå›¾TIF\plot_data for representativeness.xlsx")                            # è¾“å‡º Excel
SITE_ELEV  = 49.0        # ç«™ç‚¹æµ·æ‹”ï¼Œm
MAX_H      = 10000.0     # é«˜åº¦ä¸Šé™ï¼ˆå«ï¼‰
SHEET_LIST = pd.ExcelFile(EXCEL_IN).sheet_names
# ======================================================================= #

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åŸºç¡€å·¥å…· â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def p2h(p_hpa_series, site_elev=SITE_ELEV):
    """'è£¸ hPa' â†’ m a.g.l.ï¼ˆå‡å»ç«™ç‚¹æµ·æ‹”ï¼‰"""
    p_vals = np.asarray(p_hpa_series, dtype='float64')
    p_q = p_vals * units.hPa
    return mpcalc.pressure_to_height_std(p_q).to('m').magnitude - site_elev

def _to_epoch_seconds(ts_series):
    return (pd.to_datetime(ts_series) - pd.Timestamp("1970-01-01")) // pd.Timedelta('1s')

def _launch_from_sheet(sheet_name: str) -> pd.Timestamp:
    """å·¥ä½œè¡¨å 'YYYYMMDDHH'ï¼ˆä¾‹å¦‚ 2024080608ï¼‰ â†’ Timestamp"""
    if not re.fullmatch(r"\d{10}", str(sheet_name)):
        raise ValueError(f"å·¥ä½œè¡¨åä¸ç¬¦åˆ YYYYMMDDHH æ ¼å¼: {sheet_name}")
    return pd.to_datetime(sheet_name, format="%Y%m%d%H", errors="raise")

def _stash(container, df, variable, source, ts, val_col, time_col=None, launch=None, launch_col='launch'):
    """
    æ”¶é›†æ›²çº¿ df â†’ ç»Ÿä¸€åˆ—ï¼štime, launch, source, height, value, variable
    - è‹¥ df é‡Œæœ‰ launch åˆ—åˆ™ä¿ç•™ï¼›å¦åˆ™ç”¨ launch å‚æ•°ï¼ˆé€šå¸¸æ˜¯è¯¥ sheet çš„ launch_tsï¼‰ã€‚
    - è‹¥æä¾› time_colï¼Œåˆ™ä½¿ç”¨é€è¡Œæ—¶é—´æˆ³ï¼›å¦åˆ™ç»Ÿä¸€ä½¿ç”¨ tsã€‚
    """
    if df is None or df.empty:
        return
    rec = df.rename(columns={val_col: 'value'}).copy()
    # time
    if time_col and (time_col in rec.columns):
        rec['time'] = pd.to_datetime(rec[time_col])
    else:
        rec['time'] = ts
    # launch
    if launch_col in rec.columns:
        rec['launch'] = pd.to_datetime(rec[launch_col], errors='coerce')
    else:
        rec['launch'] = pd.to_datetime(launch) if launch is not None else pd.NaT
    # ç»Ÿä¸€åˆ—
    rec = (rec[['time', 'launch', 'height', 'value']]
           .assign(variable=variable, source=source))
    container.append(rec)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç½‘æ ¼æ„å»ºï¼ˆ1min/é•¿è¡¨ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def _grid_from_long(long_df, value_col=None):
    """
    æ¥å—ï¼š
      - Seriesï¼ˆMultiIndex=(timestamps, height)ï¼‰
      - DataFrame + value_col æŒ‡å®šåˆ—åï¼›æˆ–å•åˆ— DataFrame
    è¿”å›: (t_axis_num, h_axis, grid_vals)
    """
    if long_df is None or len(long_df) == 0:
        return None, None, None

    # å–åˆ° Series
    if isinstance(long_df, pd.Series):
        series = long_df
    elif isinstance(long_df, pd.DataFrame):
        if value_col is not None and value_col in long_df.columns:
            series = long_df[value_col]
        elif long_df.shape[1] == 1:
            series = long_df.iloc[:, 0]
        else:
            raise ValueError("_grid_from_long: ä¼ å…¥ DataFrame è¯·æä¾› value_colã€‚")
    else:
        raise TypeError("_grid_from_long: ä»…æ”¯æŒ Series æˆ– DataFrameã€‚")

    # å±•å®½ï¼šindex=timestamps, columns=height
    wide = series.unstack()
    wide.index = pd.to_datetime(wide.index, errors='coerce')
    wide = wide.sort_index().groupby(wide.index).mean()

    # é«˜åº¦åˆ—ä¸ºæ•°å€¼å¹¶é™é«˜
    wide.columns = pd.to_numeric(wide.columns, errors='coerce')
    wide = wide.loc[:, ~np.isnan(wide.columns)]
    if 'MAX_H' in globals():
        wide = wide.loc[:, [c for c in wide.columns if c <= MAX_H]]
    if wide.shape[1] == 0:
        return None, None, None

    # åˆå¹¶é‡å¤é«˜åº¦å¹¶å‡åº
    wide = wide.T.groupby(level=0).mean().T
    wide = wide.reindex(sorted(wide.columns), axis=1)

    # è½´
    t_axis = wide.index
    h_axis = wide.columns.to_numpy(dtype='float64')
    t_num  = ((t_axis - pd.Timestamp("1970-01-01")) // pd.Timedelta('1s')).to_numpy(dtype='int64')

    # å»é‡æ—¶é—´
    if np.any(np.diff(np.sort(t_num)) == 0):
        _, first_idx = np.unique(t_num, return_index=True)
        first_idx.sort()
        wide = wide.iloc[first_idx]
        t_axis = wide.index
        t_num  = ((t_axis - pd.Timestamp("1970-01-01")) // pd.Timedelta('1s')).to_numpy(dtype='int64')

    # è¿‘ä¼¼é‡å¤é«˜åº¦å†åˆå¹¶ä¸€æ¬¡
    if not np.all(np.diff(h_axis) > 0):
        wide_round = wide.copy()
        wide_round.columns = np.round(wide_round.columns.astype(float), 3)
        wide_round = wide_round.T.groupby(level=0).mean().T
        wide_round = wide_round.reindex(sorted(wide_round.columns), axis=1)
        h_axis = wide_round.columns.to_numpy(dtype='float64')
        wide   = wide_round

    if len(t_num) < 2 or len(h_axis) < 2:
        return None, None, None
    if not np.all(np.diff(h_axis) > 0) or not np.all(np.diff(np.sort(t_num)) > 0):
        return None, None, None

    return t_num, h_axis, wide.to_numpy()

def _grid_from_1min_df(df, time_col='BJT', height_col='height', value_col='hws'):
    """
    ä» 'cleaned_h_1min' æ„å»º (timeÃ—height) ç½‘æ ¼ä»¥ä¾› interpnï¼š
    è¿”å› (t_axis_num, h_axis, grid_vals)
    """
    if df is None or df.empty:
        return None, None, None
    tmp = df[[time_col, height_col, value_col]].copy()
    tmp[time_col]   = pd.to_datetime(tmp[time_col], errors='coerce')
    tmp[height_col] = pd.to_numeric(tmp[height_col], errors='coerce')
    tmp[value_col]  = pd.to_numeric(tmp[value_col], errors='coerce')
    tmp = tmp.dropna(subset=[time_col, height_col, value_col])
    if 'MAX_H' in globals():
        tmp = tmp.loc[tmp[height_col] <= MAX_H]
    if tmp.empty:
        return None, None, None

    wide = tmp.pivot_table(index=time_col, columns=height_col, values=value_col, aggfunc='mean')
    wide = wide.sort_index()
    wide = wide.groupby(wide.index).mean()

    cols = pd.to_numeric(pd.Index(wide.columns), errors='coerce')
    wide.columns = cols
    wide = wide.loc[:, ~np.isnan(wide.columns)]
    wide = wide.T.groupby(level=0).mean().T
    wide = wide.reindex(sorted(wide.columns), axis=1)
    if wide.shape[1] < 2 or wide.shape[0] < 2:
        return None, None, None

    t_axis = wide.index
    h_axis = wide.columns.to_numpy(dtype='float64')
    t_num  = _to_epoch_seconds(t_axis).to_numpy(dtype='int64')

    if np.any(np.diff(np.sort(t_num)) == 0):
        _, first_idx = np.unique(t_num, return_index=True)
        first_idx.sort()
        wide = wide.iloc[first_idx]
        t_axis = wide.index
        t_num  = _to_epoch_seconds(t_axis).to_numpy(dtype='int64')

    if not (np.all(np.diff(h_axis) > 0) and np.all(np.diff(np.sort(t_num)) > 0)):
        return None, None, None

    return t_num, h_axis, wide.to_numpy()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1D é«˜åº¦æ’å€¼ï¼ˆ1 å°æ—¶ç”¨ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def _unique_sorted_nanfloat(arr_like):
    a = pd.to_numeric(pd.Series(arr_like), errors='coerce').astype('float64').to_numpy()
    a = a[np.isfinite(a)]
    return np.unique(np.sort(a))

def _interp_profile_to_targets(src_h, src_v, tgt_h):
    src_h = pd.to_numeric(pd.Series(src_h), errors='coerce').to_numpy(dtype='float64')
    src_v = pd.to_numeric(pd.Series(src_v), errors='coerce').to_numpy(dtype='float64')
    msk = np.isfinite(src_h) & np.isfinite(src_v)
    if msk.sum() < 2 or len(tgt_h) == 0:
        return np.full(len(tgt_h), np.nan, dtype='float64')
    df = (pd.DataFrame({'h': src_h[msk], 'v': src_v[msk]})
            .groupby('h', as_index=False)['v'].mean()
            .sort_values('h'))
    if df.shape[0] < 2:
        return np.full(len(tgt_h), np.nan, dtype='float64')
    f = interp1d(df['h'].to_numpy(), df['v'].to_numpy(),
                 kind='linear', bounds_error=False, fill_value=np.nan, assume_sorted=True)
    return f(np.asarray(tgt_h, dtype='float64'))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ MWR 1min çš„â€œä»é¦–ä¸ªæœ‰æ•ˆå€¼åˆ°é¦–ä¸ª NaNâ€è£å‰ª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def _trim_from_first_finite_then_stop_at_first_nan(df: pd.DataFrame, value_col: str, order_col: str = 'time') -> pd.DataFrame:
    """
    æ¯ä¸ª launch å†…ï¼ŒæŒ‰ order_col æ’åºï¼š
      - è·³è¿‡å¼€å¤´è¿ç»­çš„ NaN
      - ä»ç¬¬ä¸€ä¸ªé NaN å¼€å§‹ï¼Œç›´åˆ°é‡åˆ°ç¬¬ä¸€ä¸ª NaN ä¸ºæ­¢ï¼ˆä¸å«è¯¥ NaN è¡Œï¼‰
    è¿”å›æ—¶æ˜¾å¼å¸¦å› 'launch' åˆ—ï¼Œå…¼å®¹æ–°æ—§ pandasã€‚
    """
    if df.empty:
        return df

    def _one(g: pd.DataFrame) -> pd.DataFrame:
        g = g.sort_values(order_col)
        vals = g[value_col].to_numpy()
        isn  = np.isnan(vals)
        finite_idx = np.flatnonzero(~isn)
        if finite_idx.size == 0:
            return g.iloc[0:0]
        start = int(finite_idx[0])
        tail_isn = isn[start:]
        nnz = np.flatnonzero(tail_isn)
        end = start + int(nnz[0]) if nnz.size > 0 else len(vals)
        return g.iloc[start:end]

    try:
        # æ–°ç‰ˆï¼šæŠŠåˆ†ç»„åˆ—ä»å­è¡¨é‡Œæ’é™¤ï¼Œä½†ä¿ç•™ä¸ºå¤–å±‚ç´¢å¼•ï¼Œä¹‹åè¿˜åŸæˆä¸€åˆ—
        out = df.groupby('launch', group_keys=True).apply(_one, include_groups=False)
        # launch ä½œä¸ºå¤–å±‚ç´¢å¼•å±‚åé€šå¸¸å°±æ˜¯ 'launch'ï¼›è‹¥æ— ååˆ™å›é€€åˆ° 'level_0'
        lvl_name = out.index.names[0] if isinstance(out.index, pd.MultiIndex) else None
        out = out.reset_index(level=0).rename(columns={lvl_name or 'level_0': 'launch'})
        return out
    except TypeError:
        # æ—§ç‰ˆ pandasï¼šä¸æ”¯æŒ include_groupsï¼›ä»ç„¶ç”¨ group_keys=Trueï¼Œä¹‹åä»ç´¢å¼•æ¢å¤
        out = df.groupby('launch', group_keys=True).apply(_one)
        lvl_name = out.index.names[0] if isinstance(out.index, pd.MultiIndex) else None
        out = out.reset_index(level=0).rename(columns={lvl_name or 'level_0': 'launch'})
        return out


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1 åˆ†é’Ÿï¼šæ¢ç©ºé”šç‚¹ + MWR æ¸©/æ¹¿ + DWL é£é€Ÿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
records = []

print("â–¶ æ±‡æ€» Radiosonde åŸå§‹æ—¶é—´ä¸é«˜åº¦é”šç‚¹â€¦")
_rs_dict = pd.read_excel(EXCEL_IN, sheet_name=None)

def _prep_rs_one(sheet_name, df):
    want = ['time', 'pressure_hPa', 'temperature_C', 'relative humidity_%',
            'geopotential height_m', 'wind speed_m/s']
    present = [c for c in want if c in df.columns]
    out = df[present].copy()
    # ç±»å‹
    out['launch'] = _launch_from_sheet(sheet_name)  # â† æ¥è‡ªå·¥ä½œè¡¨å
    out['time']   = pd.to_datetime(out['time'])
    for col in ['pressure_hPa','temperature_C','relative humidity_%','geopotential height_m','wind speed_m/s']:
        if col in out.columns:
            out[col] = pd.to_numeric(out[col], errors='coerce')
    # é«˜åº¦
    out = out[out['pressure_hPa'].between(50, 1100)]
    out['height'] = p2h(out['pressure_hPa'])
    out = out.loc[out['height'] <= MAX_H]
    # ç‰©ç†é‡
    out['temperature_K'] = out['temperature_C'] + 273.15
    out['value_pc']      = out['relative humidity_%']
    out['hws']           = out.get('wind speed_m/s')
    return out[['launch','time','height','temperature_K','value_pc','hws']]

rs_native = pd.concat([_prep_rs_one(k, v) for k, v in _rs_dict.items()], ignore_index=True)

RS_TIME   = pd.to_datetime(rs_native['time'])
RS_HGT    = rs_native['height'].to_numpy(dtype='float64')
RS_LAUNCH = rs_native['launch'].to_numpy()
RS_PTS_2D = np.column_stack([_to_epoch_seconds(RS_TIME), RS_HGT])

# â€”â€” MWRï¼šåœ¨ (time,height) ä¸Šç›´æ¥æ’å€¼åˆ°æ¢ç©ºé”šç‚¹ï¼›æŒ‰ launch è£å‰ªï¼›ä¸ RS æˆå¯¹ â€”â€” #
print("â–¶ 1min æ¸©/æ¹¿ï¼ˆMWR â†’ RS é”šç‚¹ & è£å‰ªé…å¯¹ï¼‰â€¦")

# æ¸©åº¦
tn_T = hp_T = grid_T = None
if 't_mwr_long' in globals() and t_mwr_long is not None and len(t_mwr_long) > 0:
    tn_T, hp_T, grid_T = _grid_from_long(t_mwr_long, 'T(K)')

# æ¹¿åº¦
tn_R = hp_R = grid_R = None
if 'rh_mwr_long' in globals() and rh_mwr_long is not None and len(rh_mwr_long) > 0:
    tn_R, hp_R, grid_R = _grid_from_long(rh_mwr_long, 'RH(%)')

# æ’å€¼
mwr_T_df = pd.DataFrame(columns=['launch','time','height','T(K)'])
if tn_T is not None:
    mwr_T_on_rs = interpn((tn_T, hp_T), grid_T, RS_PTS_2D,
                          method='linear', bounds_error=False, fill_value=np.nan)
    mwr_T_df = pd.DataFrame({'launch': RS_LAUNCH, 'time': RS_TIME.to_numpy(),
                             'height': RS_HGT, 'T(K)': mwr_T_on_rs})

mwr_R_df = pd.DataFrame(columns=['launch','time','height','RH(%)'])
if tn_R is not None:
    mwr_R_on_rs = interpn((tn_R, hp_R), grid_R, RS_PTS_2D,
                          method='linear', bounds_error=False, fill_value=np.nan)
    mwr_R_df = pd.DataFrame({'launch': RS_LAUNCH, 'time': RS_TIME.to_numpy(),
                             'height': RS_HGT, 'RH(%)': mwr_R_on_rs})

# è£å‰ªï¼ˆä»… MWRï¼‰
mwr_T_cut = _trim_from_first_finite_then_stop_at_first_nan(mwr_T_df, value_col='T(K)',  order_col='time')
mwr_R_cut = _trim_from_first_finite_then_stop_at_first_nan(mwr_R_df, value_col='RH(%)', order_col='time')

# ç”¨è£å‰ªåçš„ (launch,time,height) ä½œä¸ºé”®ï¼Œä¸ RS åŒ¹é…ï¼Œä¿è¯ä¸€ä¸€å¯¹åº”
keys_T = mwr_T_cut[['launch','time','height']].drop_duplicates()
keys_R = mwr_R_cut[['launch','time','height']].drop_duplicates()

rs_T_cut = (rs_native[['launch','time','height','temperature_K']]
            .merge(keys_T, on=['launch','time','height'], how='inner'))
rs_R_cut = (rs_native[['launch','time','height','value_pc']]
            .merge(keys_R, on=['launch','time','height'], how='inner'))

# å…¥åº“ï¼ˆtemp_1min / rh_1minï¼šRS ä¸ MWR æˆå¯¹ï¼ŒåŒ…å« launchï¼‰
_stash(records, rs_T_cut[['launch','time','height','temperature_K']],
       'temp_1min', 'Radiosonde', pd.NaT, 'temperature_K', time_col='time')
_stash(records, mwr_T_cut[['launch','time','height','T(K)']],
       'temp_1min', 'MWR',        pd.NaT, 'T(K)',          time_col='time')

_stash(records, rs_R_cut[['launch','time','height','value_pc']],
       'rh_1min',   'Radiosonde', pd.NaT, 'value_pc',      time_col='time')
_stash(records, mwr_R_cut[['launch','time','height','RH(%)']],
       'rh_1min',   'MWR',        pd.NaT, 'RH(%)',         time_col='time')

print(f"   â†’ æˆå¯¹æ ·æœ¬ï¼ˆæ¸©åº¦ï¼‰ï¼š{len(rs_T_cut)} | æˆå¯¹æ ·æœ¬ï¼ˆæ¹¿åº¦ï¼‰ï¼š{len(rs_R_cut)}")

# â€”â€” DWL 1min é£é€Ÿï¼šä¸æˆªæ–­ï¼Œä»…ä¿ç•™éç©ºå¹¶ä¸ RS é…å¯¹ â€”â€” #
print("â–¶ 1min é£é€Ÿï¼ˆDWL â†’ RS é”šç‚¹ & é…å¯¹ï¼Œä¸æˆªæ–­ï¼‰â€¦")

# 1) ä» cleaned_h ç”Ÿæˆ cleaned_h_1minï¼ˆé«˜åº¦Ã—1min èšåˆï¼‰
cleaned_h_1min = pd.DataFrame(columns=['height','BJT','hws'])
if 'cleaned_h' in globals() and cleaned_h is not None and len(cleaned_h) > 0:
    tmp = cleaned_h.copy()
    tmp['BJT']    = pd.to_datetime(tmp['BJT'], errors='coerce')
    tmp['height'] = pd.to_numeric(tmp['height'], errors='coerce')
    tmp['hws']    = pd.to_numeric(tmp['hws'], errors='coerce')
    cleaned_h_1min = (
        tmp.groupby(['height', pd.Grouper(key='BJT', freq='1min')], as_index=False)
           .mean(numeric_only=True)
           .dropna(subset=['hws'])
    )
    cleaned_h_1min = cleaned_h_1min.loc[cleaned_h_1min['height'] <= MAX_H]

# 2) æ„å»º (timeÃ—height) ç½‘æ ¼å¹¶ 2D æ’å€¼åˆ° RS é”šç‚¹
dwl_tn = dwl_haxis = dwl_grid = None
if not cleaned_h_1min.empty:
    dwl_tn, dwl_haxis, dwl_grid = _grid_from_1min_df(
        cleaned_h_1min, time_col='BJT', height_col='height', value_col='hws'
    )

dwl_1min_df = pd.DataFrame(columns=['launch','time','height','hws'])
if dwl_tn is not None:
    dwl_on_rs = interpn((dwl_tn, dwl_haxis), dwl_grid, RS_PTS_2D,
                        method='linear', bounds_error=False, fill_value=np.nan)
    dwl_1min_df = pd.DataFrame({
        'launch': RS_LAUNCH,
        'time':   RS_TIME.to_numpy(),
        'height': RS_HGT,
        'hws':    dwl_on_rs
    })

# 3) ä»…ä¿ç•™ DWL éç©ºç‚¹ï¼Œå¹¶ä¸ RS åœ¨ (launch,time,height) ä¸Šé…å¯¹ï¼ˆæ—¶ç©ºåŒ¹é…ï¼‰
dwl_nonnull = dwl_1min_df.dropna(subset=['hws'])
if not dwl_nonnull.empty:
    keys_H = dwl_nonnull[['launch','time','height']].drop_duplicates()
    rs_H_match = (rs_native[['launch','time','height','hws']]
                  .merge(keys_H, on=['launch','time','height'], how='inner'))
    # å…¥åº“ï¼ˆåŒ…å« launchï¼‰
    _stash(records, rs_H_match[['launch','time','height','hws']],
           'hws_1min', 'Radiosonde', pd.NaT, 'hws', time_col='time')
    _stash(records, dwl_nonnull[['launch','time','height','hws']],
           'hws_1min', 'DWL',        pd.NaT, 'hws', time_col='time')
    print(f"   â†’ æˆå¯¹æ ·æœ¬ï¼ˆé£é€Ÿï¼‰ï¼š{len(rs_H_match)}")
else:
    print("âš ï¸ DWLâ†’RS 1min é£é€Ÿï¼šæ’å€¼åå…¨ä¸º NaN æˆ–æ— åŒ¹é…ç‚¹ï¼›æœ¬è½®ä¸å†™å…¥ã€‚")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1 å°æ—¶ï¼šé«˜åº¦å¯¹é½åˆ° Radiosondeï¼ˆâ‰¤10000 mï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
print("â–¶ 1 å°æ—¶æ•°æ®å…¥åº“ï¼ˆé«˜åº¦å¯¹é½åˆ° Radiosondeï¼Œâ‰¤10000 mï¼‰â€¦")

for sheet in SHEET_LIST:
    launch_ts = _launch_from_sheet(sheet)  # æ¥è‡ªè¡¨å
    t0 = launch_ts

    # è¯¥æ—¶æ¬¡æ¢ç©º â†’ ç›®æ ‡é«˜åº¦
    snd = pd.read_excel(EXCEL_IN, sheet_name=sheet)
    snd['pressure_hPa'] = pd.to_numeric(snd['pressure_hPa'], errors='coerce')
    snd['height'] = p2h(snd['pressure_hPa'])
    snd = snd.loc[snd['height'] <= MAX_H].copy()
    tgt_h = _unique_sorted_nanfloat(snd['height'])
    if tgt_h.size == 0:
        continue

    # Radiosonde è‡ªèº«
    if 'temperature_C' in snd.columns:
        snd['temperature_C'] = pd.to_numeric(snd['temperature_C'], errors='coerce')
        rs_T = (snd.assign(temperature_K=snd['temperature_C'] + 273.15)
                   .dropna(subset=['height', 'temperature_K'])
                   .groupby('height', as_index=False)['temperature_K'].mean())
        rs_T = rs_T.set_index('height').reindex(tgt_h).reset_index()
        _stash(records, rs_T[['height','temperature_K']],
               'temp_1h', 'Radiosonde', t0, 'temperature_K', launch=launch_ts)

    if 'relative humidity_%' in snd.columns:
        snd['relative humidity_%'] = pd.to_numeric(snd['relative humidity_%'], errors='coerce')
        rs_RH = (snd.rename(columns={'relative humidity_%':'value_pc'})
                    .dropna(subset=['height', 'value_pc'])
                    .groupby('height', as_index=False)['value_pc'].mean())
        rs_RH = rs_RH.set_index('height').reindex(tgt_h).reset_index()
        _stash(records, rs_RH[['height','value_pc']],
               'rh_1h', 'Radiosonde', t0, 'value_pc', launch=launch_ts)

    if 'wind speed_m/s' in snd.columns:
        snd['wind speed_m/s'] = pd.to_numeric(snd['wind speed_m/s'], errors='coerce')
        rs_WS = (snd[['height','wind speed_m/s']]
                 .rename(columns={'wind speed_m/s':'hws'})
                 .dropna(subset=['height', 'hws'])
                 .groupby('height', as_index=False)['hws'].mean())
        rs_WS = rs_WS.set_index('height').reindex(tgt_h).reset_index()
        _stash(records, rs_WS[['height','hws']],
               'hws_1h', 'Radiosonde', t0, 'hws', launch=launch_ts)

    # ERA5
    if 'ERA5_interp_BJ' in globals():
        era5 = (ERA5_interp_BJ[ERA5_interp_BJ['valid_time'] == t0]
                .assign(height=lambda d: p2h(d['pressure_level'])))
        if not era5.empty:
            h_src = era5['height'].to_numpy()
            if 't' in era5.columns:
                v = _interp_profile_to_targets(h_src, era5['t'], tgt_h)
                _stash(records, pd.DataFrame({'height': tgt_h, 't': v}),
                       'temp_1h', 'ERA5', t0, 't', launch=launch_ts)
            if 'r' in era5.columns:
                v = _interp_profile_to_targets(h_src, era5['r'], tgt_h)
                _stash(records, pd.DataFrame({'height': tgt_h, 'r': v}),
                       'rh_1h', 'ERA5', t0, 'r', launch=launch_ts)
            if 'hws(m/s)' in era5.columns:
                v = _interp_profile_to_targets(h_src, era5['hws(m/s)'], tgt_h)
                _stash(records, pd.DataFrame({'height': tgt_h, 'hws(m/s)': v}),
                       'hws_1h', 'ERA5', t0, 'hws(m/s)', launch=launch_ts)

    # CRA
    if 'cra_regular' in globals():
        cra = (cra_regular
               .assign(timestamps=pd.to_datetime(cra_regular['timestamps'], errors='coerce'))
               .loc[lambda d: d['timestamps'] == t0]
               .assign(height=lambda d: p2h(d['Level (hPa)'])))
        if not cra.empty:
            h_src = cra['height'].to_numpy()
            if 'Temp (K)' in cra.columns:
                v = _interp_profile_to_targets(h_src, cra['Temp (K)'], tgt_h)
                _stash(records, pd.DataFrame({'height': tgt_h, 'Temp (K)': v}),
                       'temp_1h', 'CRA', t0, 'Temp (K)', launch=launch_ts)
            if 'rh (%)' in cra.columns:
                v = _interp_profile_to_targets(h_src, cra['rh (%)'], tgt_h)
                _stash(records, pd.DataFrame({'height': tgt_h, 'rh (%)': v}),
                       'rh_1h', 'CRA', t0, 'rh (%)', launch=launch_ts)
            if 'hws(m/s)' in cra.columns:
                v = _interp_profile_to_targets(h_src, cra['hws(m/s)'], tgt_h)
                _stash(records, pd.DataFrame({'height': tgt_h, 'hws(m/s)': v}),
                       'hws_1h', 'CRA', t0, 'hws(m/s)', launch=launch_ts)

    # MWRï¼ˆÂ±30min å¹³å‡ï¼‰â†’ é«˜åº¦æ’å€¼
    win30, wout30 = t0 - pd.Timedelta(minutes=30), t0 + pd.Timedelta(minutes=30)
    if 't_mwr_long' in globals():
        mwr_T_1h = (t_mwr_long.reset_index()
                    .query("timestamps >= @win30 and timestamps <= @wout30")
                    .groupby('height', as_index=False)['T(K)'].mean())
        if not mwr_T_1h.empty:
            v = _interp_profile_to_targets(mwr_T_1h['height'], mwr_T_1h['T(K)'], tgt_h)
            _stash(records, pd.DataFrame({'height': tgt_h, 'T(K)': v}),
                   'temp_1h', 'MWR', t0, 'T(K)', launch=launch_ts)
    if 'rh_mwr_long' in globals():
        mwr_RH_1h = (rh_mwr_long.reset_index()
                     .query("timestamps >= @win30 and timestamps <= @wout30")
                     .groupby('height', as_index=False)['RH(%)'].mean())
        if not mwr_RH_1h.empty:
            v = _interp_profile_to_targets(mwr_RH_1h['height'], mwr_RH_1h['RH(%)'], tgt_h)
            _stash(records, pd.DataFrame({'height': tgt_h, 'RH(%)': v}),
                   'rh_1h', 'MWR', t0, 'RH(%)', launch=launch_ts)

    # DWL 1 å°æ—¶ï¼ˆæ•´ç‚¹ï¼‰
    if 'cleaned_h_60min' in globals():
        dwl_1h = (cleaned_h_60min
                  .loc[lambda d: pd.to_datetime(d['BJT']) == t0, ['height', 'hws']]
                  .dropna())
        if not dwl_1h.empty:
            v = _interp_profile_to_targets(dwl_1h['height'], dwl_1h['hws'], tgt_h)
            _stash(records, pd.DataFrame({'height': tgt_h, 'hws': v}),
                   'hws_1h', 'DWL', t0, 'hws', launch=launch_ts)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å†™å‡º Excelï¼ˆå¸¦ launchï¼Œè¿‡æ»¤/æ’åº/åˆ—å®½=25ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
from openpyxl.utils import get_column_letter

if not records:
    raise RuntimeError("records ä¸ºç©ºï¼Œå¯èƒ½å‰é¢çš„ _stash æœªè§¦å‘ã€‚")

# æ±‡æ€»
df_all = pd.concat(records, ignore_index=True)
df_all['time']   = pd.to_datetime(df_all['time'])
df_all['launch'] = pd.to_datetime(df_all['launch'])

# å›ºå®šæ¥æºé¡ºåº
source_order = ['Radiosonde', 'MWR', 'DWL', 'ERA5', 'CRA']
df_all['source'] = df_all['source'].astype(CategoricalDtype(categories=source_order, ordered=True))

# ç»Ÿä¸€æ’åºé”®ï¼ˆä¸ rh_1min ä¸€è‡´ï¼‰
SORT_KEYS = ['time', 'height', 'source']

# å¯¼å‡ºå‰æ£€æŸ¥ launch
missing = df_all['launch'].isna().mean()
print(f"Launch ç¼ºå¤±æ¯”ä¾‹ï¼š{missing:.1%}")

# è¾“å‡ºå‰å…ˆæ¸…ç†æ—§æ–‡ä»¶
if OUT_XLSX.exists():
    OUT_XLSX.unlink()

with pd.ExcelWriter(OUT_XLSX, engine='openpyxl') as xls:
    for name, grp in df_all.groupby('variable', sort=False):
        g = grp.copy()

        # ä»…å¯¹ hws_1h ä¸¢å¼ƒç©ºå€¼
        if name == 'hws_1h':
            g = g.dropna(subset=['value'])

        # ç»Ÿä¸€æ’åºï¼ˆç¨³å®šæ’åºé¿å…åŒå€¼ä¹±åºï¼‰
        g = g.sort_values(SORT_KEYS, kind='mergesort')

        # ç»Ÿä¸€åˆ—é¡ºåºè¾“å‡ºï¼ˆåŒ…å« launchï¼‰
        cols = ['time', 'launch', 'source', 'height', 'value']
        sheet_name = name[:31]
        g[cols].to_excel(xls, sheet_name=sheet_name, index=False)

        # è®¾ç½®åˆ—å®½ï¼šæ‰€æœ‰è¡¨åˆ—å®½ç»Ÿä¸€ä¸º 25
        ws = xls.sheets[sheet_name]
        for col_idx in range(1, len(cols) + 1):
            ws.column_dimensions[get_column_letter(col_idx)].width = 25

print(f"âœ… å·²å†™å…¥ {OUT_XLSX}ï¼ˆæ‰€æœ‰è¡¨å·²åŒ…å« launchï¼›hws_1h å·²å»ç©ºï¼›ç»Ÿä¸€æ’åºï¼›åˆ—å®½=25ï¼‰")
# =============================================================================

# =============================================================================
# æŒ‰é«˜åº¦åˆ†ç®±è®¡ç®— epsilon çš„æ ¸å¿ƒå®ç°ï¼ˆå«è¯¦ç»†ä¸­æ–‡æ³¨é‡Šï¼‰
# ç›®æ ‡ï¼šä»¥ Radiosonde ä¸ºå‚è€ƒï¼Œåœ¨â€œä¸¥æ ¼ç›¸åŒæ—¶ç©ºç‚¹ï¼ˆlaunch, time, heightï¼‰â€ä¸Š
#       è®¡ç®—å„æ¥æºä¸ RS çš„å·®å€¼ diffï¼Œå¹¶æŒ‰é«˜åº¦ 0~10000 mï¼ˆæ­¥é•¿ 100 mï¼‰åˆ†ç®±ï¼Œ
#       åœ¨æ¯ä¸ªé«˜åº¦ç®±å†…è®¡ç®—ï¼š
#         - B        = mean(diff)                       # åå·®ï¼ˆç³»ç»Ÿè¯¯å·®ï¼‰
#         - mean_sq  = mean(diff**2)                    # å¹³æ–¹å‡å€¼
#         - B2       = B**2
#         - sigma    = sqrt(mean_sq)                    # æ³¨æ„ï¼šæŒ‰ä½ çš„æ–°å®šä¹‰ï¼Œä¸å‡ B2
#         - epsilon  = mean(|diff| <= sigma)            # Ïƒ å†…æ¯”ä¾‹ï¼ˆç®±å†…æ ·æœ¬ä¸ºåˆ†æ¯ï¼‰
# è¾“å‡ºï¼šæ¯ä¸ªæ¥æºã€æ¯ä¸ªå˜é‡åœ¨æ¯ä¸ªé«˜åº¦ç®±çš„ä¸€è¡Œç»Ÿè®¡ï¼ˆä¸å« bin_centerï¼‰
# è¯´æ˜ï¼š
#   1) â€œç›¸åŒæ—¶ç©ºç‚¹â€æ˜¯é€šè¿‡å¯¹ (launch, time, height) åšå†…è¿æ¥ä¿è¯çš„ï¼›
#   2) åˆ†ç®±ä¸ºå³é—­åŒºé—´ (a, b]ï¼Œå¹¶åŒ…å«æœ€å°ç«¯ï¼ˆ0ï¼‰ï¼›ä½¿ç”¨ cat.codes å›å¡«è¾¹ç•Œï¼Œ
#      é¿å… pandas é»˜è®¤æ˜¾ç¤ºçš„ -0.001 ä¼ªå½±ï¼›
#   3) ä¸¢å¼ƒ height/diff ä¸­çš„ NaNï¼Œé˜²æ­¢ç»Ÿè®¡è¢«æ±¡æŸ“ï¼›
#   4) N ä¸ºæ¯ä¸ªé«˜åº¦ç®±çš„æœ‰æ•ˆæ ·æœ¬æ•°ï¼Œç”¨äºè´¨é‡æ£€æŸ¥ï¼›
#   5) è‹¥æŸæ¥æº/å˜é‡åœ¨æŸäº›ç®±æ²¡æœ‰æ•°æ®ï¼Œåˆ™è¯¥ç®±ä¸ä¼šå‡ºç°åœ¨ç»“æœä¸­ï¼ˆè‡ªç„¶ç¼ºçœï¼‰ã€‚
# =============================================================================
import numpy as np
import pandas as pd
from openpyxl.utils import get_column_letter
from pathlib import Path

# 1) é…ç½®ï¼šå˜é‡æ¸…å•ä¸åˆ†ç®±
VAR_GROUPS = {
    "1h":   ["temp_1h", "rh_1h", "hws_1h"],
    "1min": ["temp_1min", "rh_1min", "hws_1min"],
}
BIN_EDGES = np.arange(0, 10000 + 100, 100)   # [0,100,200,...,10000]ï¼ˆå³é—­ï¼Œå«10000ï¼‰

# 2) å·¥å…·ï¼šè§£æå˜é‡å
def _var_parts(var_name: str):
    """'temp_1h' -> ('temp','1h') ; 'hws_1min' -> ('hws','1min')"""
    base, res = var_name.split("_", 1)
    return base, res

# 3) å·¥å…·ï¼šè¯¥å˜é‡ä¸‹æœ‰å“ªäº›éRSæ¥æº
def _sources_for_var(df_all, variable):
    s = (df_all[df_all["variable"] == variable]["source"]
         .dropna().unique().tolist())
    return [x for x in s if x != "Radiosonde"]

# 4) åœ¨ç›¸åŒæ—¶ç©ºç‚¹é…å¯¹ï¼ˆä¸¥æ ¼å†…è¿æ¥ï¼‰
def _pair_same_spacetime(df_all, variable, src, exclude_launches=None):
    """è¿”å›ä¸€ä¸ª DataFrameï¼Œå«åˆ— ['time','launch','height','diff']ï¼Œdiff=src-ref"""
    ref = df_all[(df_all["variable"] == variable) & (df_all["source"] == "Radiosonde")].copy()
    dat = df_all[(df_all["variable"] == variable) & (df_all["source"] == src)].copy()

    if exclude_launches:
        ref = ref[~ref["launch"].isin(exclude_launches)]
        dat = dat[~dat["launch"].isin(exclude_launches)]

    if ref.empty or dat.empty:
        return pd.DataFrame(columns=["time","launch","height","diff"])

    # ä¸ºä¿è¯ä¸¥æ ¼åŒä¸€å‘å°„æ¬¡/æ—¶åˆ»/é«˜åº¦ï¼Œå¯¹ (launch,time,height) åšå†…è¿æ¥
    key_cols = ["launch", "time", "height"]
    merged = (dat[key_cols + ["value"]]
              .merge(ref[key_cols + ["value"]],
                     on=key_cols, how="inner",
                     suffixes=("_src","_ref")))
    if merged.empty:
        return pd.DataFrame(columns=["time","launch","height","diff"])

    merged["diff"] = merged["value_src"] - merged["value_ref"]
    return merged[["time","launch","height","diff"]]

# 5) æŒ‰é«˜åº¦åˆ†ç®±è®¡ç®—æŒ‡æ ‡
def _binned_stats(df_pairs, bin_edges):
    """
    è¾“å…¥ï¼šåŒä¸€æ¥æºä¸RSé…å¯¹å¾—åˆ°çš„å·®å€¼è¡¨ df_pairsï¼ˆåˆ—å« height, diffï¼‰
    è¾“å‡ºï¼šå„é«˜åº¦åˆ†ç®±ç»Ÿè®¡ç»“æœ DataFrame
          åˆ—ï¼š['bin_low','bin_high','bin_center','N','B','mean_sq','B2','sigma','epsilon']
    """
    if df_pairs is None or df_pairs.empty:
        return pd.DataFrame(columns=["bin_low","bin_high","bin_center","N","B","mean_sq","B2","sigma","epsilon"])

    tmp = df_pairs.copy()
    tmp["height"] = pd.to_numeric(tmp["height"], errors="coerce")
    tmp["diff"]   = pd.to_numeric(tmp["diff"],   errors="coerce")
    tmp = tmp.dropna(subset=["height","diff"])
    if tmp.empty:
        return pd.DataFrame(columns=["bin_low","bin_high","bin_center","N","B","mean_sq","B2","sigma","epsilon"])

    # åˆ†ç®±ï¼ˆå³é—­ï¼Œå«æœ€ä½ç«¯ï¼‰ï¼Œobserved=True ä»…ä¿ç•™å‡ºç°è¿‡çš„ç®±
    tmp["bin"] = pd.cut(tmp["height"], bins=bin_edges, right=True, include_lowest=True, ordered=True)
    g = tmp.groupby("bin", observed=True)["diff"]

    # é€ç®±èšåˆ
    stat = pd.DataFrame({
        "N": g.size(),
        "B": g.mean(),
        "mean_sq": g.apply(lambda x: np.mean(np.square(x)) if len(x) else np.nan),
    })
    stat["B2"]   = stat["B"]**2
    stat["sigma"] = np.sqrt(stat["mean_sq"])

    # epsilonï¼šç®±å†… |diff| <= sigma çš„æ¯”ä¾‹
    def _eps_one(x):
        if len(x) == 0:
            return np.nan
        sig = np.sqrt(np.mean(np.square(x)))
        return float((np.abs(x) <= sig).mean())
    stat["epsilon"] = g.apply(_eps_one)

    # è¿˜åŸåŒºé—´å·¦å³è¾¹ & ä¸­å¿ƒ â€”â€” å…ˆè½¬æˆå¯¹è±¡å†å– left/rightï¼Œå¹¶å¼ºåˆ¶ä¸º float
    stat = stat.reset_index()
    bins_obj = stat["bin"].astype("object")
    stat["bin_low"]    = bins_obj.map(lambda iv: float(iv.left)  if pd.notna(iv) else np.nan)
    stat["bin_high"]   = bins_obj.map(lambda iv: float(iv.right) if pd.notna(iv) else np.nan)
    stat["bin_center"] = (stat["bin_low"].astype(float) + stat["bin_high"].astype(float)) / 2.0
    
    first_edge = float(bin_edges[0])
    last_edge  = float(bin_edges[-1])
    stat["bin_low"]  = stat["bin_low"].astype(float).clip(lower=first_edge)
    stat["bin_high"] = stat["bin_high"].astype(float).clip(upper=last_edge)
   
    # æ”¶å°¾
    stat = stat.drop(columns=["bin"])
    stat = stat[["bin_low","bin_high","N","B","mean_sq","B2","sigma","epsilon"]]
    stat = stat.sort_values("bin_low").reset_index(drop=True)
    return stat

# 6) è®¡ç®—æŸä¸€åˆ†è¾¨ç‡ï¼ˆå¤šä¸ªå˜é‡ï¼‰çš„ä¸¤å¥—ç»“æœ
def _compute_binned_for_vars(df_all, var_list, bin_edges, exclude_launches=None):
    """
    è¿”å›ï¼šä¸€ä¸ªé•¿è¡¨ï¼Œåˆ—ï¼š
      ['resolution','variable','source','bin_low','bin_high','bin_center','N','B','mean_sq','B2','sigma','epsilon']
    """
    rows = []
    for var in var_list:
        base, res = _var_parts(var)
        for src in _sources_for_var(df_all, var):
            pairs = _pair_same_spacetime(df_all, var, src, exclude_launches=exclude_launches)
            stat  = _binned_stats(pairs, bin_edges)
            if stat.empty:
                continue
            stat.insert(0, "source", src)
            stat.insert(0, "variable", base)   # åªä¿ç•™ç‰©ç†é‡åï¼ˆtemp/rh/hwsï¼‰
            stat.insert(0, "resolution", res)  # 1h / 1min
            rows.append(stat)
    if not rows:
        return pd.DataFrame(columns=["resolution","variable","source","bin_low","bin_high","bin_center","N","B","mean_sq","B2","sigma","epsilon"])
    return pd.concat(rows, ignore_index=True)

# 7) éœ€è¦æ’é™¤çš„ launchï¼ˆç”¨ä½ ä¹‹å‰çš„è§£æå‡½æ•° _launch_from_sheetï¼‰
EXCLUDE_LAUNCH_STRS = ["2024080908", "2024080920", "2024081008"]
EXCLUDE_LAUNCHES = [_launch_from_sheet(s) for s in EXCLUDE_LAUNCH_STRS]

# â€”â€” å…¨å±€è¿‡æ»¤ç‰ˆæœ¬ï¼šå…ˆå¾—åˆ°â€œå·²æ’é™¤â€çš„æ€»è¡¨ â€”â€” #
df_all_excl = df_all[~df_all["launch"].isin(EXCLUDE_LAUNCHES)].copy()

# â€”â€” è®¡ç®—å››ä¸ªåœºæ™¯ï¼š1h/all, 1h/excl, 1min/all, 1min/excl â€”â€” #
# â€œallâ€ ç”¨å®Œæ•´ df_allï¼›â€œexclâ€ ç”¨å…¨å±€è¿‡æ»¤åçš„ df_all_excl
# æ³¨æ„ï¼šè¿™é‡ŒæŠŠ exclude_launches å‚æ•°è®¾ä¸º Noneï¼ˆæˆ–å»æ‰ï¼‰ï¼Œé¿å…é‡å¤è¿‡æ»¤
res1h_all   = _compute_binned_for_vars(df_all,       VAR_GROUPS["1h"],   BIN_EDGES, exclude_launches=None)
res1h_excl  = _compute_binned_for_vars(df_all_excl,  VAR_GROUPS["1h"],   BIN_EDGES, exclude_launches=None)
res1m_all   = _compute_binned_for_vars(df_all,       VAR_GROUPS["1min"], BIN_EDGES, exclude_launches=None)
res1m_excl  = _compute_binned_for_vars(df_all_excl,  VAR_GROUPS["1min"], BIN_EDGES, exclude_launches=None)


# 8) å†™å…¥ Excelï¼ˆæ¯ä¸ªå˜é‡/åœºæ™¯ä¸€ä¸ªå·¥ä½œè¡¨ï¼›åˆ—å®½=25ï¼‰
EPS_BIN_XLSX = OUT_XLSX.parent / "eps_binned_by_height_1h_1min.xlsx"

def _write_binned_to_xlsx(filepath: Path, df_all_res, tag: str):
    """
    df_all_res: å•ä¸€åœºæ™¯ï¼ˆå¦‚ 1h_allï¼‰çš„ç»“æœé•¿è¡¨
    tag: åœºæ™¯åç¼€ï¼Œå¦‚ '1h_all', '1h_excl', '1min_all', '1min_excl'
    - æ¯ä¸ªå˜é‡ï¼ˆtemp/rh/hwsï¼‰å„ä¸€å¼ è¡¨ï¼Œè¡¨åï¼š<tag>_<variable>
    """
    # æŒ‰å˜é‡æ‹†è¡¨
    for var in ["temp","rh","hws"]:
        sub = df_all_res[df_all_res["variable"] == var].copy()
        if sub.empty:
            continue
        # åˆ—é¡ºåºä¸æ’åº
        cols = ["resolution","variable","source","bin_low","bin_high","N","B","mean_sq","B2","sigma","epsilon"]
        sub = sub[cols].sort_values(["resolution","source","bin_low"], kind="mergesort")

        sheet = f"{tag}_{var}"[:31]
        sub.to_excel(_xls_writer, sheet_name=sheet, index=False)
        # åˆ—å®½ç»Ÿä¸€ 25
        ws = _xls_writer.sheets[sheet]
        for i in range(1, len(cols) + 1):
            ws.column_dimensions[get_column_letter(i)].width = 25

# è¦†ç›–å†™
if EPS_BIN_XLSX.exists():
    EPS_BIN_XLSX.unlink()

with pd.ExcelWriter(EPS_BIN_XLSX, engine="openpyxl") as _xls_writer:
    _write_binned_to_xlsx(EPS_BIN_XLSX, res1h_all,  "1h_all")
    _write_binned_to_xlsx(EPS_BIN_XLSX, res1h_excl, "1h_excl")
    _write_binned_to_xlsx(EPS_BIN_XLSX, res1m_all,  "1min_all")
    _write_binned_to_xlsx(EPS_BIN_XLSX, res1m_excl, "1min_excl")

print(f"âœ… é«˜åº¦åˆ†ç®± epsilon ç»“æœå·²å†™å…¥ï¼š{EPS_BIN_XLSX}")



# =============================================================================
# Îµ(launch) â€” ä»…éšå‘å°„æ—¶é—´å˜åŒ–çš„ epsilonï¼ˆæ— é«˜åº¦åˆ†ç®±ï¼‰
# ä»¥ Radiosonde ä¸ºå‚è€ƒï¼šåœ¨æ¯ä¸ª launch å†…è·¨ timeÃ—height çš„æ‰€æœ‰åŒä½ç‚¹å·®å€¼ä¸€èµ·è®¡ç®—
# ç»“æœè¦†ç›– 1h ä¸ 1minï¼›åœºæ™¯ï¼šall / exclude æŒ‡å®š launchï¼›è¾“å‡ºåˆ° Excelï¼ˆåˆ—å®½=25ï¼‰
# =============================================================================
from openpyxl.utils import get_column_letter
from pathlib import Path

# åˆ†è¾¨ç‡å˜é‡æ¸…å•
VAR_GROUPS = {
    "1h":   ["temp_1h", "rh_1h", "hws_1h"],
    "1min": ["temp_1min", "rh_1min", "hws_1min"],
}

def _var_parts(var_name: str):
    """'temp_1h' -> ('temp','1h') ; 'hws_1min' -> ('hws','1min')"""
    base, res = var_name.split("_", 1)
    return base, res

def _sources_for_var(df_all, variable):
    s = (df_all[df_all["variable"] == variable]["source"]
         .dropna().unique().tolist())
    return [x for x in s if x != "Radiosonde"]

def _pair_same_spacetime(df_all, variable, src, exclude_launches=None):
    """è¿”å›åˆ— ['time','launch','height','diff']ï¼›diff=src-refï¼Œä»…åŒ…å«åŒä¸€ (launch,time,height)ã€‚"""
    ref = df_all[(df_all["variable"] == variable) & (df_all["source"] == "Radiosonde")].copy()
    dat = df_all[(df_all["variable"] == variable) & (df_all["source"] == src)].copy()
    if exclude_launches is not None and len(exclude_launches):
        ref = ref[~ref["launch"].isin(exclude_launches)]
        dat = dat[~dat["launch"].isin(exclude_launches)]
    if ref.empty or dat.empty:
        return pd.DataFrame(columns=["time","launch","height","diff"])
    key_cols = ["launch", "time", "height"]
    merged = (dat[key_cols + ["value"]]
              .merge(ref[key_cols + ["value"]],
                     on=key_cols, how="inner",
                     suffixes=("_src","_ref")))
    if merged.empty:
        return pd.DataFrame(columns=["time","launch","height","diff"])
    merged["diff"] = merged["value_src"] - merged["value_ref"]
    return merged[["time","launch","height","diff"]]

def _launch_stats(df_pairs: pd.DataFrame) -> pd.DataFrame:
    """
    åœ¨æ¯ä¸ª launch å†…èšåˆï¼š
      N, B=mean(diff), mean_sq=mean(diff**2), B2=B**2, sigma=sqrt(mean_sq), 
      epsilon=mean(|diff|<=sigma)
    è¿”å›åˆ—ï¼š['launch','N','B','mean_sq','B2','sigma','epsilon']
    """
    if df_pairs is None or df_pairs.empty:
        return pd.DataFrame(columns=['launch','N','B','mean_sq','B2','sigma','epsilon'])
    tmp = df_pairs.copy()
    tmp['diff'] = pd.to_numeric(tmp['diff'], errors='coerce')
    tmp = tmp.dropna(subset=['diff', 'launch'])
    if tmp.empty:
        return pd.DataFrame(columns=['launch','N','B','mean_sq','B2','sigma','epsilon'])

    g = tmp.groupby('launch')['diff']
    stat = pd.DataFrame({
        'N': g.size(),
        'B': g.mean(),
        'mean_sq': g.apply(lambda x: np.mean(np.square(x)) if len(x) else np.nan),
    })
    stat['B2']    = stat['B']**2
    stat['sigma'] = np.sqrt(stat['mean_sq'])

    def _eps_one(x):
        if len(x) == 0:
            return np.nan
        sig = float(np.sqrt(np.mean(np.square(x))))
        return float((np.abs(x) <= sig).mean())
    stat['epsilon'] = g.apply(_eps_one)

    stat = stat.reset_index().sort_values('launch').reset_index(drop=True)
    return stat[['launch','N','B','mean_sq','B2','sigma','epsilon']]

def _compute_launch_for_vars(df_use: pd.DataFrame, var_list):
    """
    åœ¨ç»™å®š df_useï¼ˆå…¨é‡æˆ–å·²å…¨å±€æ’é™¤ï¼‰ä¸Šï¼Œè®¡ç®—æ¯ä¸ª variableÃ—source çš„ launch çº§ Îµã€‚
    è¿”å›é•¿è¡¨ï¼š['resolution','variable','source','launch','N','B','mean_sq','B2','sigma','epsilon']
    """
    rows = []
    for var in var_list:
        base, res = _var_parts(var)
        for src in _sources_for_var(df_use, var):
            pairs = _pair_same_spacetime(df_use, var, src, exclude_launches=None)  # å…¨å±€è¿‡æ»¤ç”± df_use å†³å®š
            stat  = _launch_stats(pairs)
            if stat.empty:
                continue
            stat.insert(0, 'source', src)
            stat.insert(0, 'variable', base)
            stat.insert(0, 'resolution', res)
            rows.append(stat)
    if not rows:
        return pd.DataFrame(columns=['resolution','variable','source','launch','N','B','mean_sq','B2','sigma','epsilon'])
    out = pd.concat(rows, ignore_index=True)
    out['launch'] = pd.to_datetime(out['launch'])
    return out

# â€”â€” å…¨å±€æ’é™¤æŒ‡å®š launch â€”â€” #
EXCLUDE_LAUNCH_STRS = ["2024080908", "2024080920", "2024081008"]
EXCLUDE_LAUNCHES = [_launch_from_sheet(s) for s in EXCLUDE_LAUNCH_STRS]
df_all_excl = df_all[~df_all["launch"].isin(EXCLUDE_LAUNCHES)].copy()

# â€”â€” è®¡ç®—å››ä¸ªåœºæ™¯ â€”â€” #
res_launch_1h_all   = _compute_launch_for_vars(df_all,      VAR_GROUPS["1h"])
res_launch_1h_excl  = _compute_launch_for_vars(df_all_excl, VAR_GROUPS["1h"])
res_launch_1m_all   = _compute_launch_for_vars(df_all,      VAR_GROUPS["1min"])
res_launch_1m_excl  = _compute_launch_for_vars(df_all_excl, VAR_GROUPS["1min"])

# â€”â€” å†™ Excelï¼ˆæ¯ä¸ª <åˆ†è¾¨ç‡Ã—å˜é‡Ã—åœºæ™¯> ä¸€ä¸ªå·¥ä½œè¡¨ï¼›åˆ—å®½=25ï¼‰ â€”â€” #
EPS_LAUNCH_XLSX = OUT_XLSX.parent / "eps_launch_only_1h_1min.xlsx"

def _write_launch_to_xlsx(writer, df_res: pd.DataFrame, res_tag: str, scenario_tag: str):
    """
    å°†æŸåˆ†è¾¨ç‡(res_tag: '1h'/'1min')ã€æŸåœºæ™¯(scenario_tag: 'all'/'excl')çš„
    launch çº§ç»“æœå†™å…¥å¤šä¸ªå·¥ä½œè¡¨ï¼ˆæ¯ä¸ªå˜é‡ä¸€ä¸ªè¡¨ï¼‰ã€‚
    sheetåï¼š<res_tag>_launch_<variable>_<scenario_tag> ä¾‹ï¼š1h_launch_temp_all
    """
    for base in ['temp','rh','hws']:
        sub = df_res[(df_res['variable']==base) & (df_res['resolution']==res_tag)].copy()
        if sub.empty:
            continue
        cols = ['resolution','variable','source','launch','N','B','mean_sq','B2','sigma','epsilon']
        sub = sub[cols].sort_values(['source','launch'], kind='mergesort')
        sheet = f"{res_tag}_launch_{base}_{scenario_tag}"[:31]
        sub.to_excel(writer, sheet_name=sheet, index=False)
        ws = writer.sheets[sheet]
        for i in range(1, len(cols)+1):
            ws.column_dimensions[get_column_letter(i)].width = 25

# è¦†ç›–å†™
if EPS_LAUNCH_XLSX.exists():
    EPS_LAUNCH_XLSX.unlink()

with pd.ExcelWriter(EPS_LAUNCH_XLSX, engine="openpyxl") as xls:
    _write_launch_to_xlsx(xls, res_launch_1h_all,  "1h",   "all")
    _write_launch_to_xlsx(xls, res_launch_1h_excl, "1h",   "excl")
    _write_launch_to_xlsx(xls, res_launch_1m_all,  "1min", "all")
    _write_launch_to_xlsx(xls, res_launch_1m_excl, "1min", "excl")

print(f"âœ… ä»…éšå‘å°„æ—¶é—´å˜åŒ–çš„ epsilon å·²å†™å…¥ï¼š{EPS_LAUNCH_XLSX}ï¼ˆæ— é«˜åº¦åˆ†ç®±ï¼‰")
